[{"categories":["go"],"content":"Golang 初识（安装、使用） ","date":"2022-09-21","objectID":"/golang/:0:0","tags":["golang"],"title":"Golang 初识（安装、使用）","uri":"/golang/"},{"categories":["go"],"content":"Go 导学 go语言由google公司推出。 运行速度快，简单易学 适合区块链开发 拥有丰富指令 可以直接包含C语言 语言层面支持并发 ","date":"2022-09-21","objectID":"/golang/:1:0","tags":["golang"],"title":"Golang 初识（安装、使用）","uri":"/golang/"},{"categories":["go"],"content":"Go 方向 网络编程 服务器编程 区块链开发 ","date":"2022-09-21","objectID":"/golang/:1:1","tags":["golang"],"title":"Golang 初识（安装、使用）","uri":"/golang/"},{"categories":["go"],"content":"环境安装 ","date":"2022-09-21","objectID":"/golang/:2:0","tags":["golang"],"title":"Golang 初识（安装、使用）","uri":"/golang/"},{"categories":["日常"],"content":"Headscale Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 Headscale，这也是唯一的一款，希望能发展壮大。 Headscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。 Headscale 部署 我决定使用docker-compose进行部署 ","date":"2022-09-21","objectID":"/headscale/:0:0","tags":["daliy"],"title":"headscale 部署使用","uri":"/headscale/"},{"categories":["日常"],"content":"创建存储 #!/bin/bash mkdir -p /opt/headscale mkdir -p ./config touch ./config/db.sqlite curl https://raw.githubusercontent.com/juanfont/headscale/main/config-example.yaml -o ./config/config.yaml ","date":"2022-09-21","objectID":"/headscale/:1:0","tags":["daliy"],"title":"headscale 部署使用","uri":"/headscale/"},{"categories":["日常"],"content":"运行docker-compose文件 创建docker-compose.yaml version: '3' services: headscale: image: headscale/headscale:latest volumes: - ./config:/etc/headscale/ - ./data:/var/lib/headscale ports: - 8080:8080 - 9090:9090 - 50443:50443 command: headscale serve restart: unless-stopped 运行 docker-compose up -d Headscale 使用 ","date":"2022-09-21","objectID":"/headscale/:2:0","tags":["daliy"],"title":"headscale 部署使用","uri":"/headscale/"},{"categories":["日常"],"content":"Linux使用 wget https://pkgs.tailscale.com/stable/tailscale_1.22.2_amd64.tgz 解压 tar zxvf tailscale_1.22.2_amd64.tgz 将二进制文件复制到官方软件包默认的路径下： cp tailscale_1.22.2_amd64/tailscaled /usr/sbin/tailscaled cp tailscale_1.22.2_amd64/tailscale /usr/bin/tailscale 将 systemD service 配置文件复制到系统路径下： cp tailscale_1.22.2_amd64/systemd/tailscaled.service /lib/systemd/system/tailscaled.service 启动 tailscaled.service 并设置开机自启： systemctl enable --now tailscaled 查看服务状态： systemctl status tailscaled ","date":"2022-09-21","objectID":"/headscale/:3:0","tags":["daliy"],"title":"headscale 部署使用","uri":"/headscale/"},{"categories":["docker"],"content":"清理Docker容器日志 如果docker容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在Linux或者Unix系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null \u003e *-json.log，当然你也可以通过rm -rf删除后重启docker。 ","date":"2022-09-19","objectID":"/cleandocker/:0:0","tags":["docker"],"title":"清理Docker容器日志","uri":"/cleandocker/"},{"categories":["docker"],"content":"日志清理脚本clean_docker_log.sh #!/bin/sh echo \"======== start clean docker containers logs ========\" logs=$(find /var/lib/docker/containers/ -name *-json.log) for log in $logs do echo \"clean logs : $log\" cat /dev/null \u003e $log done echo \"======== end clean docker containers logs ========\" chmod +x clean_docker_log.sh \u0026\u0026 ./clean_docker_log.sh ","date":"2022-09-19","objectID":"/cleandocker/:1:0","tags":["docker"],"title":"清理Docker容器日志","uri":"/cleandocker/"},{"categories":["docker"],"content":"设置Docker容器日志大小 设置一个容器服务的日志大小上限 上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器docker-compose的max-size选项来实现 nginx: image: nginx:1.12.1 restart: always logging: driver: “json-file” options: max-size: “5g” ","date":"2022-09-19","objectID":"/cleandocker/:2:0","tags":["docker"],"title":"清理Docker容器日志","uri":"/cleandocker/"},{"categories":["docker"],"content":"全局设置 新建/etc/docker/daemon.json，若有就不用新建了。添加log-dirver和log-opts参数 # vim /etc/docker/daemon.json { \"log-driver\":\"json-file\", \"log-opts\": {\"max-size\":\"500m\", \"max-file\":\"3\"} } max-size=500m，意味着一个容器日志大小上限是500M max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。 注意：设置的日志大小，只对新建的容器有效。 ","date":"2022-09-19","objectID":"/cleandocker/:2:1","tags":["docker"],"title":"清理Docker容器日志","uri":"/cleandocker/"},{"categories":["日常"],"content":"注意此教程需要通过电脑端完成 操作步骤 ","date":"2022-09-16","objectID":"/ylgy/:0:0","tags":["daliy"],"title":"羊了个羊小程序 破解通关","uri":"/ylgy/"},{"categories":["日常"],"content":"1、微信打开羊了个羊小程序，玩第一关 ","date":"2022-09-16","objectID":"/ylgy/:1:0","tags":["daliy"],"title":"羊了个羊小程序 破解通关","uri":"/ylgy/"},{"categories":["日常"],"content":"2、进入当前登录的微信数据文件夹 微信左下角 -\u003e 设置 -\u003e 文件管理 -\u003e 打开文件夹 打开后进入当前登录的微信数据文件夹 ","date":"2022-09-16","objectID":"/ylgy/:2:0","tags":["daliy"],"title":"羊了个羊小程序 破解通关","uri":"/ylgy/"},{"categories":["日常"],"content":"3、进入当前登录微信数据文件夹后，依次进入 \\Applet\\wx141bfb9b73c970a9\\usr\\gamecaches\\resources 注意wx141bfb9b73c970a9文件名可能不同，但以a9结尾 ","date":"2022-09-16","objectID":"/ylgy/:3:0","tags":["daliy"],"title":"羊了个羊小程序 破解通关","uri":"/ylgy/"},{"categories":["日常"],"content":"4、修改游戏配置文件 在此文件夹下，有很多json文件，找到默认排序的第三个，大小2k的文件 我的电脑是16632884479734.json文件，用记事本打开，清空里面内容，将new.txt文件中的代码复制进此json文件，保存关闭 [1,0,0,[[\"cc.JsonAsset\",[\"_name\",\"json\"],1]],[[0,0,1,3]],[[0,\"levelConfigData\",{\"dailyLevel\":[[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001]],\"topicLevel\":[[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017]]}]],0,0,[],[],[]] 之后打开游戏，仅需要完成4次第一关九宫格样式即可加入羊群！ ","date":"2022-09-16","objectID":"/ylgy/:4:0","tags":["daliy"],"title":"羊了个羊小程序 破解通关","uri":"/ylgy/"},{"categories":["问题库"],"content":"K8S 问题排查：cgroup 内存泄露问题 unable to ensure pod container exists: failed to create container for [kubepods besteffort pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b: cannot allocate memory ","date":"2022-08-30","objectID":"/k8s-error/:0:0","tags":["error"],"title":"K8S 问题排查：cgroup 内存泄露问题","uri":"/k8s-error/"},{"categories":["问题库"],"content":"查看linux内核 cat /proc/version uname -a 可以发现 linux版本是3.0版本 ","date":"2022-08-30","objectID":"/k8s-error/:1:0","tags":["error"],"title":"K8S 问题排查：cgroup 内存泄露问题","uri":"/k8s-error/"},{"categories":["问题库"],"content":"原因 cgroup 的 kmem account 特性在 Linux 3.x 内核上有内存泄露问题，然后k8s用了这个特性，导致后面创建不出新的pod来了 ","date":"2022-08-30","objectID":"/k8s-error/:2:0","tags":["error"],"title":"K8S 问题排查：cgroup 内存泄露问题","uri":"/k8s-error/"},{"categories":["问题库"],"content":"解决方法 # 修改/etc/default/grub 为 GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet cgroup.memory=nokmem\" #加上了 cgroup.memory=nokmem # 生成配置 /usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg # 重启机器 reboot ","date":"2022-08-30","objectID":"/k8s-error/:3:0","tags":["error"],"title":"K8S 问题排查：cgroup 内存泄露问题","uri":"/k8s-error/"},{"categories":["问题库"],"content":"验证 cat /sys/fs/cgroup/memory/kubepods/burstable/pod*/*/memory.kmem.slabinfo 输出信息 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod0fe273ca-42e0-4223-9fe8-16d8dd1774e9/0fdd5d9c16929fd600dbdf313b5c3ebabad912dc0cb076ed6e7799e028b31481/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod0fe273ca-42e0-4223-9fe8-16d8dd1774e9/aa30198d0c5413b70bf488c9daa350a85c7fc6b677235c5adaf2dde6caf95ec4/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod5be86c5d-d012-4cc2-b693-4882a15eda90/059b26b00f4f286b0f52e759b83dad79c7676e1705ee0f3f175a277fd1e5ea5a/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod5be86c5d-d012-4cc2-b693-4882a15eda90/bfa9db0c23fd056a0c05ee5b2b377dd551451cc0f18ddd5db82f9693674a4677/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod8f588e3d-fe89-4716-ab36-3ef606c70367/6fab9f4f7a83bf4c79a68277b214807bd566a8f13212a0fdb5742e4eee4d75d5/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod8f588e3d-fe89-4716-ab36-3ef606c70367/b04594732f7e38a47500ffe1150705110cfa683b585aa7eaf0965cc48ba2a46d/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod9c449bdf-492b-4adc-a623-4ced323ac6d4/c9e73e56ddae0c6c301e43852a51165419eb293b05fa65407f8cb3fe449daf5d/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/pod9c449bdf-492b-4adc-a623-4ced323ac6d4/d7392b1e4be1728fd739dc7117e6efc723a4727f143b91a1b386ad35dc1d3a2e/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/podd316acd7-69fe-4ad5-963a-6e19174b7cb0/0ec18ac0509e6ab454ebe637bde002330afc9eb70eff6f23fe8caa12880e82f6/memory.kmem.slabinfo: 输入/输出错误 cat: /sys/fs/cgroup/memory/kubepods/burstable/podd316acd7-69fe-4ad5-963a-6e19174b7cb0/dc5be82c01802c349c9505375c37dc054898b9b84e57cb4e671044e8a6459aac/memory.kmem.slabinfo: 输入/输出错误 ","date":"2022-08-30","objectID":"/k8s-error/:4:0","tags":["error"],"title":"K8S 问题排查：cgroup 内存泄露问题","uri":"/k8s-error/"},{"categories":["日常"],"content":"RocketMQ k8s部署 4主4从集群 ","date":"2022-08-29","objectID":"/rocketmq3/:0:0","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"使用NFS配置StatefulSet的动态持久化存储 ","date":"2022-08-29","objectID":"/rocketmq3/:1:0","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"安装NFS服务端 sudo apt update sudo apt install nfs-kernel-server nfs-common ","date":"2022-08-29","objectID":"/rocketmq3/:1:1","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"安装NFS客户端 所有的节点都得执行 sudo apt install nfs-common -y ","date":"2022-08-29","objectID":"/rocketmq3/:1:2","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"创建目录 mkdir -p /data/storage/k8s/rocketmq 使用NFS作为StatefulSet持久化存储的操作记录，分别需要创建nfs-provisioner的rbac、storageclass、nfs-client-provisioner和statefulset的pod ","date":"2022-08-29","objectID":"/rocketmq3/:1:3","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"创建nfs的rbac --- apiVersion: v1 kind: ServiceAccount metadata: name: nfs-provisioner namespace: sanjiang --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-provisioner-runner namespace: sanjiang rules: - apiGroups: [\"\"] resources: [\"persistentvolumes\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\"] - apiGroups: [\"\"] resources: [\"persistentvolumeclaims\"] verbs: [\"get\", \"list\", \"watch\", \"update\"] - apiGroups: [\"storage.k8s.io\"] resources: [\"storageclasses\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"\"] resources: [\"events\"] verbs: [\"list\",\"watch\", \"create\", \"update\", \"patch\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"get\",\"create\",\"list\", \"watch\",\"update\"] - apiGroups: [\"extensions\"] resources: [\"podsecuritypolicies\"] resourceNames: [\"nfs-provisioner\"] verbs: [\"use\"] - apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"create\", \"delete\", \"get\", \"list\", \"watch\", \"patch\", \"update\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-provisioner subjects: - kind: ServiceAccount name: nfs-provisioner namespace: sanjiang roleRef: kind: ClusterRole name: nfs-provisioner-runner apiGroup: rbac.authorization.k8s.io kubectl apply -f nfs-rbac.yaml ","date":"2022-08-29","objectID":"/rocketmq3/:1:4","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"创建rocketmq集群的storageclass apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: rocketmq-nfs-storage namespace: sanjiang provisioner: rocketmq/nfs reclaimPolicy: Retain kubectl apply -f rocketmq-nfs-class.yaml 查看创建情况 kubectl get sc -n sanjiang ","date":"2022-08-29","objectID":"/rocketmq3/:1:5","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"创建rocketmq集群的nfs-client-provisioner PROVISIONER_NAME的值一定要和StorageClass中的provisioner相等 apiVersion: apps/v1 kind: Deployment metadata: name: rocketmq-nfs-client-provisioner namespace: sanjiang spec: replicas: 1 selector: matchLabels: app: rocketmq-nfs-client-provisioner strategy: type: Recreate template: metadata: labels: app: rocketmq-nfs-client-provisioner spec: serviceAccount: nfs-provisioner containers: - name: rocketmq-nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner imagePullPolicy: IfNotPresent volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: rocketmq/nfs - name: NFS_SERVER value: 193.0.40.171 #nfs ip - name: NFS_PATH value: /data/storage/k8s/rocketmq volumes: - name: nfs-client-root nfs: server: 193.0.40.171 #nfs ip path: /data/storage/k8s/rocketmq kubectl apply -f rocketmq-nfs.yml ","date":"2022-08-29","objectID":"/rocketmq3/:1:6","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"k8s 部署 ","date":"2022-08-29","objectID":"/rocketmq3/:2:0","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"生成文件 broker-a-s.properties brokerClusterName=rocketmq-cluster brokerName=broker-a brokerId=1 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=SLAVE flushDiskType=SYNC_FLUSH broker-a.properties brokerClusterName=rocketmq-cluster brokerName=broker-a brokerId=0 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=MASTER broker-b-s.properties brokerClusterName=rocketmq-cluster brokerName=broker-b brokerId=1 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=SLAVE flushDiskType=SYNC_FLUSH broker-b.properties brokerClusterName=rocketmq-cluster brokerName=broker-b brokerId=0 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=MASTER flushDiskType=SYNC_FLUSH broker-c-s.properties brokerClusterName=rocketmq-cluster brokerName=broker-c brokerId=1 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=SLAVE flushDiskType=SYNC_FLUSH broker-c.properties brokerClusterName=rocketmq-cluster brokerName=broker-c brokerId=0 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=MASTER flushDiskType=SYNC_FLUSH broker-d-s.properties brokerClusterName=rocketmq-cluster brokerName=broker-d brokerId=1 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=SLAVE flushDiskType=SYNC_FLUSH broker-d.properties brokerClusterName=rocketmq-cluster brokerName=broker-d brokerId=0 namesrvAddr=rocketmq-0.rocketmq:9876 defaultTopicQueueNums=4 autoCreateTopicEnable=true autoCreateSubscriptionGroup=true listenPort=20911 deleteWhen=04 fileReservedTime=120 mapedFileSizeCommitLog=1073741824 mapedFileSizeConsumeQueue=300000 diskMaxUsedSpaceRatio=88 storePathRootDir=/data/rocketmq/store maxMessageSize=65536 brokerRole=MASTER flushDiskType=SYNC_FLUSH 运行命令 kubectl create cm rocketmq-config --from-file=broker-a.properties --from-file=broker-a-s.properties --from-file=broker-b.properties --from-file=broker-b-s.properties --from-file=broker-c.properties --from-file=broker-c-s.properties --from-file=broker-d.properties --from-file=broker-d-s.properties -n sanjiang kubectl get cm -n sanjiang|grep rocketmq ","date":"2022-08-29","objectID":"/rocketmq3/:2:1","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"创建配置文件 broker-a-s.yaml apiVersion: v1 kind: Service metadata: labels: app: broker-a-s name: broker-a-s namespace: sanjiang spec: ports: - port: 20911 targetPort: 20911 name: broker-port selector: app: broker-a-s --- apiVersion: apps/v1 kind: StatefulSet metadata: name: broker-a-s namespace: sanjiang spec: serviceName: broker-a-s replicas: 1 selector: matchLabels: app: broker-a-s template: metadata: labels: app: broker-a-s spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \"app\" operator: In values: - broker-a-s topologyKey: \"kubernetes.io/hostname\" containers: - name: broker-a-s image: liuyi71sinacom/rocketmq-4.8.0 imagePullPolicy: IfNotPresent command: [\"sh\",\"-c\",\"mqbroker -c /usr/local/rocketmq-4.8.0/conf/broker-a-s.properties\"] env: - name: JAVA_OPT value: \"-server -XX:ParallelGCThreads=1 -Xms1g -Xmx1g -Xmn512m\" #value: \"-XX:MaxRAMPercentage=80.0\" volumeMounts: - mountPath: /root/logs name: rocketmq-data subPath: mq-brokeroptlogs - mountPath: /data/rocketmq name: rocketmq-data subPath: mq-brokeroptstore - name: broker-config mountPath: /usr/local/rocketmq-4.8.0/conf/broker-a-s.properties subPath: broker-a-s.properties lifecycle: postStart: exec: command: [\"/bin/sh\",\"-c\",\"touch /tmp/health\"] livenessProbe: exec: command: [\"test\",\"-e\",\"/tmp/health\"] initialDelaySeconds: 5 timeoutSeconds: 5 periodSeconds: 10 readinessProbe: tcpSocket: port: 20911 initialDelaySeconds: 15 timeoutSeconds: 5 periodSeconds: 20 volumes: - name: broker-config configMap: name: rocketmq-config items: - key: broker-a-s.properties path: broker-a-s.properties volumeClaimTemplates: - metadata: name: rocketmq-data namespace: sanjiang annotations: volume.beta.kubernetes.io/storage-class: \"rocketmq-nfs-storage\" spec: accessModes: - ReadWriteMany resources: requests: storage: 2Gi --- apiVersion: v1 kind: PersistentVolume metadata: name: broker-a-s-pv namespace: sanjiang spec: accessModes: - ReadWriteMany capacity: storage: 2Gi persistentVolumeReclaimPolicy: Retain storageClassName: rocketmq-nfs-storage nfs: path: /data/storage/k8s/rocketmq/broker-a-s server: 193.0.40.171 broker-a.yaml apiVersion: v1 kind: Service metadata: labels: app: broker-a name: broker-a namespace: sanjiang spec: ports: - port: 20911 targetPort: 20911 name: broker-port selector: app: broker-a --- apiVersion: apps/v1 kind: StatefulSet metadata: name: broker-a namespace: sanjiang spec: serviceName: broker-a replicas: 1 selector: matchLabels: app: broker-a template: metadata: labels: app: broker-a spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: \"app\" operator: In values: - broker-a topologyKey: \"kubernetes.io/hostname\" containers: - name: broker-a image: liuyi71sinacom/rocketmq-4.8.0 imagePullPolicy: IfNotPresent command: [\"sh\",\"-c\",\"mqbroker -c /usr/local/rocketmq-4.8.0/conf/broker-a.properties\"] env: - name: JAVA_OPT value: \"-server -XX:ParallelGCThreads=1 -Xms1g -Xmx1g -Xmn512m\" #value: \"-XX:MaxRAMPercentage=80.0\" volumeMounts: - mountPath: /root/logs name: rocketmq-data subPath: mq-brokeroptlogs - mountPath: /data/rocketmq name: rocketmq-data subPath: mq-brokeroptstore - name: broker-config mountPath: /usr/local/rocketmq-4.8.0/conf/broker-a.properties subPath: broker-a.properties lifecycle: postStart: exec: command: [\"/bin/sh\",\"-c\",\"touch /tmp/health\"] livenessProbe: exec: command: [\"test\",\"-e\",\"/tmp/health\"] initialDelaySeconds: 5 timeoutSeconds: 5 periodSeconds: 10 readinessProbe: tcpSocket: port: 20911 initialDelaySeconds: 15 timeoutSeconds: 5 periodSeconds: 20 volumes: - name: broker-config configMap: name: rocketmq-config volumeClaimTemplates: - metadata: name: rocketmq-data namespace: sanjiang annotations: volume.beta.kubernetes.io/storage-class: \"rocketmq-nfs-storage\" spec: accessModes: - ReadWriteMany resources: requests: storage: 2Gi --- apiVersion: v1 kind: PersistentVolume metadata: name: broker-a-pv namespace: sanjiang spec: access","date":"2022-08-29","objectID":"/rocketmq3/:2:2","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["日常"],"content":"部署服务 kubectl apply -f . ","date":"2022-08-29","objectID":"/rocketmq3/:2:3","tags":["RocketMQ"],"title":"RocketMQ k8s部署 4主4从集群","uri":"/rocketmq3/"},{"categories":["docker"],"content":"contained 安装及使用 containerd 是一个行业标准的容器运行时，强调简单性、健壮性和可移植性。它可作为 Linux 和 Windows 的守护进程使用，可以管理其主机系统的完整容器生命周期：图像传输和存储、容器执行和监督、低级存储和网络附件等。 containerd is a member of CNCF with graduated status. 早在2016年3月，Docker 1.11的Docker Engine里就包含了containerd，而现在则是把containerd从Docker Engine里彻底剥离出来，作为一个独立的开源项目独立发展，目标是提供一个更加开放、稳定的容器运行基础设施。和原先包含在Docker Engine里containerd相比，独立的containerd将具有更多的功能，可以涵盖整个容器运行时管理的所有需求。 containerd并不是直接面向最终用户的，而是主要用于集成到更上层的系统里，比如Swarm, Kubernetes, Mesos等容器编排系统。 containerd以Daemon的形式运行在系统上，通过暴露底层的gRPC API，上层系统可以通过这些API管理机器上的容器。 每个containerd只负责一台机器，Pull镜像，对容器的操作（启动、停止等），网络，存储都是由containerd完成。具体运行容器由runC负责，实际上只要是符合OCI规范的容器都可以支持。 对于容器编排服务来说，运行时只需要使用containerd+runC，更加轻量，容易管理。 5.独立之后containerd的特性演进可以和Docker Engine分开，专注容器运行时管理，可以更稳定。 ","date":"2022-08-17","objectID":"/contained/:0:0","tags":["docker"],"title":"contained 安装及使用","uri":"/contained/"},{"categories":["docker"],"content":"安装 centos yum install -y containerd.io ubuntu apt install -y containerd.io 设置开机自启 systemctl enable containerd systemctl start containerd systemctl status containerd 验证 ctr version ","date":"2022-08-17","objectID":"/contained/:1:0","tags":["docker"],"title":"contained 安装及使用","uri":"/contained/"},{"categories":["docker"],"content":"ctr 命令 命令 作用 plugins, plugin 提供有关容器插件的信息 version 打印客户端和服务器版本 containers, c, container 管理容器 content 管理内容 events, event 显示容器事件 images, image, i 管理图像 leases 管理租约 namespaces, namespace, ns 管理租命名空间 pprof 为 containerd 提供 golang pprof 输出 run 运行一个容器 snapshots, snapshot 管理快照 tasks, t, task 管理任务 install 安装一个新包 oci OCI 工具 shim 直接与shim交互 help, h 显示命令列表或一个命令的帮助 ","date":"2022-08-17","objectID":"/contained/:2:0","tags":["docker"],"title":"contained 安装及使用","uri":"/contained/"},{"categories":["web3.0"],"content":"Planet 下载及安装 ","date":"2022-08-17","objectID":"/planet/:0:0","tags":["Planet","web3.0"],"title":"Planet 下载及安装","uri":"/planet/"},{"categories":["web3.0"],"content":"官网下载 Planet 是一款用于发布和关注 Web 内容的免费开源软件，它不需要集中式服务器或服务。它使用 IPFS 来实现点对点的内容分发。此外，您可以将您的内容链接到以太坊名称 (.eth)，以便其他人可以通过 Planet 以 .eth 名称关注您。由于 IPFS 和 ENS 都是去中心化的，因此您可以以去中心化的方式构建您的网站或关注其他网站。 ","date":"2022-08-17","objectID":"/planet/:1:0","tags":["Planet","web3.0"],"title":"Planet 下载及安装","uri":"/planet/"},{"categories":["web3.0"],"content":"如何使用 标准是 EIP-1577，这个 Content Hash 字段可以接受一些可能的值。例如，IPFS——另一种去中心化的内容分发技术。而vitalik.eth 网站已经在IPFS 上运行。 通过 Planet 关注来自vitalik.eth 的更新 使用 Planet 创建网站后，右键单击侧栏中的项目，然后选择Copy IPNS，然后您将在粘贴板中看到如下所示的内容： k51qzi5uqu5dgv8kzl1anc0m74n6t9ffdjnypdh846ct5wgpljc7rulynxa74a ","date":"2022-08-17","objectID":"/planet/:2:0","tags":["Planet","web3.0"],"title":"Planet 下载及安装","uri":"/planet/"},{"categories":["web3.0"],"content":"公开ENS 然后您可以像这样将该 IPNS 放入您的 ENS ContentHash 中： 确保在该字符串之前添加了 ipns://。 ","date":"2022-08-17","objectID":"/planet/:3:0","tags":["Planet","web3.0"],"title":"Planet 下载及安装","uri":"/planet/"},{"categories":["web3.0"],"content":"完成！ 然后您的网站将链接到您的 ENS。恭喜！现在你有一个在 ENS + IPFS 上运行的去中心化网站！ ","date":"2022-08-17","objectID":"/planet/:4:0","tags":["Planet","web3.0"],"title":"Planet 下载及安装","uri":"/planet/"},{"categories":["数据库"],"content":"索引 在关系数据库中，如果有上万甚至上亿条记录，在查找记录的时候，想要获得非常快的速度，就需要使用索引。 索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。 students表: id class_id name gender score 1 1 小明 M 90 2 1 小红 F 95 3 1 小军 M 88 ","date":"2022-08-16","objectID":"/sql-index/:0:0","tags":["mysql"],"title":"关系数据库 索引操作","uri":"/sql-index/"},{"categories":["数据库"],"content":"如果要经常根据score列进行查询，就可以对score列创建索引： ALTER TABLE students ADD INDEX idx_score (score); ","date":"2022-08-16","objectID":"/sql-index/:0:1","tags":["mysql"],"title":"关系数据库 索引操作","uri":"/sql-index/"},{"categories":["数据库"],"content":"使用ADD INDEX idx_score (score)就创建了一个名称为idx_score，使用列score的索引。索引名称是任意的，索引如果有多列，可以在括号里依次写上，例如： ALTER TABLE students ADD INDEX idx_name_score (name, score); 索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反过来，如果记录的列存在大量相同的值，例如gender列，大约一半的记录值是M，另一半是F，因此，对该列创建索引就没有意义。 ","date":"2022-08-16","objectID":"/sql-index/:0:2","tags":["mysql"],"title":"关系数据库 索引操作","uri":"/sql-index/"},{"categories":["数据库"],"content":"唯一索引 在设计关系数据表的时候，看上去唯一的列，例如身份证号、邮箱地址等，因为他们具有业务含义，因此不宜作为主键。 但是，这些列根据业务要求，又具有唯一性约束：即不能出现两条记录存储了同一个身份证号。这个时候，就可以给该列添加一个唯一索引。例如，我们假设students表的name不能重复： ALTER TABLE students ADD UNIQUE INDEX uni_name (name); 通过UNIQUE关键字我们就添加了一个唯一索引。 也可以只对某一列添加一个唯一约束而不创建唯一索引： ALTER TABLE students ADD CONSTRAINT uni_name UNIQUE (name); 这种情况下，name列没有索引，但仍然具有唯一性保证。 无论是否创建索引，对于用户和应用程序来说，使用关系数据库不会有任何区别。这里的意思是说，当我们在数据库中查询时，如果有相应的索引可用，数据库系统就会自动使用索引来提高查询效率，如果没有索引，查询也能正常执行，只是速度会变慢。因此，索引可以在使用数据库的过程中逐步优化 通过对数据库表创建索引，可以提高查询速度。 通过创建唯一索引，可以保证某一列的值具有唯一性。 数据库索引对于用户和应用程序来说都是透明的。 ","date":"2022-08-16","objectID":"/sql-index/:1:0","tags":["mysql"],"title":"关系数据库 索引操作","uri":"/sql-index/"},{"categories":["日常"],"content":"RocketMQ docker-compose部署 4主4从集群 V 4.8.0 采用4主4从，同步模式。HA实现上采用Master/Slave+Failover组件方式 每台主机运行三个容器，分别为NameServer、BrokerMaster、SlaveMaster，每个Master和Slave分别存放在不同的机器上 ","date":"2022-08-15","objectID":"/rocketmq2/:0:0","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["日常"],"content":"架构 IP 角色 服务 193.0.40.172 NameServer - 193.0.40.172 BrokerMaster broker-a 193.0.40.172 SlaveMaster broker-d-s 193.0.40.172 BrokerMaster broker-b 193.0.40.172 SlaveMaster broker-a-s 193.0.40.172 BrokerMaster broker-c 193.0.40.172 SlaveMaster broker-b-s 193.0.40.172 BrokerMaster broker-d 193.0.40.172 SlaveMaster broker-c-s ","date":"2022-08-15","objectID":"/rocketmq2/:1:0","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["日常"],"content":"部署 ","date":"2022-08-15","objectID":"/rocketmq2/:2:0","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["日常"],"content":"安装docker-compose #!/bin/bash # 下载安装 v2.4.1 docker-compose curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose docker-compose --version 执行 docker-compose --version 查看是否安装成功 ","date":"2022-08-15","objectID":"/rocketmq2/:2:1","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["日常"],"content":"生成配置文件 #!/bin/bash #docker-compose 生成配置文件 mkdir -p /rocketmq/data/namesv1 mkdir -p /rocketmq/logs/namesv1 mkdir -p /rocketmq/data/namesv2 mkdir -p /rocketmq/logs/namesv2 mkdir -p /rocketmq/config/broker-a mkdir -p /rocketmq/data/broker-a mkdir -p /rocketmq/logs/broker-a mkdir -p /rocketmq/config/broker-a-s mkdir -p /rocketmq/data/broker-a-s mkdir -p /rocketmq/logs/broker-a-s mkdir -p /rocketmq/config/broker-b mkdir -p /rocketmq/data/broker-b mkdir -p /rocketmq/logs/broker-b mkdir -p /rocketmq/config/broker-b-s mkdir -p /rocketmq/data/broker-b-s mkdir -p /rocketmq/logs/broker-b-s mkdir -p /rocketmq/config/broker-c mkdir -p /rocketmq/data/broker-c mkdir -p /rocketmq/logs/broker-c mkdir -p /rocketmq/config/broker-c-s mkdir -p /rocketmq/data/broker-c-s mkdir -p /rocketmq/logs/broker-c-s mkdir -p /rocketmq/config/broker-d mkdir -p /rocketmq/data/broker-d mkdir -p /rocketmq/logs/broker-d mkdir -p /rocketmq/config/broker-d-s mkdir -p /rocketmq/data/broker-d-s mkdir -p /rocketmq/logs/broker-d-s cd /rocketmq/config/broker-a cat \u003e broker-a.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-a #brokerId master用0 slave用其他 brokerId=0 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerRole=SYNC_MASTER #刷盘策略 - ASYNC_FLUSH 异步刷盘 - SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #主机ip brokerIP1=193.0.40.172 #对外服务的监听接口，同一台机器上部署多个broker,端口号要不相同 listenPort=10911 #namesvr namesrvAddr=193.0.40.172:9876;193.0.40.172:9877 #是否能够自动创建topic autoCreateTopicEnable=true EOF # 生成配置文件 cd /rocketmq/config/broker-a-s cat \u003e broker-a-s.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-a #brokerId master用0 slave用其他 brokerId=1 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerRole=SLAVE #刷盘策略 - ASYNC_FLUSH 异步刷盘 - SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #主机ip brokerIP1=193.0.40.172 #对外服务的监听接口，同一台机器上部署多个broker,端口号要不相同 listenPort=11911 #namesrv namesrvAddr=193.0.40.172:9876;193.0.40.172:9877 #是否能够自动创建topic autoCreateTopicEnable=true EOF cd /rocketmq/config/broker-b cat \u003e broker-b.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-b #brokerId master用0 slave用其他 brokerId=0 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerRole=SYNC_MASTER #刷盘策略 - ASYNC_FLUSH 异步刷盘 - SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #主机ip brokerIP1=193.0.40.172 #对外服务的监听接口，同一台机器上部署多个broker,端口号要不相同 listenPort=12911 #namesrv namesrvAddr=193.0.40.172:9876;193.0.40.172:9877 #是否能够自动创建topic autoCreateTopicEnable=true EOF cd /rocketmq/config/broker-b-s cat \u003e broker-b-s.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-b #brokerId master用0 slave用其他 brokerId=1 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerRole=SLAVE #刷盘策略 - ASYNC_FLUSH 异步刷盘 - SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #主机ip brokerIP1=193.0.40.172 #对外服务的监听接口，同一台机器上部署多个broker,端口号要不相同 listenPort=13911 #namesrv namesrvAddr=193.0.40.172:9876;193.0.40.172:9877 #是否能够自动创建topic autoCreateTopicEnable=true EOF cd /rocketmq/config/broker-c cat \u003e broker-c.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-c #brokerId master用0 slave用其他 brokerId=0 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerRole=SYNC_MASTER #刷盘策略 - ASYNC_FLUSH 异步刷盘 - SYNC_FLUSH 同步刷盘 flushDiskType=SYNC_FLUSH #主机ip brokerIP1=193.0.40.172 #对外服务的监听接口，同一台机器上部署多个broker,端口号要不相同 listenPort=14911 #namesrv namesrvAddr=193.0.40.172:9876;193.0.40.172:9877 #是否能够自动创建topic autoCreateTopicEnable=true EOF cd /rocketmq/config/broker-c-s cat \u003e broker-c-s.conf \u003c\u003cEOF #集群名称 brokerClusterName=DefaultCluster #broker名称 brokerName=broker-c #brokerId master用0 slave用其他 brokerId=1 #清理时机 deleteWhen=4 #文件保留时长 48小时 fileReservedTime=48 #broker角色 -ASYNC_MASTER异步复制 -SYNC_MASTER同步双写 -SLAVE brokerR","date":"2022-08-15","objectID":"/rocketmq2/:2:2","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["日常"],"content":"执行docker-compose.yaml 文件 version: '3' services: rocketmq-namesv1: image: apache/rocketmq:4.8.0 container_name: rocketmq-namesv1 restart: always ports: - 9876:9876 volumes: - /rocketmq/logs/namesv1:/home/rocketmq/logs environment: JAVA_OPT_EXT: -server -Xms256M -Xmx256M -Xmn128m command: sh mqnamesrv networks: rocketmq: aliases: - rocketmq-namesv1 rocketmq-namesv2: image: apache/rocketmq:4.8.0 container_name: rocketmq-namesv2 restart: always ports: - 9877:9876 volumes: - /rocketmq/logs/namesv2:/home/rocketmq/logs environment: JAVA_OPT_EXT: -server -Xms256M -Xmx256M -Xmn128m command: sh mqnamesrv networks: rocketmq: aliases: - rocketmq-namesv2 broker-a: image: apache/rocketmq:4.8.0 container_name: broker-a links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 10909:10909 - 10911:10911 - 10912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/broker-a:/home/rocketmq/logs - /rocketmq/config/broker-a/broker-a.conf:/home/rocketmq/rocketmq-4.8.0/conf/broker.conf command: sh mqbroker -c /home/rocketmq/rocketmq-4.8.0/conf/broker.conf autoCreateTopicEnable=true \u0026 networks: rocketmq: aliases: - broker-a broker-a-s: image: apache/rocketmq:4.8.0 container_name: broker-a-s links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 11909:10909 - 11911:11911 - 11912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/broker-a-s:/home/rocketmq/logs - /rocketmq/config/broker-a-s/broker-a-s.conf:/home/rocketmq/rocketmq-4.8.0/conf/broker.conf command: sh mqbroker -c /home/rocketmq/rocketmq-4.8.0/conf/broker.conf autoCreateTopicEnable=true \u0026 networks: rocketmq: aliases: - broker-a-s broker-b: image: apache/rocketmq:4.8.0 container_name: broker-b links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 12909:10909 - 12911:12911 - 12912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/broker-b:/home/rocketmq/logs - /rocketmq/config/broker-b/broker-b.conf:/home/rocketmq/rocketmq-4.8.0/conf/broker.conf command: sh mqbroker -c /home/rocketmq/rocketmq-4.8.0/conf/broker.conf autoCreateTopicEnable=true \u0026 networks: rocketmq: aliases: - broker-b broker-b-s: image: apache/rocketmq:4.8.0 container_name: broker-b-s links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 13909:10909 - 13911:13911 - 13912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/broker-b-s:/home/rocketmq/logs - /rocketmq/config/broker-b-s/broker-b-s.conf:/home/rocketmq/rocketmq-4.8.0/conf/broker.conf command: sh mqbroker -c /home/rocketmq/rocketmq-4.8.0/conf/broker.conf autoCreateTopicEnable=true \u0026 networks: rocketmq: aliases: - broker-b-s broker-c: image: apache/rocketmq:4.8.0 container_name: broker-c links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 14909:10909 - 14911:14911 - 14912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/broker-c:/home/rocketmq/logs - /rocketmq/config/broker-c/broker-c.conf:/home/rocketmq/rocketmq-4.8.0/conf/broker.conf command: sh mqbroker -c /home/rocketmq/rocketmq-4.8.0/conf/broker.conf autoCreateTopicEnable=true \u0026 networks: rocketmq: aliases: - broker-c broker-c-s: image: apache/rocketmq:4.8.0 container_name: broker-c-s links: - rocketmq-namesv1:rocketmq-namesv1 - rocketmq-namesv2:rocketmq-namesv2 ports: - 15909:10909 - 15911:15911 - 15912:10912 environment: TZ: Asia/Shanghai NAMESRV_ADDR: \"rocketmq-namesv1:9876\" JAVA_OPT_EXT: \"-server -Xms256M -Xmx256M -Xmn128m\" volumes: - /rocketmq/logs/brok","date":"2022-08-15","objectID":"/rocketmq2/:2:3","tags":["RocketMQ"],"title":"RocketMQ docker-compose部署 4主4从集群","uri":"/rocketmq2/"},{"categories":["gitlab"],"content":"Argo cd 安装和部署 Argo CD 是一个为 Kubernetes 而生的，遵循声明式 GitOps 理念的持续部署（CD）工具。Argo CD 可在 Git 存储库更改时自动同步和部署应用程序 ","date":"2022-08-10","objectID":"/argocd/:0:0","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"安装 k8s快速安装 k3s kubectl create namespace argocd k3s kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml ","date":"2022-08-10","objectID":"/argocd/:1:0","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"安装 Argo CD CLI Argo CD CLI 是用于管理 Argo CD 的命令行工具,Mac 系统可以直接使用 brew install 进行安装 brew install argocd ","date":"2022-08-10","objectID":"/argocd/:1:1","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"发布 Argo CD 服务 默认情况下， Argo CD 服务不对外暴露服务，可以通过 LoadBalancer 或者 NodePort 类型的 Service、Ingress、Kubectl 端口转发等方式将 Argo CD 服务发布到 Kubernetes 集群外部。 通过 NodePort 服务的方式暴露 Argo CD 到集群外部 kubectl patch svc argocd-server -n argocd -p '{\"spec\": {\"type\": \"NodePort\"}}' ","date":"2022-08-10","objectID":"/argocd/:1:2","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"查看端口 kubectl get svc -n argocd ","date":"2022-08-10","objectID":"/argocd/:1:3","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"使用 ","date":"2022-08-10","objectID":"/argocd/:2:0","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"获取 Argo CD 密码 默认情况下 admin 帐号的初始密码是自动生成的，会以明文的形式存储在 Argo CD 安装的命名空间中argocd-initial-admin-secret 的 Secret 对象下的 password kubectl -n argocd get secret \\ argocd-initial-admin-secret \\ -o jsonpath=\"{.data.password}\" | base64 -d ","date":"2022-08-10","objectID":"/argocd/:2:1","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["gitlab"],"content":"命令行可以使用以下方式登录 argocd login \u003c节点 IP\u003e:\u003c端口\u003e ","date":"2022-08-10","objectID":"/argocd/:2:2","tags":["gitlab"],"title":"Argo cd 安装和部署","uri":"/argocd/"},{"categories":["监控"],"content":"skywalking 基于OpenTracing规范，专门为微服务架构以及云原生服务。 ","date":"2022-08-10","objectID":"/skywalking/:0:0","tags":["skywalking"],"title":"skywalking APM 监控","uri":"/skywalking/"},{"categories":["监控"],"content":"APM 监控 一个基于微服务架构的电商系统 APM (Application Performance Management) 即应用性能管理，属于IT运维管理（ITOM)范畴. 分为一下三个方面： Logging 服务在处理某个请求时打印的错误日志，可以将这些日志信息记录到Elasticsearch或是其他存储中。通过Kibana或是其他工具来分析这些日志了解服务的行为和状态，大多数情况下。日志记录的数据很分散，并且相互独立。例如错误日志，请求处理过程中关键步骤的日志等等。 Metrics Metric是可以聚合的，例如为电商系统中每个HTTP接口添加一个计数器，计算每个接口的QPS，可以通过简单的加和计算得到系统的总负载情况。 Tracing 在微服务架构系统中一请求会经过很多服务处理，调用链路会非常长，要确定中间哪个服务出现异常是非常麻烦的事情，通过分布式链路追踪，运维人员就可以构建一个请求的视图。视图上战术了一个请求从进入系统开始到返回响应的整个流程。 系统交互图 系统加载图 ","date":"2022-08-10","objectID":"/skywalking/:1:0","tags":["skywalking"],"title":"skywalking APM 监控","uri":"/skywalking/"},{"categories":["监控"],"content":"目前流行的APM监控 Zipkin 对web.xml 进行修改，代码侵入 twitter开源 Cat 支持Java、C/C++、Node.Js、Python、go 代码侵入，埋点 美团开源 Pinpoint 基于字节码注入技术，代码无侵入 韩国公司开发，社区交流滞后 只支持hbase 颗粒度更细 Skywalking 观测性分析平台 基于字节码注入技术，代码无侵入 服务、服务实例、端点指标分析 服务拓扑图分析 服务、服务实例和端点（Endpont）SLA分析 支持es，h2,mysql,TiDb,sharding-sphere skywalking 整体框架 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。 右部分 Storage ：Tracing 数据存储。目前支持 ES、MySQL、Sharding Sphere、TiDB、H2 多种存储器。而我们目前采用的是 ES ，主要考虑是 SkyWalking 开发团队自己的生产环境采用 ES 为主。 左部分 SkyWalking UI ：负责提供控台，查看链路等等。 ","date":"2022-08-10","objectID":"/skywalking/:2:0","tags":["skywalking"],"title":"skywalking APM 监控","uri":"/skywalking/"},{"categories":["监控"],"content":"skywalking 配置 ","date":"2022-08-10","objectID":"/skywalking/:3:0","tags":["skywalking"],"title":"skywalking APM 监控","uri":"/skywalking/"},{"categories":["监控"],"content":"使用docker-compose安装 使用mysql作为存储 下载 mysql-connector-java-8.0.30.jar mkdir ./libs/ mv mysql-connector-java-8.0.30.jar ./libs/ 创建带mysql驱动的基础镜像 FROM apache/skywalking-oap-server:9.1.0 LABEL maintainer=\"nb@nbtyfood.com\" COPY ./libs/* /skywalking/oap-libs 上传dockerhub或者自己的镜像仓库，这里我是上传到自己的仓库 创建镜像 docker build -t skywalking-mysql-server:v1.0 . 打tag，选择上传位置 docker tag skywalking-mysql-server:v1.0 \u003c仓库地址\u003e/blog/skywalking-mysql-server:v1.0 上传镜像 docker push \u003c仓库地址\u003e/blog/skywalking-mysql-server:v1.0 version: \"3\" services: skywalking-oap-server: image: \"hub.docker.com/jobcher/skywalking-mysql-server:v1.0\" #docker iamge 地址 container_name: \"oap-server\" restart: \"always\" environment: - SW_STORAGE=mysql - SW_JDBC_URL=\"jdbc:mysql://10.12.12.4:3306/sk\" - SW_DATA_SOURCE_USER=user # mysql用户名 - SW_DATA_SOURCE_PASSWORD=password # mysql密码 ports: - \"10.12.12.16:12800:12800\" - \"10.12.12.16:1234:1234\" - \"10.12.12.16:11800:11800\" skywalking-oap-ui: #UI界面 image: \"apache/skywalking-ui:9.1.0\" container_name: \"oap-ui\" restart: \"always\" environment: - SW_OAP_ADDRESS=http://10.12.12.16:12800 ports: - \"8180:8080\" ","date":"2022-08-10","objectID":"/skywalking/:4:0","tags":["skywalking"],"title":"skywalking APM 监控","uri":"/skywalking/"},{"categories":["基础"],"content":"介绍 systemd 是linux中用来启动守护进程，Linux最早一直采用init进程 (systemd 架构图) ","date":"2022-08-08","objectID":"/systemd/:1:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"systemd 命令 systemd 不是一个具体的命令，而是一组命令，用于系统管理的各个方面 ","date":"2022-08-08","objectID":"/systemd/:2:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"1.systemctl systemctl是 Systemd 的主命令，用于管理系统。 # 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue ","date":"2022-08-08","objectID":"/systemd/:2:1","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"2.systemd-analyze systemd-analyze命令用于查看启动耗时 # 查看启动耗时 systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service ","date":"2022-08-08","objectID":"/systemd/:2:2","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"3.hostnamectl hostnamectl命令用于查看当前主机的信息。 # 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname jobcher ","date":"2022-08-08","objectID":"/systemd/:2:3","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"4.localectl localectl命令用于查看本地化设置 # 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB ","date":"2022-08-08","objectID":"/systemd/:2:4","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"5.timedatectl timedatectl命令用于查看当前时区设置 # 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS ","date":"2022-08-08","objectID":"/systemd/:2:5","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"6.loginctl loginctl命令用于查看当前登录的用户 # 列出当前session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf ","date":"2022-08-08","objectID":"/systemd/:2:6","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"Unit Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。 分类 资源 Service unit 系统服务 Target unit 多个 Unit 构成的一个组 Device Unit 硬件设备 Mount Unit 文件系统的挂载点 Automount Unit 自动挂载点 Path Unit 文件或路径 Scope Unit 不是由 Systemd 启动的外部进程 Slice Unit 进程组 Snapshot Unit Systemd 快照，可以切回某个快照 Socket Unit 进程间通信的 socket Swap Unit swap 文件 Timer Unit 定时器 ","date":"2022-08-08","objectID":"/systemd/:3:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"1.systemctl list-units systemctl list-units命令可以查看当前系统的所有 Unit # 列出正在运行的 Unit $ systemctl list-units # 列出所有Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service ","date":"2022-08-08","objectID":"/systemd/:3:1","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"2.Unit 的状态 systemctl status命令用于查看系统状态和单个 Unit 的状态。 # 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。 # 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service ","date":"2022-08-08","objectID":"/systemd/:3:2","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"3.Unit 管理 对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。 # 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 ","date":"2022-08-08","objectID":"/systemd/:3:3","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"4.依赖关系 Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。 systemctl list-dependencies命令列出一个 Unit 的所有依赖。 systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用–all参数。 systemctl list-dependencies --all nginx.service ","date":"2022-08-08","objectID":"/systemd/:3:4","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"Unit 的配置文件 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。 systemctl enable命令用于在上面两个目录之间，建立符号链接关系。 $ sudo systemctl enable jobcher.service # 等同于 $ sudo ln -s '/usr/lib/systemd/system/jobcher.service' '/etc/systemd/system/multi-user.target.wants/jobcher.service' 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。 与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service ","date":"2022-08-08","objectID":"/systemd/:4:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"1.配置文件的状态 systemctl list-unit-files命令用于列出所有配置文件。 # 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个列表显示每个配置文件的状态，一共有四种。 状态 连接 enabled 已建立启动链接 disabled 没建立启动链接 static 该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked 该配置文件被禁止建立启动链接 一旦修改配置文件，就要让 SystemD 重新加载配置文件，然后重新启动，否则修改不会生效。 $ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service ","date":"2022-08-08","objectID":"/systemd/:4:1","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"2.配置文件的格式 配置文件就是普通的文本文件，可以用文本编辑器打开。 systemctl cat命令可以查看配置文件的内容。 $ systemctl cat atd.service [Unit] Description=ATD daemon [Service] Type=forking ExecStart=/usr/bin/atd [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。 每个区块内部是一些等号连接的键值对。注意，键值对的等号两侧不能有空格。 [Section] Directive1=value Directive2=value ","date":"2022-08-08","objectID":"/systemd/:5:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"3.配置文件的区块 [Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。 区块 简介 Description 简短描述 Documentation 文档地址 Requires 当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败 Wants 与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败 BindsTo 与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行 Before 如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After 如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动 Conflicts 这里指定的 Unit 不能与当前 Unit 同时运行 Condition… 当前 Unit 运行必须满足的条件，否则不会运行 Assert… 当前 Unit 运行必须满足的条件，否则会报启动失败 [Install]通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。它的主要字段如下。 区块 简介 WantedBy 它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中 RequiredBy 它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias 当前 Unit 可用于启动的别名 Also 当前 Unit 激活（enable）时，会被同时激活的其他 Unit [Service]区块用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。 区块 简介 Type 定义启动时的进程行为。它有以下几种值。 Type=simple 默认值，执行ExecStart指定的命令，启动主进程 Type=forking 以 fork 方式从父进程创建子进程，创建后父进程会立即退出 Type=oneshot 一次性进程，Systemd 会等当前服务退出，再继续往下执行 Type=dbus 当前服务通过D-Bus启动 Type=notify 当前服务启动完毕，会通知Systemd，再继续往下执行 Type=idle 若有其他任务执行完毕，当前服务才会运行 ExecStart 启动当前服务的命令 ExecStartPre 启动当前服务之前执行的命令 ExecStartPost 启动当前服务之后执行的命令 ExecReload 重启当前服务时执行的命令 ExecStop 停止当前服务时执行的命令 ExecStopPost 停止当其服务之后执行的命令 RestartSec 自动重启当前服务间隔的秒数 Restart 定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutSec 定义 Systemd 停止当前服务之前等待的秒数 Environment 指定环境变量 ","date":"2022-08-08","objectID":"/systemd/:6:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"Target 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。 简单说，Target 就是一个 Unit 组，包含许多相关的 Unit 。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\"状态点\"，启动某个 Target 就好比启动到某种状态。 传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。 # 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target 它与init进程的主要差别如下： 默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。 启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。 配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。 ","date":"2022-08-08","objectID":"/systemd/:7:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["基础"],"content":"日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。 journalctl功能强大，用法非常多。 # 查看所有日志（默认情况下 ，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\"2012-10-30 18:17:16\" $ sudo journalctl --since \"20 min ago\" $ sudo journalctl --since yesterday $ sudo journalctl --since \"2015-01-10\" --until \"2015-01-11 03:00\" $ sudo journalctl --since 09:00 --until \"1 hour ago\" # 显示尾部的最新10行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有8级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years ","date":"2022-08-08","objectID":"/systemd/:8:0","tags":["运维"],"title":"systemd 守护命令","uri":"/systemd/"},{"categories":["问题库"],"content":"docker 无法启动 打开服务器输入docker ps,输出错误 Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 怀疑是不是docker.services 部署没成功，systemctl start docker 启动docker，结果服务器还是报错 Job for docker.service failed because the control process exited with error code. See “systemctl status docker.service” and “journalctl -xe” for details. systemctl status docker.service 输出日志： ● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2022-08-04 11:43:05 CST; 2min 57s ago TriggeredBy: ● docker.socket Docs: https://docs.docker.com Process: 30432 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (code=exited, status=1/FAILURE) Main PID: 30432 (code=exited, status=1/FAILURE) Aug 04 11:43:05 master01 systemd[1]: docker.service: Scheduled restart job, restart counter is at 3. Aug 04 11:43:05 master01 systemd[1]: Stopped Docker Application Container Engine. Aug 04 11:43:05 master01 systemd[1]: docker.service: Start request repeated too quickly. Aug 04 11:43:05 master01 systemd[1]: docker.service: Failed with result 'exit-code'. Aug 04 11:43:05 master01 systemd[1]: Failed to start Docker Application Container Engine. journalctl -xe 输出日志： Aug 04 11:46:49 master01 systemd[1]: Starting Docker Socket for the API. -- Subject: A start job for unit docker.socket has begun execution -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- A start job for unit docker.socket has begun execution. -- -- The job identifier is 58900. Aug 04 11:46:49 master01 systemd[1]: Listening on Docker Socket for the API. -- Subject: A start job for unit docker.socket has finished successfully -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- A start job for unit docker.socket has finished successfully. -- -- The job identifier is 58900. Aug 04 11:46:49 master01 systemd[1]: Starting Docker Application Container Engine... -- Subject: A start job for unit docker.service has begun execution -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- A start job for unit docker.service has begun execution. -- -- The job identifier is 58830. Aug 04 11:46:49 master01 dockerd[30544]: unable to configure the Docker daemon with file /etc/docker/daemon.json: EOF Aug 04 11:46:49 master01 systemd[1]: docker.service: Main process exited, code=exited, status=1/FAILURE -- Subject: Unit process exited -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- An ExecStart= process belonging to unit docker.service has exited. -- -- The process' exit code is 'exited' and its exit status is 1. Aug 04 11:46:49 master01 systemd[1]: docker.service: Failed with result 'exit-code'. -- Subject: Unit failed -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- The unit docker.service has entered the 'failed' state with result 'exit-code'. Aug 04 11:46:49 master01 systemd[1]: Failed to start Docker Application Container Engine. -- Subject: A start job for unit docker.service has failed -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- A start job for unit docker.service has finished with a failure. -- -- The job identifier is 58830 and the job result is failed. Aug 04 11:46:49 master01 sudo[30535]: pam_unix(sudo:session): session closed for user root 我运行了: sudo dockerd –debug 输出日志： unable to configure the Docker daemon with file /etc/docker/daemon.json: EOF 解决方法： #如果 /etc/docker/daemon.json 为空 vim /etc/docker/daemon.json # 添加 { } #保存退出 :wq 重启docker systemctl restart docker ","date":"2022-08-04","objectID":"/docker-error/:0:1","tags":["error"],"title":"docker 问题处理","uri":"/docker-error/"},{"categories":["k8s"],"content":"kubernetes 存储 k8s支持多种途径的多种类型的存储。例如iSCSI,SMB,NFS，以及对象存储。都是不同类型的部署在云上或者自建数据中心的外部存储系统。k8s上的所有存储都被称作卷 ","date":"2022-08-01","objectID":"/k8s10/:0:0","tags":["k8s"],"title":"kubernetes 存储","uri":"/k8s10/"},{"categories":["k8s"],"content":"CSI 容器存储接口 CSI是k8s存储体系中一部分，是一个开源项目，定义了一套基于标准的接口，从而使容器能够以一种统一的方式被不同的容器编排的工具使用。可以将插件称为provisioner ","date":"2022-08-01","objectID":"/k8s10/:1:0","tags":["k8s"],"title":"kubernetes 存储","uri":"/k8s10/"},{"categories":["k8s"],"content":"持久化 持久化卷 （pv） 持久化卷申请 （pvc） 存储类 （sv） PV 代表k8s的存储，pvc代表的是许可证，赋予pod访问pv的权限。cs使分配过程是动态的。 ","date":"2022-08-01","objectID":"/k8s10/:2:0","tags":["k8s"],"title":"kubernetes 存储","uri":"/k8s10/"},{"categories":["k8s"],"content":"使用iSCSI操作存储 iscsi 卷能将 iSCSI (基于 IP 的 SCSI) 卷挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，iscsi 卷的内容在删除 Pod 时会被保留，卷只是被卸载。 这意味着 iscsi 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。 iSCSI 的一个特点是它可以同时被多个用户以只读方式挂载。 这意味着你可以用数据集预先填充卷，然后根据需要在尽可能多的 Pod 上使用它。 不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载。不允许同时写入。 ","date":"2022-08-01","objectID":"/k8s10/:3:0","tags":["k8s"],"title":"kubernetes 存储","uri":"/k8s10/"},{"categories":["k8s"],"content":"创建 iscsi-pv.yaml iscsi-pvc.yaml iscsi-pv.yaml apiVersion: v1 kind: PersistentVolume metadata: name: iscsi-pv spec: capacity: storage: 500Gi accessModes: - ReadWriteOnce iscsi: targetPortal: 10.12.12.xxx:3260 # 修改 iqn: iqn.2000-01.com.synology:xxx.Target-1.21xxxxx344 # 修改 lun: 1 iscsi-pvc.yaml apiVersion: v1 kind: PersistentVolume metadata: name: iscsi-pv spec: capacity: storage: 500Gi accessModes: - ReadWriteOnce iscsi: targetPortal: 10.12.12.xxx:3260 # 修改 iqn: iqn.2000-01.com.synology:xxx.Target-1.21xxxxx344 # 修改 lun: 1 ","date":"2022-08-01","objectID":"/k8s10/:3:1","tags":["k8s"],"title":"kubernetes 存储","uri":"/k8s10/"},{"categories":["日常"],"content":"linux服务器 删除空间却未释放 在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink)，然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用，这样就会导致我们明明删除了文件，但是磁盘空间却未被释放 ","date":"2022-07-20","objectID":"/linux-disk/:0:0","tags":["日常生活"],"title":"linux服务器 删除空间却未释放","uri":"/linux-disk/"},{"categories":["日常"],"content":"获取占用列表状态 lsof | grep deleted 可以看到哪些文件还被使用，未被释放空间。 ","date":"2022-07-20","objectID":"/linux-disk/:1:0","tags":["日常生活"],"title":"linux服务器 删除空间却未释放","uri":"/linux-disk/"},{"categories":["日常"],"content":"释放磁盘空间 一种方法是kill掉相应的进程，或者停掉使用这个文件的应用，让os自动回收磁盘空间，当linux打开一个文件的时候,Linux内核会为每一个进程在/proc/, /proc/nnnn/fd/目录（nnnn为pid）建立一个以其pid为名的目录用来保存进程的相关信息，而其子目录fd保存的是该进程打开的所有文件的fd（fd：file descriptor）； kill进程是通过截断proc文件系统中的文件可以强制要求系统回收分配给正在使用的的文件，这是一项高级技术，仅当管理员确定不会对运行中的进程造成影响时使用。 kill -9 12345 # PID 重启服务 ","date":"2022-07-20","objectID":"/linux-disk/:2:0","tags":["日常生活"],"title":"linux服务器 删除空间却未释放","uri":"/linux-disk/"},{"categories":["日常"],"content":"lsof命令 lsof全名list opened files，也就是列举系统中已经被打开的文件。我们都知道，linux环境中，任何事物都是文件，设备是文件，目录是文件，甚至sockets也是文件。 ","date":"2022-07-20","objectID":"/linux-disk/:3:0","tags":["日常生活"],"title":"linux服务器 删除空间却未释放","uri":"/linux-disk/"},{"categories":["监控"],"content":"logstash 多管道部署 找到logstash 目录位置，一般来说在 /etc/logstash 路径下,修改 logstash.yml #增加 日志记录 path.logs: /var/log/logstash ","date":"2022-07-19","objectID":"/logstash/:0:0","tags":["logstash"],"title":"logstash 多管道部署","uri":"/logstash/"},{"categories":["监控"],"content":"增加管道 增加 conf.d目录下 test.conf input { beats { host =\u003e \"0.0.0.0\" port =\u003e 23000 # 修改端口IP } } filter { mutate{ add_field =\u003e { \"cluster\" =\u003e \"test\" # 修改标签 \"job\" =\u003e \"logstash\" } } } output { file { path =\u003e \"/data/路径名称\" # 路径名称 gzip =\u003e false #匹配以空格开头的行 } } 修改 pipelines.yml - pipeline.id: 名称 path.config: \"/etc/logstash/conf.d/配置文件.conf\" queue.type: persisted ","date":"2022-07-19","objectID":"/logstash/:1:0","tags":["logstash"],"title":"logstash 多管道部署","uri":"/logstash/"},{"categories":["监控"],"content":"启动logstash文件 /usr/share/logstash/bin/logstash \u0026 ","date":"2022-07-19","objectID":"/logstash/:2:0","tags":["logstash"],"title":"logstash 多管道部署","uri":"/logstash/"},{"categories":["k8s"],"content":"kubernetes 从1.23.x 升级到 1.24.x k8s 在1.24.x之后的版本放弃了和docker的兼容，使用containerd 作为底层的容器，直接参照官方文档的资料进行更新就会报错。因为你没有安装containerd，所以要安装containerd并配置才能正确的升级k8s 我用的是CentOS7.9的版本，因此以下操作都是在CentOS下操作。 ","date":"2022-06-29","objectID":"/k8s9/:0:0","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"Master 节点操作 ","date":"2022-06-29","objectID":"/k8s9/:1:0","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"1.升级kubeadm yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes kubeadm version kubeadm upgrade plan sudo kubeadm upgrade apply v1.24.2 ","date":"2022-06-29","objectID":"/k8s9/:1:1","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"2.安装containerd yum install containerd.io -y containerd config default \u003e /etc/containerd/config.toml vim /var/lib/kubelet/kubeadm-flags.env 修改kubeadm-flags.env 变量： KUBELET_KUBEADM_ARGS=\"--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\" ","date":"2022-06-29","objectID":"/k8s9/:1:2","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"3.升级kubelet yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes=kubernetes systemctl daemon-reload \u0026\u0026 systemctl restart containerd \u0026\u0026 systemctl restart kubelet 查看状态： kubectl get nodes systemctl status kubelet ","date":"2022-06-29","objectID":"/k8s9/:1:3","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"Worker 节点操作 ","date":"2022-06-29","objectID":"/k8s9/:2:0","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"1.升级kubeadm yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes kubeadm version kubeadm upgrade plan sudo kubeadm upgrade node ","date":"2022-06-29","objectID":"/k8s9/:2:1","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"2.安装containerd yum install containerd.io -y containerd config default \u003e /etc/containerd/config.toml vim /var/lib/kubelet/kubeadm-flags.env 修改kubeadm-flags.env 变量： KUBELET_KUBEADM_ARGS=\"--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\" ","date":"2022-06-29","objectID":"/k8s9/:2:2","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"3.升级kubelet yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes=kubernetes systemctl daemon-reload \u0026\u0026 systemctl restart containerd \u0026\u0026 systemctl restart kubelet 查看状态： systemctl status kubelet ","date":"2022-06-29","objectID":"/k8s9/:2:3","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"4.优化的维护节点 # 设置为不可调度 kubectl cordon \u003cnodename\u003e # 优雅排出容器 kubectl drain \u003cnodename\u003e --ignore-daemonsets --delete-emptydir-data # 确认维护完成之后，恢复正常 kubectl uncordon \u003cnodename\u003e ","date":"2022-06-29","objectID":"/k8s9/:2:4","tags":["k8s"],"title":"kubernetes 从1.23.x 升级到 1.24.x","uri":"/k8s9/"},{"categories":["k8s"],"content":"编写 kubernetes 资源描述文件 ","date":"2022-06-27","objectID":"/k8s8/:0:0","tags":["k8s"],"title":"编写 kubernetes 资源描述文件","uri":"/k8s8/"},{"categories":["k8s"],"content":"1. 部署一个应用 apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本 kind: Deployment #该配置的类型，我们使用的是 Deployment metadata: #译名为元数据，即 Deployment 的一些基本属性和信息 name: nginx-deployment #Deployment 的名称 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 app: nginx #为该Deployment设置key为app，value为nginx的标签 spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 replicas: 1 #使用该Deployment创建一个应用程序实例 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 matchLabels: #选择包含标签app:nginx的资源 app: nginx template: #这是选择或创建的Pod的模板 metadata: #Pod的元数据 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod app: nginx spec: #期望Pod实现的功能（即在pod中部署） containers: #生成container，与docker中的container是同一种 - name: nginx #container的名称 image: nginx:1.7.9 #使用镜像nginx:1.7.9创建container，该container默认80端口可访问 kubectl apply -f xxx.yaml ","date":"2022-06-27","objectID":"/k8s8/:0:1","tags":["k8s"],"title":"编写 kubernetes 资源描述文件","uri":"/k8s8/"},{"categories":["k8s"],"content":"2、暴露应用 apiVersion: v1 kind: Service metadata: name: nginx-service #Service 的名称 labels: #Service 自己的标签 app: nginx #为该 Service 设置 key 为 app，value 为 nginx 的标签 spec: #这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问 selector: #标签选择器 app: nginx #选择包含标签 app:nginx 的 Pod ports: - name: nginx-port #端口的名字 protocol: TCP #协议类型 TCP/UDP port: 80 #集群内的其他容器组可通过 80 端口访问 Service nodePort: 32600 #通过任意节点的 32600 端口访问 Service targetPort: 80 #将请求转发到匹配 Pod 的 80 端口 type: NodePort #Serive的类型，ClusterIP/NodePort/LoaderBalancer ","date":"2022-06-27","objectID":"/k8s8/:0:2","tags":["k8s"],"title":"编写 kubernetes 资源描述文件","uri":"/k8s8/"},{"categories":["k8s"],"content":"3、扩缩容 修改deployment.yaml 中的 replicas 属性即可 完成后运行 kubectl apply -f xxx.yaml ","date":"2022-06-27","objectID":"/k8s8/:0:3","tags":["k8s"],"title":"编写 kubernetes 资源描述文件","uri":"/k8s8/"},{"categories":["k8s"],"content":"4、滚动升级 修改deployment.yaml 中的 imageName 属性等 完成后运行 kubectl apply -f xxx.yaml ","date":"2022-06-27","objectID":"/k8s8/:0:4","tags":["k8s"],"title":"编写 kubernetes 资源描述文件","uri":"/k8s8/"},{"categories":["web 服务器"],"content":"nginx ssh-key connection exception Not long ago, I wanted to restart the company’s gitlab server.I couldn’t coonect to ssh when it restarted.emm……I try copy the ssh rsa.pub,but it didn’t work. error log: identity_sign: private key ~/.ssh/id_rsa contents do not match public what is happen？ solution reconfigure gitlab ssh key! create new ssh key ssh-keygen -t rsa -C 'git@gitlab.com' -f ~/.ssh/gitlab-rsa update config file,enter ~./ssh,open config # add host Host gitlab.com HostName gitlab.com IdentityFile ~/.ssh/gitlab_id-rsa enter http://gitlab.com ,Profile Settings–\u003eSSH Keys–\u003eAdd SSH Key You are done ","date":"2022-06-15","objectID":"/nginx05/:0:0","tags":["nginx","linux"],"title":"nginx ssh-key connection exception","uri":"/nginx05/"},{"categories":["k8s"],"content":"k8s manual expansion We find k8s-master node.Input the Command： expand kubectl scale --replicas=3 deploy my-test-deploy shrink kubectl scale --replicas=1 deploy my-test-deploy ","date":"2022-06-13","objectID":"/k8s7/:0:0","tags":["k8s"],"title":"kubernetes manual expansion","uri":"/k8s7/"},{"categories":["k8s"],"content":"trouble cleaning get resource list kubectl get deployment kubectl get pods kubectl get nodes # exists in the namespace kubectl api-resources --namespaced=true # not exists in the namespace kubectl api-resources --namespaced=false show info kubectl describe pod my-test-pod kubectl describe deployment my-test-pod exec container kubectl exec -ti my-test-pod /bin/bash ","date":"2022-06-13","objectID":"/k8s7/:1:0","tags":["k8s"],"title":"kubernetes manual expansion","uri":"/k8s7/"},{"categories":["监控"],"content":"nginx exporter 安装配置 二进制安装 wget https://github.com/nginxinc/nginx-prometheus-exporter/releases/download/v0.10.0/nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz tar -zxvf nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz -C ./nginx-exporter 在nginx上配置 ./configure \\ … \\ --with-http_stub_status_module make sudo make install 在nginx.config上配置 server { # 新增 location /nginx_status { stub_status on; access_log off; } } 重启nginx服务 nginx -t nginx -s reload 启动nginx exporter nginx-prometheus-exporter -nginx.scrape-uri http://\u003cnginx\u003e:8080/nginx_status 配置 prometheus 添加 prometheus.yml - job_name: 'nginx-exporter' file_sd_configs: - files: - \"./file_sd/nginx-exporter.yaml\" 在 ./file_sd/新建 nginx-exporter.yaml - targets: ['\u003cIP\u003e:9113'] labels: instance: \u003cnginx名称\u003e ","date":"2022-06-08","objectID":"/nginx-exporter/:0:0","tags":["prometheus"],"title":"nginx exporter 安装配置","uri":"/nginx-exporter/"},{"categories":["go"],"content":"go Struct 结构体 结构体是将零个或多个任意类型的变量，组合在一起的聚合数据类型，也可以看做是数据的集合。 ","date":"2022-04-26","objectID":"/go3/:0:0","tags":["golang"],"title":"go Struct 结构体","uri":"/go3/"},{"categories":["go"],"content":"声明结构体 //demo_11.go package main import ( \"fmt\" ) type Person struct { Name string Age int } func main() { var p1 Person p1.Name = \"Tom\" p1.Age = 30 fmt.Println(\"p1 =\", p1) var p2 = Person{Name:\"Burke\", Age:31} fmt.Println(\"p2 =\", p2) p3 := Person{Name:\"Aaron\", Age:32} fmt.Println(\"p2 =\", p3) //匿名结构体 p4 := struct { Name string Age int } {Name:\"匿名\", Age:33} fmt.Println(\"p4 =\", p4) } ","date":"2022-04-26","objectID":"/go3/:1:0","tags":["golang"],"title":"go Struct 结构体","uri":"/go3/"},{"categories":["go"],"content":"生成 JSON //demo_12.go package main import ( \"encoding/json\" \"fmt\" ) type Result struct { Code int `json:\"code\"` Message string `json:\"msg\"` } func main() { var res Result res.Code = 200 res.Message = \"success\" //序列化 jsons, errs := json.Marshal(res) if errs != nil { fmt.Println(\"json marshal error:\", errs) } fmt.Println(\"json data :\", string(jsons)) //反序列化 var res2 Result errs = json.Unmarshal(jsons, \u0026res2) if errs != nil { fmt.Println(\"json unmarshal error:\", errs) } fmt.Println(\"res2 :\", res2) } ","date":"2022-04-26","objectID":"/go3/:2:0","tags":["golang"],"title":"go Struct 结构体","uri":"/go3/"},{"categories":["go"],"content":"改变数据 //demo_13.go package main import ( \"encoding/json\" \"fmt\" ) type Result struct { Code int `json:\"code\"` Message string `json:\"msg\"` } func main() { var res Result res.Code = 200 res.Message = \"success\" toJson(\u0026res) setData(\u0026res) toJson(\u0026res) } func setData (res *Result) { res.Code = 500 res.Message = \"fail\" } func toJson (res *Result) { jsons, errs := json.Marshal(res) if errs != nil { fmt.Println(\"json marshal error:\", errs) } fmt.Println(\"json data :\", string(jsons)) } ","date":"2022-04-26","objectID":"/go3/:3:0","tags":["golang"],"title":"go Struct 结构体","uri":"/go3/"},{"categories":["go"],"content":"go Slice切片语法 切片是一种动态数组，比数组操作灵活，长度不是固定的，可以进行追加和删除。 len() 和 cap() 返回结果可相同和不同。 ","date":"2022-04-25","objectID":"/go2/:0:0","tags":["golang"],"title":"go Slice切片语法","uri":"/go2/"},{"categories":["go"],"content":"声明切片 //demo_7.go package main import ( \"fmt\" ) func main() { var sli_1 [] int //nil 切片 fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_1),cap(sli_1),sli_1) var sli_2 = [] int {} //空切片 fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_1),cap(sli_2),sli_2) var sli_3 = [] int {1, 2, 3, 4, 5} fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_3),cap(sli_3),sli_3) sli_4 := [] int {1, 2, 3, 4, 5} fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_4),cap(sli_4),sli_4) var sli_5 [] int = make([] int, 5, 8) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_5),cap(sli_5),sli_5) sli_6 := make([] int, 5, 9) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli_6),cap(sli_6),sli_6) } ","date":"2022-04-25","objectID":"/go2/:1:0","tags":["golang"],"title":"go Slice切片语法","uri":"/go2/"},{"categories":["go"],"content":"截取切片 //demo_8.go package main import ( \"fmt\" ) func main() { sli := [] int {1, 2, 3, 4, 5, 6} fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) fmt.Println(\"sli[1] ==\", sli[1]) fmt.Println(\"sli[:] ==\", sli[:]) fmt.Println(\"sli[1:] ==\", sli[1:]) fmt.Println(\"sli[:4] ==\", sli[:4]) fmt.Println(\"sli[0:3] ==\", sli[0:3]) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli[0:3]),cap(sli[0:3]),sli[0:3]) fmt.Println(\"sli[0:3:4] ==\", sli[0:3:4]) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli[0:3:4]),cap(sli[0:3:4]),sli[0:3:4]) } ","date":"2022-04-25","objectID":"/go2/:2:0","tags":["golang"],"title":"go Slice切片语法","uri":"/go2/"},{"categories":["go"],"content":"追加切片 //demo_9.go package main import ( \"fmt\" ) func main() { sli := [] int {4, 5, 6} fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) sli = append(sli, 7) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) sli = append(sli, 8) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) sli = append(sli, 9) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) sli = append(sli, 10) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) } ","date":"2022-04-25","objectID":"/go2/:3:0","tags":["golang"],"title":"go Slice切片语法","uri":"/go2/"},{"categories":["go"],"content":"删除切片 //demo_10.go package main import ( \"fmt\" ) func main() { sli := [] int {1, 2, 3, 4, 5, 6, 7, 8} fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) //删除尾部 2 个元素 fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli[:len(sli)-2]),cap(sli[:len(sli)-2]),sli[:len(sli)-2]) //删除开头 2 个元素 fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli[2:]),cap(sli[2:]),sli[2:]) //删除中间 2 个元素 sli = append(sli[:3], sli[3+2:]...) fmt.Printf(\"len=%d cap=%d slice=%v\\n\",len(sli),cap(sli),sli) } ","date":"2022-04-25","objectID":"/go2/:4:0","tags":["golang"],"title":"go Slice切片语法","uri":"/go2/"},{"categories":["go"],"content":"go 基础知识 ","date":"2022-04-25","objectID":"/go1/:0:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"目录结构 ├─ code -- 代码根目录 │ ├─ bin │ ├─ pkg │ ├─ src │ ├── hello │ ├── hello.go bin 存放编译后可执行的文件。 pkg 存放编译后的应用包。 src 存放应用源代码。 Hello World 代码 //在 hello 目录下创建 hello.go package main import ( \"fmt\" ) func main() { fmt.Println(\"Hello World!\") } ","date":"2022-04-25","objectID":"/go1/:1:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"基础命令 go build hello #在src目录或hello目录下执行 go build hello，只在对应当前目录下生成文件。 go install hello #在src目录或hello目录下执行 go install hello，会把编译好的结果移动到 $GOPATH/bin。 go run hello #在src目录或hello目录下执行 go run hello，不生成任何文件只运行程序。 go fmt hello #在src目录或hello目录下执行 go run hello，格式化代码，将代码修改成标准格式。 ","date":"2022-04-25","objectID":"/go1/:2:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"数据类型 类型 表示 备注 字符串 string 只能用一对双引号（\"\"）或反引号（``）括起来定义，不能用单引号（’’）定义！ 布尔 bool 只有 true 和 false，默认为 false。 整型 int8 uint8 int16 uint16 int32 uint32 int64 uint64 int uint 具体长度取决于 CPU 位数。 浮点型 float32 float64 ","date":"2022-04-25","objectID":"/go1/:3:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"常量声明 常量，在程序编译阶段就确定下来的值，而程序在运行时无法改变该值。 ","date":"2022-04-25","objectID":"/go1/:4:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"1. 单个常量声明 第一种：const 变量名称 数据类型 = 变量值 如果不赋值，使用的是该数据类型的默认值。 第二种：const 变量名称 = 变量值 根据变量值，自行判断数据类型。 ","date":"2022-04-25","objectID":"/go1/:4:1","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"2. 多个常量声明 第一种：const 变量名称,变量名称 … ,数据类型 = 变量值,变量值 … 第二种：const 变量名称,变量名称 … = 变量值,变量值 … ","date":"2022-04-25","objectID":"/go1/:4:2","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"3. 代码 //demo_1.go package main import ( \"fmt\" ) func main() { const name string = \"Tom\" fmt.Println(name) const age = 30 fmt.Println(age) const name_1, name_2 string = \"Tom\", \"Jay\" fmt.Println(name_1, name_2) const name_3, age_1 = \"Tom\", 30 fmt.Println(name_3, age_1) } ","date":"2022-04-25","objectID":"/go1/:4:3","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"变量声明 ","date":"2022-04-25","objectID":"/go1/:5:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"单个变量声明 第一种：var 变量名称 数据类型 = 变量值 如果不赋值，使用的是该数据类型的默认值。 第二种：var 变量名称 = 变量值 根据变量值，自行判断数据类型。 第三种：变量名称 := 变量值 省略了 var 和数据类型，变量名称一定要是未声明过的。 ","date":"2022-04-25","objectID":"/go1/:5:1","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"多个变量声明 第一种：var 变量名称,变量名称 … ,数据类型 = 变量值,变量值 … 第二种：var 变量名称,变量名称 … = 变量值,变量值 … 第三种：变量名称,变量名称 … := 变量值,变量值 … ","date":"2022-04-25","objectID":"/go1/:5:2","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"代码 //demo_2.go package main import ( \"fmt\" ) func main() { var age_1 uint8 = 31 var age_2 = 32 age_3 := 33 fmt.Println(age_1, age_2, age_3) var age_4, age_5, age_6 int = 31, 32, 33 fmt.Println(age_4, age_5, age_6) var name_1, age_7 = \"Tom\", 30 fmt.Println(name_1, age_7) name_2, is_boy, height := \"Jay\", true, 180.66 fmt.Println(name_2, is_boy, height) } ","date":"2022-04-25","objectID":"/go1/:5:3","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"输出方法 fmt.Print：输出到控制台（仅只是输出） fmt.Println：输出到控制台并换行 fmt.Printf：仅输出格式化的字符串和字符串变量（整型和整型变量不可以） fmt.Sprintf：格式化并返回一个字符串，不输出。 ","date":"2022-04-25","objectID":"/go1/:6:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"代码 //demo_3.go package main import ( \"fmt\" ) func main() { fmt.Print(\"输出到控制台不换行\") fmt.Println(\"---\") fmt.Println(\"输出到控制台并换行\") fmt.Printf(\"name=%s,age=%d\\n\", \"Tom\", 30) fmt.Printf(\"name=%s,age=%d,height=%v\\n\", \"Tom\", 30, fmt.Sprintf(\"%.2f\", 180.567)) } ","date":"2022-04-25","objectID":"/go1/:6:1","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"数组 数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成，一旦声明了，数组的长度就固定了，不能动态变化。 len() 和 cap() 返回结果始终一样。 ","date":"2022-04-25","objectID":"/go1/:7:0","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"声明数组 package main import ( \"fmt\" ) func main() { //一维数组 var arr_1 [5] int fmt.Println(arr_1) var arr_2 = [5] int {1, 2, 3, 4, 5} fmt.Println(arr_2) arr_3 := [5] int {1, 2, 3, 4, 5} fmt.Println(arr_3) arr_4 := [...] int {1, 2, 3, 4, 5, 6} fmt.Println(arr_4) arr_5 := [5] int {0:3, 1:5, 4:6} fmt.Println(arr_5) //二维数组 var arr_6 = [3][5] int {{1, 2, 3, 4, 5}, {9, 8, 7, 6, 5}, {3, 4, 5, 6, 7}} fmt.Println(arr_6) arr_7 := [3][5] int {{1, 2, 3, 4, 5}, {9, 8, 7, 6, 5}, {3, 4, 5, 6, 7}} fmt.Println(arr_7) arr_8 := [...][5] int {{1, 2, 3, 4, 5}, {9, 8, 7, 6, 5}, {0:3, 1:5, 4:6}} fmt.Println(arr_8) } ","date":"2022-04-25","objectID":"/go1/:7:1","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["go"],"content":"注意事项 一、数组不可动态变化问题，一旦声明了，其长度就是固定的。 var arr_1 = [5] int {1, 2, 3, 4, 5} arr_1[5] = 6 fmt.Println(arr_1) 运行会报错：invalid array index 5 (out of bounds for 5-element array) 二、数组是值类型问题，在函数中传递的时候是传递的值，如果传递数组很大，这对内存是很大开销。 //demo_5.go package main import ( \"fmt\" ) func main() { var arr = [5] int {1, 2, 3, 4, 5} modifyArr(arr) fmt.Println(arr) } func modifyArr(a [5] int) { a[1] = 20 } //demo_6.go package main import ( \"fmt\" ) func main() { var arr = [5] int {1, 2, 3, 4, 5} modifyArr(\u0026arr) fmt.Println(arr) } func modifyArr(a *[5] int) { a[1] = 20 } 三、数组赋值问题，同样类型的数组（长度一样且每个元素类型也一样）才可以相互赋值，反之不可以。 var arr = [5] int {1, 2, 3, 4, 5} var arr_1 [5] int = arr var arr_2 [6] int = arr 运行会报错：cannot use arr (type [5]int) as type [6]int in assignment ","date":"2022-04-25","objectID":"/go1/:7:2","tags":["golang"],"title":"go 基础知识","uri":"/go1/"},{"categories":["日常"],"content":"VSCode插件推荐=\u003e Code Runner Run code snippet or code file for multiple languages: C, C++, Java, JavaScript, PHP, Python, Perl, Perl 6, Ruby, Go, Lua, Groovy, PowerShell, BAT/CMD, BASH/SH, F# Script, F# (.NET Core), C# Script, C# (.NET Core), VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml Script, R, AppleScript, Elixir, Visual Basic .NET, Clojure, Haxe, Objective-C, Rust, Racket, Scheme, AutoHotkey, AutoIt, Kotlin, Dart, Free Pascal, Haskell, Nim, D, Lisp, Kit, V, SCSS, Sass, CUDA, Less, Fortran, Ring, and custom command 可以用编译运行超过40种语言，非常的方便～ ","date":"2022-04-25","objectID":"/vscode-runcode/:0:0","tags":["日常生活"],"title":"VSCode插件推荐=\u003e Code Runner","uri":"/vscode-runcode/"},{"categories":["日常"],"content":"在vscode插件里安装 ","date":"2022-04-25","objectID":"/vscode-runcode/:1:0","tags":["日常生活"],"title":"VSCode插件推荐=\u003e Code Runner","uri":"/vscode-runcode/"},{"categories":["日常"],"content":"运行你的代码 键盘快捷键 Ctrl+Alt+N 快捷键 F1 调出 命令面板, 然后输入 Run Code 在编辑区，右键选择 Run Code 在左侧的文件管理器，右键选择 Run Code 右上角的运行小三角按钮 ","date":"2022-04-25","objectID":"/vscode-runcode/:2:0","tags":["日常生活"],"title":"VSCode插件推荐=\u003e Code Runner","uri":"/vscode-runcode/"},{"categories":["日常"],"content":"ant build.xml 编写 ","date":"2022-04-21","objectID":"/ant1/:0:0","tags":["java"],"title":"ant build.xml 编写","uri":"/ant1/"},{"categories":["日常"],"content":"生成build.xml Eclipse 自动生成 Ant的Build.xml 配置文件,生成的方法很隐蔽 选择你要生成Build.xml文件的项目,右键. Export-\u003e General -\u003e Ant Buildfiles . 点Next,选择项目，再点Finish. ","date":"2022-04-21","objectID":"/ant1/:1:0","tags":["java"],"title":"ant build.xml 编写","uri":"/ant1/"},{"categories":["日常"],"content":"编写build.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?\u003e \u003c!-- 每个构建文件对应一个项目。\u003cproject\u003e标签时构建文件的根标签。它可以有多个内在属性，就如代码中所示，其各个属性的含义分别如下。 (1) default表示默认的运行目标，这个属性是必须的。 (2) basedir表示项目的基准目录。 (3) name表示项目名。 (4) description表示项目的描述。 --\u003e \u003cproject default=\"build\" name=\"Sort\"\u003e \u003c!-- 设置属性或文件路径，读取属性使用${property}，value路径默认项目根目录 --\u003e \u003cproperty file=\"ant/builds.properties\" /\u003e \u003cproperty name=\"src.dir\" value=\"src/statics\" /\u003e \u003cproperty name=\"classes.dir\" value=\"ant/classes\" /\u003e \u003cproperty name=\"lib.dir\" value=\"lib\" /\u003e \u003cproperty name=\"dist.dir\" value=\"ant/dist\" /\u003e \u003c!-- 定义classpath --\u003e \u003cpath id=\"master-classpath\"\u003e \u003cfileset file=\"${lib.dir}/*.jar\" /\u003e \u003cpathelement path=\"${classes.dir}\" /\u003e \u003c/path\u003e \u003c!--一个项目标签Project包含多个target标签，一个target标签可以依赖其他的target标签 在生成可执行文件之前必须先编译该文件，因策可执行文件的target依赖于编译程序的 target。 (1).name表示标明，这个属性是必须的。 (2).depends表示依赖的目标。 (3)if表示仅当属性设置时才执行。 (4)unless表示当属性没有设置时才执行。 (5)description表示项目的描述。 Ant的depends属性指定了target的执行顺序。Ant会依照depends属性中target出现顺序依次执行每个target。在执行之前，首先需要执行它所依赖的target。 --\u003e \u003c!-- 初始化任务 --\u003e \u003ctarget name=\"init\"\u003e \u003c!-- 输出标签 ，${init}是builds.properties中的属性 --\u003e \u003cecho message=\" Available Targets:\"/\u003e \u003cecho message=\"-------------------------------------------------------\"/\u003e \u003cecho message=\" init ${init} ...\"/\u003e \u003cecho message=\"-------------------------------------------------------\"/\u003e \u003c/target\u003e \u003c!-- 编译 --\u003e \u003ctarget name=\"compile\" depends=\"init\" description=\"compile the source files\"\u003e \u003c!-- 删除文件夹 --\u003e \u003cdelete dir=\"${classes.dir}\" /\u003e \u003c!-- 创建文件夹 --\u003e \u003cmkdir dir=\"${classes.dir}\" /\u003e \u003c!-- 编译java生成class文件 ，其属性如下 (1).srcdir表示源程序的目录。 (2).destdir表示class文件的输出目录。 (3).include表示被编译的文件的模式。 (4).excludes表示被排除的文件的模式。 (5).classpath表示所使用的类路径。 (6).debug表示包含的调试信息。 (7).optimize表示是否使用优化。 (8).verbose 表示提供详细的输出信息。 (9).fileonerror表示当碰到错误就自动停止。 --\u003e \u003cjavac srcdir=\"${src.dir}\" destdir=\"${classes.dir}\"\u003e \u003c!-- 编译需要的jar包 引用前面设置的class-path --\u003e \u003cclasspath refid=\"master-classpath\" /\u003e \u003c/javac\u003e \u003c/target\u003e \u003c!-- 打包成jar --\u003e \u003ctarget name=\"pack\" description=\"make .jar file\"\u003e \u003cdelete dir=\"${dist.dir}\" /\u003e \u003cmkdir dir=\"${dist.dir}\" /\u003e \u003c!-- 该标签用来生成一个JAR文件，其属性如下 (1) destfile表示JAR文件名。 (2) basedir表示被归档的文件名。要操作的文件路径 (3) includes表示别归档的文件模式。 (4) exchudes表示被排除的文件模式。 --\u003e \u003cjar destfile=\"${dist.dir}/hello.jar\" basedir=\"${classes.dir}\"\u003e \u003c!-- 不包含的类或内容 --\u003e \u003cexclude name=\"**/*Test.*\" /\u003e \u003c/jar\u003e \u003c/target\u003e \u003c!-- 生成zip压缩包 --\u003e \u003ctarget name=\"zip\"\u003e \u003cdelete dir=\"${release-dir}\" /\u003e \u003cmkdir dir=\"${release-dir}\" /\u003e \u003c!-- 该标签用来生成一个zip文件，其属性如下 (1) destfile表示zip文件名。 (2) basedir表示被归档的文件名。 要操作的文件路径 (3) includes表示别归档的文件模式。 (4) exchudes表示被排除的文件模式。 --\u003e \u003czip destfile=\"${release-dir}/antTest.zip\" update=\"true\" basedir=\"ant\" /\u003e \u003c/target\u003e \u003c/project\u003e ","date":"2022-04-21","objectID":"/ant1/:2:0","tags":["java"],"title":"ant build.xml 编写","uri":"/ant1/"},{"categories":["k8s"],"content":"k8s 调度过程 ","date":"2022-04-21","objectID":"/k8s6/:0:0","tags":["k8s"],"title":"kubernetes 调度过程","uri":"/k8s6/"},{"categories":["k8s"],"content":"执行滚动升级 修改deployment.yml文件，追加rollingUpdate # 部署应用 apiVersion: apps/v1 kind: Deployment metadata: name: jobcher-blog-deployment labels: app: jobcher-blog spec: replicas: 3 selector: matchLabels: app: jobcher-blog minReadySeconds: 10 #准备10s strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 #更新期间不少于3-1 maxSurge: 1 #更新期间不超过3+1 template: metadata: labels: app: jobcher-blog spec: containers: - name: jobcher-blog-pod image: hub.docker.com/blog/hugo:latest 执行命令 kubectl rollout restart deployment jobcher-blog-deployment ","date":"2022-04-21","objectID":"/k8s6/:1:0","tags":["k8s"],"title":"kubernetes 调度过程","uri":"/k8s6/"},{"categories":["go"],"content":"Golang go build 编译不同系统下的可执行文件 ","date":"2022-04-17","objectID":"/go/:0:0","tags":["golang"],"title":"Golang go build 编译不同版本","uri":"/go/"},{"categories":["go"],"content":"Mac系统编译 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ","date":"2022-04-17","objectID":"/go/:1:0","tags":["golang"],"title":"Golang go build 编译不同版本","uri":"/go/"},{"categories":["go"],"content":"Linux系统编译 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go ","date":"2022-04-17","objectID":"/go/:2:0","tags":["golang"],"title":"Golang go build 编译不同版本","uri":"/go/"},{"categories":["go"],"content":"windows系统编译 SET CGO_ENABLED=0 SET GOOS=darwin3 SET GOARCH=amd64 go build test.go SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm ","date":"2022-04-17","objectID":"/go/:3:0","tags":["golang"],"title":"Golang go build 编译不同版本","uri":"/go/"},{"categories":["日常"],"content":"记录一次上门打散工 壬寅年头磨难多 人间规则奈吾何 吟诗为把瘟神送 风起大江扬洪波 疫情减弱，遍邀亲友，无人相约，但闻昔日挚友，感怀往事邀吾往之。欲把殷勤牵挂诉，幸之。遂至友舍，诉之：帮忙装个监控吧～ ","date":"2022-04-17","objectID":"/20220416/:0:0","tags":["日常生活"],"title":"记录一次上门打散工","uri":"/20220416/"},{"categories":["日常"],"content":"买物料 和朋友两个人出发，帮朋友邻居家装个监控，他这个监控是要求装在车库里，但是网线要从4楼下放下去。所以，我们首先要出门购买一下物料： 带RJ45接口监控 足够长的网线 走了10000多步人都走傻了～ ","date":"2022-04-17","objectID":"/20220416/:1:0","tags":["日常生活"],"title":"记录一次上门打散工","uri":"/20220416/"},{"categories":["日常"],"content":"布线 这个没啥好说的，纯粹体力活，感谢朋友的暴风之锤，提高了工作效率，加快了项目进度 ","date":"2022-04-17","objectID":"/20220416/:2:0","tags":["日常生活"],"title":"记录一次上门打散工","uri":"/20220416/"},{"categories":["日常"],"content":"感谢 感谢朋友，给我这次项目实践和锻炼的机会让我认识到了自己的能力的不足～ ","date":"2022-04-17","objectID":"/20220416/:3:0","tags":["日常生活"],"title":"记录一次上门打散工","uri":"/20220416/"},{"categories":["gitlab"],"content":"ansible 命令 Inventory：Ansible管理的主机信息，包括IP地址、SSH端口、账号、密码等 Modules：任务均有模块完成，也可以自定义模块，例如经常用的脚本。 Plugins：使用插件增加Ansible核心功能，自身提供了很多插件，也可以自定义插件。例如connection插件，用于连接目标主机。 Playbooks：“剧本”，模块化定义一系列任务，供外部统一调用。Ansible核心功能。 ","date":"2022-04-14","objectID":"/ansible1/:0:0","tags":["ansible"],"title":"ansible 命令","uri":"/ansible1/"},{"categories":["gitlab"],"content":"编辑主机清单 [webservers] 192.168.0.20 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.21 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 192.168.0.22 ansible_ssh_user=root ansible_ssh_pass=’200271200’ [dbservers] 10.12.0.100 10.12.0.101 sed -i \"s/#host_key_checking = .*/host_key_checking = False/g\" /etc/ansible/ansible.cfg ","date":"2022-04-14","objectID":"/ansible1/:1:0","tags":["ansible"],"title":"ansible 命令","uri":"/ansible1/"},{"categories":["gitlab"],"content":"命令行 ansible all -m ping ansible all -m shell -a \"ls /root\" -u root -k ","date":"2022-04-14","objectID":"/ansible1/:2:0","tags":["ansible"],"title":"ansible 命令","uri":"/ansible1/"},{"categories":["gitlab"],"content":"常用模块 在目标主机执行shell命令。 shell - name: 将命令结果输出到指定文件 shell: somescript.sh \u003e\u003e somelog.txt - name: 切换目录执行命令 shell: cmd: ls -l | grep log chdir: somedir/ - name: 编写脚本 shell: | if [ 0 -eq 0 ]; then echo yes \u003e /tmp/result else echo no \u003e /tmp/result fi args: executable: /bin/bash copy 将文件复制到远程主机。 - name: 拷贝文件 copy: src: /srv/myfiles/foo.conf dest: /etc/foo.conf owner: foo group: foo mode: u=rw,g=r,o=r # mode: u+rw,g-wx,o-rwx # mode: '0644' backup: yes file 管理文件和文件属性。 - name: 创建目录 file: path: /etc/some_directory state: directory mode: '0755' - name: 删除文件 file: path: /etc/foo.txt state: absent - name: 递归删除目录 file: path: /etc/foo state: absent present，latest：表示安装 absent：表示卸载 yum 软件包管理。 - name: 安装最新版apache yum: name: httpd state: latest - name: 安装列表中所有包 yum: name: - nginx - postgresql - postgresql-server state: present - name: 卸载apache包 yum: name: httpd state: absent - name: 更新所有包 yum: name: '*' state: latest - name: 安装nginx来自远程repo yum: name: http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm # name: /usr/local/src/nginx-release-centos-6-0.el6.ngx.noarch.rpm state: present service/systemd 管理服务 - name: 服务管理 service: name: httpd state: started #state: stopped #state: restarted #state: reloaded - name: 设置开机启动 service: name: httpd enabled: yes unarchive 解压 - name: 解压 unarchive: src=test.tar.gz dest=/tmp debug 执行过程中打印语句。 - debug: msg: System {{ inventory_hostname }} has uuid {{ ansible_product_uuid }} - name: 显示主机已知的所有变量 debug: var: hostvars[inventory_hostname] verbosity: 4 ","date":"2022-04-14","objectID":"/ansible1/:3:0","tags":["ansible"],"title":"ansible 命令","uri":"/ansible1/"},{"categories":["日常"],"content":"Ant中如何添加第三方jar包依赖 如果使用ant进行java项目的编译部署，那怎么添加第三方jar包的依赖呢？方法如下： 在项目的根目录下创建lib目录，并把所有需要的第三方jar包放到此目录下。 在build.xml中依次添加：path、property，并在javac中添加classpath，添加unjar。完整配置如下： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject name=\"MyTool\" default=\"build\" basedir=\".\"\u003e \u003cdescription\u003eThe ant project to build MyTool.\u003c/description\u003e \u003cproperty name=\"srcDir\" location=\"src\" description=\"源文件的存放目录\" /\u003e \u003cproperty name=\"libDir\" location=\"lib\" description=\"第三方jar包的存放目录\" /\u003e \u003cproperty name=\"antDir\" location=\"ant\" description=\"编译后所有文件存放的根目录\" /\u003e \u003cproperty name=\"binDir\" location=\"${antDir}/bin\" description=\"编译后class文件的存放目录\" /\u003e \u003cproperty name=\"jarDir\" location=\"${antDir}/jar\" description=\"打包后jar包的存放目录\" /\u003e \u003cproperty name=\"jarFile\" location=\"${jarDir}/MyTool.jar\" description=\"打包后jar包存放的完整路径\" /\u003e \u003cproperty name=\"package\" value=\"com.xiboliya.mytool\" description=\"包名\" /\u003e \u003cproperty name=\"mainClass\" value=\"MyTool\" description=\"主类名\" /\u003e \u003cproperty name=\"resFromDir\" location=\"res\" description=\"资源文件的源目录\" /\u003e \u003cproperty name=\"resToDir\" location=\"${binDir}/res\" description=\"资源文件的目标目录\" /\u003e \u003cpath id=\"libPath\" description=\"编译时依赖的第三方jar包的存放路径\"\u003e \u003cfileset dir=\"${libDir}\" erroronmissingdir=\"false\"\u003e \u003cinclude name=\"*.jar\" /\u003e \u003c/fileset\u003e \u003c/path\u003e \u003cproperty name=\"classpath\" refid=\"libPath\" description=\"编译时依赖的第三方jar包的存放路径\" /\u003e \u003ctarget name=\"init\" description=\"初始化\"\u003e \u003cdelete dir=\"${binDir}\" /\u003e \u003cdelete dir=\"${jarDir}\" /\u003e \u003cmkdir dir=\"${binDir}\" /\u003e \u003cmkdir dir=\"${jarDir}\" /\u003e \u003ccopy todir=\"${resToDir}\" description=\"复制资源文件\"\u003e \u003cfileset dir=\"${resFromDir}\" /\u003e \u003c/copy\u003e \u003c/target\u003e \u003ctarget name=\"compile\" depends=\"init\" description=\"编译代码\"\u003e \u003cjavac srcdir=\"${srcDir}\" destdir=\"${binDir}\" classpath=\"${classpath}\" includeAntRuntime=\"false\"\u003e \u003ccompilerarg value=\"-Xlint:unchecked\"/\u003e \u003ccompilerarg value=\"-Xlint:deprecation\"/\u003e \u003c/javac\u003e \u003c/target\u003e \u003ctarget name=\"unjarLib\" depends=\"init\" description=\"解压第三方jar包，以便于重新打包入程序jar包中\"\u003e \u003cunjar dest=\"${binDir}\"\u003e \u003cfileset dir=\"${libDir}\"\u003e \u003cinclude name=\"**/*.jar\" /\u003e \u003c/fileset\u003e \u003cpatternset\u003e \u003cexclude name=\"META-INF\"/\u003e \u003cexclude name=\"META-INF/MANIFEST.MF\"/\u003e \u003c/patternset\u003e \u003c/unjar\u003e \u003c/target\u003e \u003ctarget name=\"makeJar\" depends=\"init,compile,unjarLib\" description=\"生成jar包\"\u003e \u003cjar destfile=\"${jarFile}\" basedir=\"${binDir}\" excludes=\"**/Thumbs.db\" description=\"打包为jar文件，并排除Thumbs.db文件\"\u003e \u003cmanifest\u003e \u003cattribute name=\"Main-Class\" value=\"${package}.${mainClass}\" /\u003e \u003c/manifest\u003e \u003c/jar\u003e \u003c/target\u003e \u003ctarget name=\"build\" depends=\"init,compile,makeJar\" description=\"编译并打包\"\u003e \u003cecho message=\"Ant is building the project.\" /\u003e \u003c/target\u003e \u003c/project\u003e ","date":"2022-04-14","objectID":"/ant/:0:0","tags":["javascript"],"title":"Ant中如何添加第三方jar包依赖","uri":"/ant/"},{"categories":["k8s"],"content":"k8s本地联调神器kt-connect 转载自Bboysoul’sBlog k8s集群内部的服务网络怎么和我们本地网络打通。kt-connect就是用来解决这个问题的 ","date":"2022-04-14","objectID":"/kt-connect/:0:0","tags":["k8s"],"title":"k8s本地联调神器kt-connect","uri":"/kt-connect/"},{"categories":["k8s"],"content":"使用方法 下载安装什么的都很简单，一个二进制而已 https://github.com/alibaba/kt-connect 如果你安装好了，那么直接使用下面的命令使用就好了 sudo ktctl connect 当然也可以指定配置文件 sudo ktctl --kubeconfig ~/.kube/local connect 执行完成之后，这个集群的所有svc都可以直接在本地解析，当然直接ping pod的ip也是可以的 ","date":"2022-04-14","objectID":"/kt-connect/:1:0","tags":["k8s"],"title":"k8s本地联调神器kt-connect","uri":"/kt-connect/"},{"categories":["k8s"],"content":"OpenELB：云原生负载均衡器插件 OpenELB 是一个开源的云原生负载均衡器实现，可以在基于裸金属服务器、边缘以及虚拟化的 Kubernetes 环境中使用 LoadBalancer 类型的 Service 对外暴露服务。 ","date":"2022-04-13","objectID":"/openelb/:0:0","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"在 Kubernetes 中安装 OpenELB kubectl apply -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml 查看状态 kubectl get po -n openelb-system ","date":"2022-04-13","objectID":"/openelb/:1:0","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"使用 kubectl 删除 OpenELB kubectl delete -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml kubectl get ns ","date":"2022-04-13","objectID":"/openelb/:2:0","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"配置 OpenELB kubectl edit configmap kube-proxy -n kube-system # 修改 网卡 ipvs: strictARP: true ","date":"2022-04-13","objectID":"/openelb/:3:0","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"重启组件 kubectl rollout restart daemonset kube-proxy -n kube-system ","date":"2022-04-13","objectID":"/openelb/:3:1","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"为 master1 节点添加一个 annotation 来指定网卡： kubectl annotate nodes master1 layer2.openelb.kubesphere.io/v1alpha1=\"192.168.0.2\" ","date":"2022-04-13","objectID":"/openelb/:3:2","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"创建地址池 layer2-eip.yaml apiVersion: network.kubesphere.io/v1alpha2 kind: Eip metadata: name: layer2-eip spec: address: 192.168.0.91-192.168.0.100 interface: eth0 protocol: layer2 ","date":"2022-04-13","objectID":"/openelb/:3:3","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"创建部署 jobcher-service.yaml #暴露端口 apiVersion: v1 kind: Service metadata: name: jobcher-service annotations: lb.kubesphere.io/v1alpha1: openelb protocol.openelb.kubesphere.io/v1alpha1: layer2 eip.openelb.kubesphere.io/v1alpha2: layer2-eip labels: app: jobcher-blog spec: selector: app: jobcher-blog ports: - name: jobcher-port protocol: TCP port: 80 targetPort: 80 type: LoadBalancer ","date":"2022-04-13","objectID":"/openelb/:3:4","tags":["k8s"],"title":"OpenELB：让k8s私有环境对外暴露端口","uri":"/openelb/"},{"categories":["k8s"],"content":"kubernetes ansible 自动化部署 ","date":"2022-04-08","objectID":"/k8s5/:0:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"服务器规划 角色 IP 组件 k8s-master1 10.12.12.15 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-master2 10.12.12.17 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-02 10.12.12.22 kubelet kube-proxy docker etcd k8s-03 10.12.12.21 kubelet kube-proxy docker etcd load Balancer(master) 10.12.12.15 10.12.12.23(VIP) nginx keepalived load Balancer(backup) 10.12.12.17 nginx keepalived ","date":"2022-04-08","objectID":"/k8s5/:1:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"系统初始化 关闭selinux，firewalld 关闭swap 时间同步 写hosts ssh免密（可选） ","date":"2022-04-08","objectID":"/k8s5/:2:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"etcd集群部署 生成etcd证书 部署三个ETC集群 查看集群状态 ","date":"2022-04-08","objectID":"/k8s5/:3:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"部署Masterß 生成apiserver证书 部署apiserver、controller-manager和scheduler组件 启动TLS Bootstrapping ","date":"2022-04-08","objectID":"/k8s5/:4:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"部署Node 安装Docker 部署Kubelet和kube-proxy 在Master上运行为新Node颁发证书 授权apiserver访问kubelet ","date":"2022-04-08","objectID":"/k8s5/:5:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"部署插件（准备好镜像） Flannel Web UI CoreDNS Ingress Controller ","date":"2022-04-08","objectID":"/k8s5/:6:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["k8s"],"content":"Master高可用 增加Master节点（与Master1一致） 部署nginx负载均衡器 Nginx+Keepalived 高可用 修改Node连接VIP ","date":"2022-04-08","objectID":"/k8s5/:7:0","tags":["k8s"],"title":"kubernetes ansible自动化部署","uri":"/k8s5/"},{"categories":["薅羊毛"],"content":"薅羊毛限时活动~ ","date":"2022-03-31","objectID":"/nice/:0:0","tags":["薅羊毛"],"title":"薅羊毛限时活动~","uri":"/nice/"},{"categories":["薅羊毛"],"content":"招商银行鹏扬基金宠粉福利，抽0.1-8.8元现金红包 活动内容： 本次活动共设置3个任务。一网通登录的用户完成以下全部3个任务后，即可参与抽奖。任务1：关注鹏扬基金招财号；任务2：将鹏扬中证500质量成长C加自选；任务3：将鹏扬沪深300质量低波C加自选。 本次活动奖品为随机现金红包，红包面额为0.1-8.8元不等，随机红包共100000个。活动不设绝对中奖，奖品数量有限，领完即止。 活动时间： 结束时间未知 活动步骤： 点击【立即前往】参与 ","date":"2022-03-31","objectID":"/nice/:1:0","tags":["薅羊毛"],"title":"薅羊毛限时活动~","uri":"/nice/"},{"categories":["gitlab"],"content":"Git飞行规则(Flight Rules) 编辑提交(editting commits) 我刚才提交了什么? 我的提交信息(commit message)写错了 我提交(commit)里的用户名和邮箱不对 我想从一个提交(commit)里移除一个文件 我想删除我的的最后一次提交(commit) 删除任意提交(commit) 我尝试推一个修正后的提交(amended commit)到远程，但是报错： 我意外的做了一次硬重置(hard reset)，我想找回我的内容 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) 我想要暂存一个新文件的一部分，而不是这个文件的全部 我想把在一个文件里的变化(changes)加到两个提交(commit)里 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 我想把未暂存的内容移动到另一个已存在的分支 我想丢弃本地未提交的变化(uncommitted changes) 我想丢弃某些未暂存的内容 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 我需要提交到一个新分支，但错误的提交到了main 我想保留来自另外一个ref-ish的整个文件 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 我想删除上游(upstream)分支被删除了的本地分支 我不小心删除了我的分支 我想删除一个分支 我想从别人正在工作的远程分支签出(checkout)一个分支 Rebasing 和合并(Merging) 我想撤销rebase/merge 我已经rebase过, 但是我不想强推(force push) 我需要组合(combine)几个提交(commit) 安全合并(merging)策略 我需要将一个分支合并成一个提交(commit) 我只想组合(combine)未推的提交(unpushed commit) 检查是否分支上的所有提交(commit)都合并(merge)过了 交互式rebase(interactive rebase)可能出现的问题 这个rebase 编辑屏幕出现’noop’ 有冲突的情况 Stash 暂存所有改动 暂存指定文件 暂存时记录消息 使用某个指定暂存 暂存时保留未暂存的内容 杂项(Miscellaneous Objects) 克隆所有子模块 删除标签(tag) 恢复已删除标签(tag) 已删除补丁(patch) 跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 我想从Git删除一个文件，但保留该文件 配置(Configuration) 我想给一些Git命令添加别名(alias) 我想缓存一个仓库(repository)的用户名和密码 我不知道我做错了些什么 其它资源(Other Resources) 书(Books) 教程(Tutorials) 脚本和工具(Scripts and Tools) GUI客户端(GUI Clients) ","date":"2022-03-24","objectID":"/git3/:0:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"编辑提交(editting commits) ","date":"2022-03-24","objectID":"/git3/:1:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我刚才提交了什么? 如果你用 git commit -a 提交了一次变化(changes)，而你又不确定到底这次提交了哪些内容。 你就可以用下面的命令显示当前HEAD上的最近一次的提交(commit): (main)$ git show 或者 $ git log -n1 -p ","date":"2022-03-24","objectID":"/git3/:1:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我的提交信息(commit message)写错了 如果你的提交信息(commit message)写错了且这次提交(commit)还没有推(push), 你可以通过下面的方法来修改提交信息(commit message): $ git commit --amend --only 这会打开你的默认编辑器, 在这里你可以编辑信息. 另一方面, 你也可以用一条命令一次完成: $ git commit --amend --only -m 'xxxxxxx' 如果你已经推(push)了这次提交(commit), 你可以修改这次提交(commit)然后强推(force push), 但是不推荐这么做。 ","date":"2022-03-24","objectID":"/git3/:1:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我提交(commit)里的用户名和邮箱不对 如果这只是单个提交(commit)，修改它： $ git commit --amend --author \"New Authorname \u003cauthoremail@mydomain.com\u003e\" 如果你需要修改所有历史, 参考 ‘git filter-branch’的指南页. ","date":"2022-03-24","objectID":"/git3/:1:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想从一个提交(commit)里移除一个文件 通过下面的方法，从一个提交(commit)里移除一个文件: $ git checkout HEAD^ myfile $ git add -A $ git commit --amend 这将非常有用，当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，你需要强推(force push)去更新这个远程补丁。 ","date":"2022-03-24","objectID":"/git3/:1:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想删除我的的最后一次提交(commit) 如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。 $ git reset HEAD^ --hard $ git push -f [remote] [branch] 如果你还没有推到远程, 把Git重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化): (my-branch*)$ git reset --soft HEAD@{1} 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是rebase-safe的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。 ","date":"2022-03-24","objectID":"/git3/:1:5","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"删除任意提交(commit) 同样的警告：不到万不得已的时候不要这么做. $ git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT $ git push -f [remote] [branch] 或者做一个 交互式rebase 删除那些你想要删除的提交(commit)里所对应的行。 ","date":"2022-03-24","objectID":"/git3/:1:6","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我尝试推一个修正后的提交(amended commit)到远程，但是报错： To https://github.com/yourusername/repo.git ! [rejected] mybranch -\u003e mybranch (non-fast-forward) error: failed to push some refs to 'https://github.com/tanay1337/webmaker.org.git' hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 – 总是 确保你指明一个分支! (my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。 ","date":"2022-03-24","objectID":"/git3/:1:7","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我意外的做了一次硬重置(hard reset)，我想找回我的内容 如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为Git对每件事都会有日志，且都会保存几天。 (main)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的SHA，再重置一次: (main)$ git reset --hard SHA1234 这样就完成了。 ","date":"2022-03-24","objectID":"/git3/:1:8","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"暂存(Staging) ","date":"2022-03-24","objectID":"/git3/:2:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我需要把暂存的内容添加到上一次的提交(commit) (my-branch*)$ git commit --amend ","date":"2022-03-24","objectID":"/git3/:2:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想要暂存一个新文件的一部分，而不是这个文件的全部 一般来说, 如果你想暂存一个文件的一部分, 你可这样做: $ git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)； 然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时, 这样做: $ git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。 ","date":"2022-03-24","objectID":"/git3/:2:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想把在一个文件里的变化(changes)加到两个提交(commit)里 git add 会把整个文件加入到一个提交. git add -p 允许交互式的选择你想要提交的部分. ","date":"2022-03-24","objectID":"/git3/:2:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 多数情况下，你应该将所有的内容变为未暂存，然后再选择你想要的内容进行commit。 但假定你就是想要这么做，这里你可以创建一个临时的commit来保存你已暂存的内容，然后暂存你的未暂存的内容并进行stash。然后reset最后一个commit将原本暂存的内容变为未暂存，最后stash pop回来。 $ git commit -m \"WIP\" $ git add . $ git stash $ git reset HEAD^ $ git stash pop --index 0 注意1: 这里使用pop仅仅是因为想尽可能保持幂等。 注意2: 假如你不加上--index你会把暂存的文件标记为为存储.这个链接 解释得比较清楚。（不过是英文的，其大意是说，这是一个较为底层的问题，stash时会做2个commit，其中一个会记录index状态，staged的文件等东西，另一个记录worktree和其他的一些东西，如果你不在apply时加index，git会把两个一起销毁，所以staged里就空了）。 ","date":"2022-03-24","objectID":"/git3/:2:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"未暂存(Unstaged)的内容 ","date":"2022-03-24","objectID":"/git3/:3:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想把未暂存的内容移动到一个新分支 $ git checkout -b my-branch ","date":"2022-03-24","objectID":"/git3/:3:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想把未暂存的内容移动到另一个已存在的分支 $ git stash $ git checkout my-branch $ git stash pop ","date":"2022-03-24","objectID":"/git3/:3:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想丢弃本地未提交的变化(uncommitted changes) 如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以： # one commit (my-branch)$ git reset --hard HEAD^ # two commits (my-branch)$ git reset --hard HEAD^^ # four commits (my-branch)$ git reset --hard HEAD~4 # or (main)$ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数: $ git reset filename ","date":"2022-03-24","objectID":"/git3/:3:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想丢弃某些未暂存的内容 如果你想丢弃工作拷贝中的一部分内容，而不是全部。 签出(checkout)不需要的内容，保留需要的。 $ git checkout -p # Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。 $ git stash -p # Select all of the snippets you want to save $ git reset --hard $ git stash pop 或者, stash 你不需要的部分, 然后stash drop。 $ git stash -p # Select all of the snippets you don't want to save $ git stash drop ","date":"2022-03-24","objectID":"/git3/:3:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"分支(Branches) ","date":"2022-03-24","objectID":"/git3/:4:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我从错误的分支拉取了内容，或把内容拉取到了错误的分支 这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前HEAD的指向。 (main)$ git reflog ab7555f HEAD@{0}: pull origin wrong-branch: Fast-forward c5bc55a HEAD@{1}: checkout: checkout message goes here 重置分支到你所需的提交(desired commit): $ git reset --hard c5bc55a 完成。 ","date":"2022-03-24","objectID":"/git3/:4:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 先确认你没有推(push)你的内容到远程。 git status 会显示你领先(ahead)源(origin)多少个提交: (my-branch)$ git status # On branch my-branch # Your branch is ahead of 'origin/my-branch' by 2 commits. # (use \"git push\" to publish your local commits) # 一种方法是: (main)$ git reset --hard origin/my-branch ","date":"2022-03-24","objectID":"/git3/:4:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我需要提交到一个新分支，但错误的提交到了main 在main下创建一个新分支，不切换到新分支,仍在main下: (main)$ git branch my-branch 把main分支重置到前一个提交: (main)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。 或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的hash(git log 能够完成)， 然后重置到这个hash。 使用git push 同步内容到远程。 例如, main分支想重置到的提交的hash为a13b85e: (main)$ git reset --hard a13b85e HEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作: (main)$ git checkout my-branch ","date":"2022-03-24","objectID":"/git3/:4:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想保留来自另外一个ref-ish的整个文件 假设你正在做一个原型方案(原文为working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容: (solution)$ git add -A \u0026\u0026 git commit -m \"Adding all changes from this spike into one big commit.\" 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。 假设你有: 分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题: (develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来: # On branch develop # Your branch is up-to-date with 'origin/develop'. # Changes to be committed: # (use \"git reset HEAD \u003cfile\u003e...\" to unstage) # # modified: file1.txt 然后, 正常提交。 Note: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia. ","date":"2022-03-24","objectID":"/git3/:4:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 假设你有一个main分支， 执行git log, 你看到你做过两次提交: (main)$ git log commit e3851e817c451cc36f2e6f3049db528415e3c114 Author: Alex Lee \u003calexlee@example.com\u003e Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protection commit 5ea51731d150f7ddc4a365437931cd8be3bf3131 Author: Alex Lee \u003calexlee@example.com\u003e Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on title commit a13b85e984171c6e2a1729bb061994525f626d14 Author: Aki Rose \u003cakirose@example.com\u003e Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交hash(commit hash)标记bug (e3851e8 for #21, 5ea5173 for #14). 首先, 我们把main分支重置到正确的提交(a13b85e): (main)$ git reset --hard a13b85e HEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支: (main)$ git checkout -b 21 (21)$ 接着, 我们用 cherry-pick 把对bug #21的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在HEAD上面。 (21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突. 再者， 我们为bug #14 创建一个新的分支, 也基于main分支 (21)$ git checkout main (main)$ git checkout -b 14 (14)$ 最后, 为 bug #14 执行 cherry-pick: (14)$ git cherry-pick 5ea5173 ","date":"2022-03-24","objectID":"/git3/:4:5","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想删除上游(upstream)分支被删除了的本地分支 一旦你在github 上面合并(merge)了一个pull request, 你就可以删除你fork里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。 $ git fetch -p ","date":"2022-03-24","objectID":"/git3/:4:6","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我不小心删除了我的分支 如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件: (main)$ git checkout -b my-branch (my-branch)$ git branch (my-branch)$ touch foo.txt (my-branch)$ ls README.md foo.txt 添加文件并做一次提交 (my-branch)$ git add . (my-branch)$ git commit -m 'foo.txt added' (my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt (my-branch)$ git log commit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012 Author: siemiatj \u003csiemiatj@example.com\u003e Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt added commit 69204cdf0acbab201619d95ad8295928e7f411d5 Author: Kate Hudson \u003ckatehudson@example.com\u003e Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(main)分支，‘不小心的’删除my-branch分支 (my-branch)$ git checkout main Switched to branch 'main' Your branch is up-to-date with 'origin/main'. (main)$ git branch -D my-branch Deleted branch my-branch (was 4e3cd85). (main)$ echo oh noes, deleted my branch! oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。 (main)$ git reflog 69204cd HEAD@{0}: checkout: moving from my-branch to main 4e3cd85 HEAD@{1}: commit: foo.txt added 69204cd HEAD@{2}: checkout: moving from main to my-branch 正如你所见，我们有一个来自删除分支的提交hash(commit hash)，接下来看看是否能恢复删除了的分支。 (main)$ git checkout -b my-branch-help Switched to a new branch 'my-branch-help' (my-branch-help)$ git reset --hard 4e3cd85 HEAD is now at 4e3cd85 foo.txt added (my-branch-help)$ ls README.md foo.txt 看! 我们把删除的文件找回来了。 Git的 reflog 在rebasing出错的时候也是同样有用的。 ","date":"2022-03-24","objectID":"/git3/:4:7","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想删除一个分支 删除一个远程分支: (main)$ git push origin --delete my-branch 你也可以: (main)$ git push origin :my-branch 删除一个本地分支: (main)$ git branch -D my-branch ","date":"2022-03-24","objectID":"/git3/:4:8","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想从别人正在工作的远程分支签出(checkout)一个分支 首先, 从远程拉取(fetch) 所有分支: (main)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves (main)$ git checkout --track origin/daves Branch daves set up to track remote branch daves from origin. Switched to a new branch 'daves' (--track 是 git checkout -b branch] [remotename/branch 的简写) 这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到. ","date":"2022-03-24","objectID":"/git3/:4:9","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"Rebasing 和合并(Merging) ","date":"2022-03-24","objectID":"/git3/:5:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想撤销rebase/merge 你可以合并(merge)或rebase了一个错误的分支, 或者完成不了一个进行中的rebase/merge。 Git 在进行危险操作的时候会把原始的HEAD保存在一个叫ORIG_HEAD的变量里, 所以要把分支恢复到rebase/merge前的状态是很容易的。 (my-branch)$ git reset --hard ORIG_HEAD ","date":"2022-03-24","objectID":"/git3/:5:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我已经rebase过, 但是我不想强推(force push) 不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了Git历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做: (main)$ git checkout my-branch (my-branch)$ git rebase -i main (my-branch)$ git checkout main (main)$ git merge --ff-only my-branch 更多, 参见 this SO thread. ","date":"2022-03-24","objectID":"/git3/:5:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我需要组合(combine)几个提交(commit) 假设你的工作分支将会做对于 main 的pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(main)分支是最新的和你的变化都已经提交了, 然后: (my-branch)$ git reset --soft main (my-branch)$ git commit -am \"New awesome feature\" 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式rebase (interactive rebase): (my-branch)$ git rebase -i main 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD~2 进行rebase， 组合最近3次提交(commit), 相对于HEAD~3, 等等。 (main)$ git rebase -i HEAD~2 在你执行了交互式 rebase的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容: pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature pick b729ad5 fixup pick e3851e8 another fix # Rebase 8074d12..b729ad5 onto 8074d12 # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \"squash\", but discard this commit's log message # x, exec = run command (the rest of the line) using shell # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase. 然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。 例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f: pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature f b729ad5 fixup f e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f: pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature s b729ad5 fixup s e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。 Newer, awesomer features # Please enter the commit message for your changes. Lines starting # with '#' will be ignored, and an empty message aborts the commit. # rebase in progress; onto 8074d12 # You are currently editing a commit while rebasing branch 'main' on '8074d12'. # # Changes to be committed: # modified: README.md # 如果成功了, 你应该看到类似下面的内容: (main)$ Successfully rebased and updated refs/heads/main. 安全合并(merging)策略 --no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。 (main)$ git merge --no-ff --no-commit my-branch 我需要将一个分支合并成一个提交(commit) (main)$ git merge --squash my-branch 我只想组合(combine)未推的提交(unpushed commit) 有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。 (main)$ git rebase -i @{u} 这会产生一次交互式的rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行reorder/fix/squash 都是安全的。 ","date":"2022-03-24","objectID":"/git3/:5:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"检查是否分支上的所有提交(commit)都合并(merge)过了 检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的head(或任何 commits)之间做一次diff: (main)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是: (main)$ git log main ^feature/120-on-scroll --no-merges ","date":"2022-03-24","objectID":"/git3/:5:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"交互式rebase(interactive rebase)可能出现的问题 这个rebase 编辑屏幕出现’noop’ 如果你看到的是这样: noop 这意味着你rebase的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试: 检查确保主(main)分支没有问题 rebase HEAD~2 或者更早 有冲突的情况 如果你不能成功的完成rebase, 你可能必须要解决冲突。 首先执行 git status 找出哪些文件有冲突: (my-branch)$ git status On branch my-branch Changes not staged for commit: (use \"git add \u003cfile\u003e...\" to update what will be committed) (use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory) modified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容: \u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD some code ========= some code \u003e\u003e\u003e\u003e\u003e\u003e\u003e new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方. 有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor): (main*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续rebase。 (my-branch)$ git add README.md (my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。 任何时候你想结束整个rebase 过程，回来rebase前的分支状态, 你可以做: (my-branch)$ git rebase --abort ","date":"2022-03-24","objectID":"/git3/:5:5","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"Stash ","date":"2022-03-24","objectID":"/git3/:6:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"暂存所有改动 暂存你工作目录下的所有改动 $ git stash 你可以使用-u来排除一些文件 $ git stash -u ","date":"2022-03-24","objectID":"/git3/:6:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"暂存指定文件 假设你只想暂存某一个文件 $ git stash push working-directory-path/filename.ext 假设你想暂存多个文件 $ git stash push working-directory-path/filename1.ext working-directory-path/filename2.ext ","date":"2022-03-24","objectID":"/git3/:6:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"暂存时记录消息 这样你可以在list时看到它 $ git stash save \u003cmessage\u003e 或 $ git stash push -m \u003cmessage\u003e ","date":"2022-03-24","objectID":"/git3/:6:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"使用某个指定暂存 首先你可以查看你的stash记录 $ git stash list 然后你可以apply某个stash $ git stash apply \"stash@{n}\" 此处， ’n’是stash在栈中的位置，最上层的stash会是0 除此之外，也可以使用时间标记(假如你能记得的话)。 $ git stash apply \"stash@{2.hours.ago}\" ","date":"2022-03-24","objectID":"/git3/:6:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"暂存时保留未暂存的内容 你需要手动create一个stash commit， 然后使用git stash store。 $ git stash create $ git stash store -m \"commit-message\" CREATED_SHA1 ","date":"2022-03-24","objectID":"/git3/:6:5","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"杂项(Miscellaneous Objects) ","date":"2022-03-24","objectID":"/git3/:7:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"克隆所有子模块 $ git clone --recursive git://github.com/foo/bar.git 如果已经克隆了: $ git submodule update --init --recursive ","date":"2022-03-24","objectID":"/git3/:7:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"删除标签(tag) $ git tag -d \u003ctag_name\u003e $ git push \u003cremote\u003e :refs/tags/\u003ctag_name\u003e ","date":"2022-03-24","objectID":"/git3/:7:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"恢复已删除标签(tag) 如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag): $ git fsck --unreachable | grep tag 记下这个标签(tag)的hash，然后用Git的 update-ref: $ git update-ref refs/tags/\u003ctag_name\u003e \u003chash\u003e 这时你的标签(tag)应该已经恢复了。 ","date":"2022-03-24","objectID":"/git3/:7:3","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"已删除补丁(patch) 如果某人在 GitHub 上给你发了一个pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。 做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的pull request。 ","date":"2022-03-24","objectID":"/git3/:7:4","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"跟踪文件(Tracking Files) ","date":"2022-03-24","objectID":"/git3/:8:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我只想改变一个文件名字的大小写，而不修改内容 (main)$ git mv --force myfile MyFile ","date":"2022-03-24","objectID":"/git3/:8:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想从Git删除一个文件，但保留该文件 (main)$ git rm --cached log.txt ","date":"2022-03-24","objectID":"/git3/:8:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"配置(Configuration) ","date":"2022-03-24","objectID":"/git3/:9:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想给一些Git命令添加别名(alias) 在 OS X 和 Linux 下, 你的 Git的配置文件储存在 ~/.gitconfig。我在[alias] 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下: [alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @{u} s = status unpushed = log @{u} wc = whatchanged wip = rebase -i @{u} zap = fetch -p ","date":"2022-03-24","objectID":"/git3/:9:1","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我想缓存一个仓库(repository)的用户名和密码 你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper能帮你。 $ git config --global credential.helper cache # Set git to use the credential memory cache $ git config --global credential.helper 'cache --timeout=3600' # Set the cache to timeout after 1 hour (setting is in seconds) ","date":"2022-03-24","objectID":"/git3/:9:2","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"我不知道我做错了些什么 你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。 这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次HEAD的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。 (main)$ git reflog 0a2e358 HEAD@{0}: reset: moving to HEAD~2 0254ea7 HEAD@{1}: checkout: moving from 2.2 to main c10f740 HEAD@{2}: checkout: moving from main to 2.2 上面的reflog展示了从main分支签出(checkout)到2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识. 如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前main上指向的提交(0254ea7)。 $ git reset --hard 0254ea7 然后使用git reset就可以把main改回到之前的commit，这提供了一个在历史被意外更改情况下的安全网。 (摘自). 其它资源(Other Resources) ","date":"2022-03-24","objectID":"/git3/:10:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"书(Books) Pro Git - Scott Chacon’s excellent git book Git Internals - Scott Chacon’s other excellent git book ","date":"2022-03-24","objectID":"/git3/:11:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"教程(Tutorials) Learn Git branching 一个基于网页的交互式 branching/merging/rebasing 教程 Getting solid at Git rebase vs. merge git-workflow - Aaron Meurer的怎么使用Git为开源仓库贡献 GitHub as a workflow - 使用GitHub做为工作流的趣事, 尤其是空PRs ","date":"2022-03-24","objectID":"/git3/:12:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"脚本和工具(Scripts and Tools) firstaidgit.io 一个可搜索的最常被问到的Git的问题 git-extra-commands - 一堆有用的额外的Git脚本 git-extras - GIT 工具集 – repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git小提示 git-town - 通用，高级Git工作流支持！ http://www.git-town.com ","date":"2022-03-24","objectID":"/git3/:13:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["gitlab"],"content":"GUI客户端(GUI Clients) GitKraken - 豪华的Git客户端 Windows, Mac \u0026 Linux git-cola - 另外一个Git客户端 Windows \u0026 OS X GitUp - 一个新的Git客户端，在处理Git的复杂性上有自己的特点 gitx-dev - 图形化的Git客户端 OS X Source Tree - 免费的图形化Git客户端 Windows \u0026 OS X Tower - 图形化Git客户端 OS X(付费) ","date":"2022-03-24","objectID":"/git3/:14:0","tags":["gitlab"],"title":"Git 规则","uri":"/git3/"},{"categories":["work"],"content":"shell脚本之变量 ","date":"2022-03-20","objectID":"/shell1/:0:0","tags":["work"],"title":"shell 脚本（1）","uri":"/shell1/"},{"categories":["work"],"content":"变量替换 语法 说明 ${变量名#匹配规则} 从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则} 从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则} 从变量尾部进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则} 从变量尾部进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串} 变量内容符合旧字符串则，则第一个旧字符串会被新字符串取代 ${变量名//旧字符串/新字符串} 变量内容符合旧字符串则，则全部的旧字符串会被新字符串取代 ","date":"2022-03-20","objectID":"/shell1/:1:0","tags":["work"],"title":"shell 脚本（1）","uri":"/shell1/"},{"categories":["work"],"content":"字符串处理 计算字符串长度 - 语法 说明 方法一 ${#string} 无 方法二 expr length “$string” string有空格，则必须加双引号 获取子串在字符串中的索引位置 语法： expr index $string $substring 计算子串长度 语法： expr match $string substr 抽取子串 ${string:position} ：从string中的position开始 ${string:position:length}：从position开始，匹配长度为length ${string:-position}：从右边开始匹配 ${string:(position)}：从左边开始匹配 expr substr $string $position $length：从position开始，匹配长度为length ","date":"2022-03-20","objectID":"/shell1/:2:0","tags":["work"],"title":"shell 脚本（1）","uri":"/shell1/"},{"categories":["k8s"],"content":"kubernetes 脚本快速安装 1、三台机器设置自己的hostname（不能是localhost） # 修改 hostname; k8s-01要变为自己的hostname hostnamectl set-hostname k8s-01 # 设置 hostname 解析 echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts 2、所有机器批量执行如下脚本 #先在所有机器执行 vi k8s.sh # 进入编辑模式（输入i），把如下脚本复制 # 所有机器给脚本权限 chmod +x k8s.sh #执行脚本 ./k8s.sh #/bin/sh #######################开始设置环境##################################### \\n printf \"##################正在配置所有基础环境信息################## \\n\" printf \"##################关闭selinux################## \\n\" sed -i 's/enforcing/disabled/' /etc/selinux/config setenforce 0 printf \"##################关闭swap################## \\n\" swapoff -a sed -ri 's/.*swap.*/#\u0026/' /etc/fstab printf \"##################配置路由转发################## \\n\" cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF echo 'net.ipv4.ip_forward = 1' \u003e\u003e /etc/sysctl.d/k8s.conf ## 必须 ipv6流量桥接 echo 'net.bridge.bridge-nf-call-ip6tables = 1' \u003e\u003e /etc/sysctl.d/k8s.conf ## 必须 ipv4流量桥接 echo 'net.bridge.bridge-nf-call-iptables = 1' \u003e\u003e /etc/sysctl.d/k8s.conf echo \"net.ipv6.conf.all.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.d/k8s.conf echo \"net.ipv6.conf.default.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.d/k8s.conf echo \"net.ipv6.conf.lo.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.d/k8s.conf echo \"net.ipv6.conf.all.forwarding = 1\" \u003e\u003e /etc/sysctl.d/k8s.conf modprobe br_netfilter sudo sysctl --system printf \"##################配置ipvs################## \\n\" cat \u003c\u003cEOF | sudo tee /etc/sysconfig/modules/ipvs.modules #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF chmod 755 /etc/sysconfig/modules/ipvs.modules sh /etc/sysconfig/modules/ipvs.modules printf \"##################安装ipvsadm相关软件################## \\n\" yum install -y ipset ipvsadm printf \"##################安装docker容器环境################## \\n\" sudo yum remove docker* sudo yum install -y yum-utils sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install -y docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io systemctl enable docker systemctl start docker sudo systemctl daemon-reload sudo systemctl restart docker printf \"##################安装k8s核心包 kubeadm kubelet kubectl################## \\n\" cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF ###指定k8s安装版本 yum install -y kubelet-1.21.0 kubeadm-1.21.0 kubectl-1.21.0 ###要把kubelet立即启动。 systemctl enable kubelet systemctl start kubelet printf \"##################下载api-server等核心镜像################## \\n\" sudo tee ./images.sh \u003c\u003c-'EOF' #!/bin/bash docker pull k8s.gcr.io/kube-apiserver:v1.21.9 docker pull k8s.gcr.io/kube-controller-manager:v1.21.9 docker pull k8s.gcr.io/kube-scheduler:v1.21.9 docker pull k8s.gcr.io/kube-proxy:v1.21.9 docker pull k8s.gcr.io/pause:3.4.1 docker pull k8s.gcr.io/etcd:3.4.13-0 docker pull k8s.gcr.io/coredns/coredns:v1.8.0 EOF chmod +x ./images.sh \u0026\u0026 ./images.sh ### k8s的所有基本环境全部完成 3、使用kubeadm引导集群（参照初始化master继续做） #### --apiserver-advertise-address 的地址一定写成自己master机器的ip地址 #### 虚拟机或者其他云厂商给你的机器ip 10.96 192.168 #### 以下的只在master节点执行 kubeadm init \\ --apiserver-advertise-address=10.12.12.24 \\ --kubernetes-version v1.21.0 \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=10.124.0.0/16 4、master结束以后，按照控制台引导继续往下 ## 第一步 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ##第二步 export KUBECONFIG=/etc/kubernetes/admin.conf ##第三步 部署网络插件 kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml ##第四步，用控制台打印的kubeadm join 去其他node节点执行 kubeadm join 10.170.11.8:6443 --token cnb7x2.lzgz7mfzcjutn0nk \\ --discovery-token-ca-cert-hash sha256:00c9e977ee52632098aadb515c90076603daee94a167728110ef8086d0d5b37d ","date":"2022-03-10","objectID":"/k8s4/:0:0","tags":["k8s"],"title":"kubernetes 脚本快速安装","uri":"/k8s4/"},{"categories":["k8s"],"content":"初始化worker节点（worker执行） ##过期怎么办 kubeadm token create --print-join-command kubeadm join --token y1eyw5.ylg568kvohfdsfco --discovery-token-ca-cert-hash sha256: 6c35e4f73f72afd89bf1c8c303ee55677d2cdb1342d67bb23c852aba2efc7c73 5、验证集群 #等一会，在master节点执行 kubectl get nodes 6、设置kube-proxy的ipvs模式 ##修改kube-proxy默认的配置 kubectl edit cm kube-proxy -n kube-system ## 修改mode: \"ipvs\" ##改完以后重启kube-proxy ### 查到所有的kube-proxy kubectl get pod -n kube-system |grep kube-proxy ### 删除之前的即可 kubectl delete pod 【用自己查出来的kube-proxy-dw5sf kube-proxy-hsrwp kube-proxy-vqv7n】 -n kube-system ### ","date":"2022-03-10","objectID":"/k8s4/:1:0","tags":["k8s"],"title":"kubernetes 脚本快速安装","uri":"/k8s4/"},{"categories":["work"],"content":"Maven 安装编译 Maven就是专门为Java项目打造的管理和构建工具，它的主要功能有： 提供了一套标准化的项目结构； 提供了一套标准化的构建流程（编译，测试，打包，发布……）； 提供了一套依赖管理机制。 默认结构： a-maven-project ├── pom.xml ├── src │ ├── main │ │ ├── java │ │ └── resources │ └── test │ ├── java │ └── resources └── target 项目的根目录a-maven-project是项目名， 它有一个项目描述文件pom.xml， 存放Java源码的目录是src/main/java， 存放资源文件的目录是src/main/resources， 存放测试源码的目录是src/test/java， 存放测试资源的目录是src/test/resources， 最后，所有编译、打包生成的文件都放在target目录里。 这些就是一个Maven项目的标准目录结构。 pom.xml文件: \u003cproject ...\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003ecom.itranswarp.learnjava\u003c/groupId\u003e \u003cartifactId\u003ehello\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003cpackaging\u003ejar\u003c/packaging\u003e \u003cproperties\u003e ... \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-logging\u003c/groupId\u003e \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e \u003cversion\u003e1.2\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e groupId类似于Java的包名，通常是公司或组织名称， artifactId类似于Java的类名，通常是项目名称， version，一个Maven工程就是由groupId，artifactId和version作为唯一标识。 我们在引用其他第三方库的时候，也是通过这3个变量确定。 依赖commons-logging： \u003cdependency\u003e \u003cgroupId\u003ecommons-logging\u003c/groupId\u003e \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e \u003cversion\u003e1.2\u003c/version\u003e \u003c/dependency\u003e 使用\u003cdependency\u003e声明一个依赖后，Maven就会自动下载这个依赖包并把它放到classpath中。 ","date":"2022-03-03","objectID":"/maven/:0:0","tags":["work"],"title":"Maven 安装编译","uri":"/maven/"},{"categories":["work"],"content":"安装Maven ","date":"2022-03-03","objectID":"/maven/:1:0","tags":["work"],"title":"Maven 安装编译","uri":"/maven/"},{"categories":["work"],"content":"Nodejs 安装编译 Node.js平台是在后端运行JavaScript代码，必须首先在本机安装Node环境。 ","date":"2022-03-03","objectID":"/nodejs/:0:0","tags":["work"],"title":"Nodejs 安装编译","uri":"/nodejs/"},{"categories":["work"],"content":"安装Node.js ","date":"2022-03-03","objectID":"/nodejs/:1:0","tags":["work"],"title":"Nodejs 安装编译","uri":"/nodejs/"},{"categories":["work"],"content":"安装npm npm其实是Node.js的包管理工具（package manager）。 ","date":"2022-03-03","objectID":"/nodejs/:2:0","tags":["work"],"title":"Nodejs 安装编译","uri":"/nodejs/"},{"categories":["gitlab"],"content":"git版本控制 ","date":"2022-02-28","objectID":"/git2/:0:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"版本回退 ","date":"2022-02-28","objectID":"/git2/:1:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"1.查看git提交历史 #查看git提交历史 git log 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数 git log --pretty=oneline ","date":"2022-02-28","objectID":"/git2/:1:1","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"2.回退到上一个版本 Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，也就是最新的提交b534d741..（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100 git reset --hard HEAD^ 最新的那个版本已经看不到了，可以顺着往上找，找到那个版本的ID git reset --hard c8275ca Git在内部有个指向当前版本的HEAD指针,当你回退版本的时候，Git仅仅是把HEAD从指向update ┌────┐ │HEAD│ └────┘ │ └──\u003e ○ update │ ○ Create README.md │ ○ init 改为指向Create README.md： ┌────┐ │HEAD│ └────┘ │ │ ○ update │ │ └──\u003e ○ Create README.md │ ○ init 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？ 在Git中，总是有后悔药可以吃的。当你用$ git reset --hard HEAD^回退到Create README.md版本时，再想恢复到update，就必须找到update的commit id。Git提供了一个命令git reflog用来记录你的每一次命令： git reflog ","date":"2022-02-28","objectID":"/git2/:1:2","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"3.总结一下： HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id。 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。 要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 ","date":"2022-02-28","objectID":"/git2/:1:3","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"工作区和暂存区 工作区（Working Directory） 就是你在电脑里能看到的目录，比如我的shell文件夹就是一个工作区 版本库（Repository） 工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 ","date":"2022-02-28","objectID":"/git2/:2:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"管理修改 那怎么提交第二次修改呢？你可以继续git add再git commit，也可以别着急提交第一次修改，先git add第二次修改，再git commit，就相当于把两次修改合并后一块提交了： 第一次修改 -\u003e git add -\u003e 第二次修改 -\u003e git add -\u003e git commit 现在，你又理解了Git是如何跟踪修改的，每次修改，如果不用git add到暂存区，那就不会加入到commit中。 ","date":"2022-02-28","objectID":"/git2/:3:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"撤销修改 git checkout -- file可以丢弃工作区的修改 git checkout -- readme.txt 命令git checkout -- readme.txt意思就是，把readme.txt文件在工作区的修改全部撤销，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 git checkout -- file命令中的--很重要，没有--，就变成了“切换到另一个分支”的命令，我们在后面的分支管理中会再次遇到git checkout命令。 ","date":"2022-02-28","objectID":"/git2/:4:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["gitlab"],"content":"删除文件 ","date":"2022-02-28","objectID":"/git2/:5:0","tags":["gitlab"],"title":"git版本控制","uri":"/git2/"},{"categories":["基础"],"content":"Linux crontab 命令 Linux crontab是用来定期执行程序的命令。 系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 ","date":"2022-02-22","objectID":"/crontab/:0:0","tags":["运维"],"title":"Linux crontab 命令","uri":"/crontab/"},{"categories":["基础"],"content":"语法 crontab [ -u user ] file crontab [ -u user ] { -l | -r | -e } 说明： crontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。 -u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。 参数说明： -e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe) -r : 删除目前的时程表 -l : 列出目前的时程表 时间格式如下： f1 f2 f3 f4 f5 program * * * * * - - - - - | | | | | | | | | +----- 星期中星期几 (0 - 6) (星期天 为0) | | | +---------- 月份 (1 - 12) | | +--------------- 一个月中的第几天 (1 - 31) | +-------------------- 小时 (0 - 23) +------------------------- 分钟 (0 - 59) 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,... 时表示第 a, b, c,... 分钟要执行，f2 为 a, b, c,... 时表示第 a, b, c...个小时要执行，其馀类推 ","date":"2022-02-22","objectID":"/crontab/:1:0","tags":["运维"],"title":"Linux crontab 命令","uri":"/crontab/"},{"categories":["日常"],"content":"linux 网络测速 ","date":"2022-02-22","objectID":"/bench/:0:0","tags":["javascript"],"title":"linux 网络测速","uri":"/bench/"},{"categories":["日常"],"content":"一键测试脚本bench.sh 适用于各种 Linux 发行版的网络（下行）和 IO 测试： 显示当前测试的各种系统信息 取自世界多处的知名数据中心的测试点，下载测试比较全面 支持 IPv6 下载测速 IO 测试三次，并显示平均值 wget -qO- bench.sh | bash #或者下面这命令下载执行 curl -Lso- bench.sh | bash ","date":"2022-02-22","objectID":"/bench/:1:0","tags":["javascript"],"title":"linux 网络测速","uri":"/bench/"},{"categories":["docker"],"content":"docker 命令(2) ","date":"2022-02-18","objectID":"/docker02/:0:0","tags":["docker"],"title":"docker 命令(2)","uri":"/docker02/"},{"categories":["docker"],"content":"docker ps 命令 docker ps 能查看所有运行中的容器 docker ps -a 能查看所有的容器 docker rm -f $(docker ps -aq) 强制删除所有容器 ","date":"2022-02-18","objectID":"/docker02/:1:0","tags":["docker"],"title":"docker 命令(2)","uri":"/docker02/"},{"categories":["docker"],"content":"docker run和docker create有什么区别 docker create命令能够基于镜像创建容器。 该命令执行的效果类似于docker run -d，即创建一个将在系统后台运行的容器。 但是与docker run -d不同的是，docker create创建的容器并未实际启动，还需要执行docker start命令或docker run命令以启动容器。 事实上，docker create命令常用于在启动容器之前进行必要的设置。 ","date":"2022-02-18","objectID":"/docker02/:2:0","tags":["docker"],"title":"docker 命令(2)","uri":"/docker02/"},{"categories":["gitlab"],"content":"CICD 概念 DevOps Devlopment和Operation的组合词 规划-》代码-》构建-》测试-》发布-》部署-》运营-》监控-》再次规划 devOps看作开发（软件工程）、技术运营和质量保障（QA）三者的交集 突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗。更加高效的协同工作。良好的闭环可以大大增加整体的产出。 CICD 持续集成 持续部署 持续集成 持续集成是指软件个人研发的部分向软件整体部分交付，频繁进行集成以便更快地发现其中的错误。“持续集成”源自于极限编程（XP），是12最初的12种实践之一 Ci需要具备这些： 全面的自动化测试，这是实践持续集成和持续部署的基础，同时，选择合适的自动化测试工具也极其重要； 灵活的基础设施。容器，虚拟化的存在让开发人员和QA不必再大费周折 版本控制工具。如git，cvs，svn等 自动化的构建和软件发布流程工具，如 Jenkins，flow.ci; 反馈机制，如构建/测试的失败，可以快速地反馈到相关负责人，以尽快解决达到一个更稳定的版本。 ","date":"2022-02-17","objectID":"/devops/:0:0","tags":["gitlab"],"title":"CICD 概念","uri":"/devops/"},{"categories":["gitlab"],"content":"git使用方法 ","date":"2022-02-17","objectID":"/git/:0:0","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"一、git安装配置 Debian/Ubuntu apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev apt-get install git git --version git version 1.8.1.2 Centos/RedHat yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel yum -y install git-core git --version git version 1.7.1 ","date":"2022-02-17","objectID":"/git/:1:0","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"二、git拉取异常如何重新拉取 ","date":"2022-02-17","objectID":"/git/:2:0","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"1.同一文件有修改，产生冲突。 先将本地修改存储起来 使用git stash命令，这样本地的所有修改就都被暂时存储起来 。其中stash@{0}就是刚才保存的标记。后续可以通过此标记访问。 再次拉取代码 git pull 还原暂存的内容 git stash pop stash@{0} 解决冲突 在存在冲突的文件中，Updated upstream 和=====之间的内容为拉取下来的代码，=====和stashed changes之间的内容就为本地修改的代码。解决完成之后，就可以正常的提交了。 5.删除stash 使用git stash drop stash@{0}命令，如果不加stash编号，默认的就是删除最新的，即编号为0的。或者git stash clear命令，清除所有stash。 ","date":"2022-02-17","objectID":"/git/:2:1","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"2.想要让某一个文件放弃修改，同步服务器。 git checkout [本地变动文件的路径] ","date":"2022-02-17","objectID":"/git/:2:2","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"3.服务器代码完全替换和覆盖本地的代码改动。 git fetch --all git reset --hard origin/master git pull ","date":"2022-02-17","objectID":"/git/:2:3","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"三、git命令表格 专用名词 含义 Workspace 工作区 Index/Stage 暂存区 Repository 仓库区（或本地仓库） Remote 远程仓库 ","date":"2022-02-17","objectID":"/git/:3:0","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"1.新建代码仓库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] ","date":"2022-02-17","objectID":"/git/:3:1","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"2.配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" ","date":"2022-02-17","objectID":"/git/:3:2","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"3.增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] ","date":"2022-02-17","objectID":"/git/:3:3","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"4.代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... ","date":"2022-02-17","objectID":"/git/:3:4","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"5.分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] ","date":"2022-02-17","objectID":"/git/:3:5","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"6.标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] ","date":"2022-02-17","objectID":"/git/:3:6","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"7.查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\" # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog ","date":"2022-02-17","objectID":"/git/:3:7","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all ","date":"2022-02-17","objectID":"/git/:3:8","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop ","date":"2022-02-17","objectID":"/git/:3:9","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["gitlab"],"content":"其他 # 生成一个可供发布的压缩包 $ git archive ","date":"2022-02-17","objectID":"/git/:3:10","tags":["gitlab"],"title":"git使用方法","uri":"/git/"},{"categories":["k8s"],"content":"kubernetes面试题汇总 ","date":"2022-02-16","objectID":"/k8s3/:0:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"1、 k8s是什么？请说出你的了解？ 答：Kubenetes是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。 K8S是Google公司推出的，它来源于由Google公司内部使用了15年的Borg系统，集结了Borg的精华。 ","date":"2022-02-16","objectID":"/k8s3/:1:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"2、 K8s架构的组成是什么？ 答：和大多数分布式系统一样，K8S集群至少需要一个主节点（Master）和多个计算节点（Node）。 主节点主要用于暴露API，调度部署和节点的管理； 计算节点运行一个容器运行环境，一般是docker环境（类似docker环境的还有rkt），同时运行一个K8s的代理（kubelet）用于和master通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是k8s集群中真正工作的节点。 K8S架构细分： 1、Master节点（默认不参加实际工作）： Kubectl：客户端命令行工具，作为整个K8s集群的操作入口； Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件； Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等； Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上； Etcd：担任数据中心的角色，保存了整个群集的状态； 2、Node节点： Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）； Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务时，Service接收到的请求后就是通过kube-proxy来转发到pod上的）； container-runtime：是负责管理运行容器的软件，比如docker Pod：是k8s集群里面最小的单位。每个pod里边可以运行一个或多个container（容器），如果一个pod中有两个container，那么container的USR（用户）、MNT（挂载点）、PID（进程号）是相互隔离的，UTS（主机名和域名）、IPC（消息队列）、NET（网络栈）是相互共享的。我比较喜欢把pod来当做豌豆夹，而豌豆就是pod中的container； ","date":"2022-02-16","objectID":"/k8s3/:2:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"3、 容器和主机部署应用的区别是什么？ 答：容器的中心思想就是秒级启动；一次封装、到处运行；这是主机部署应用无法达到的效果，但同时也更应该注重容器的数据持久化问题。 另外，容器部署可以将各个服务进行隔离，互不影响，这也是容器的另一个核心概念。 ","date":"2022-02-16","objectID":"/k8s3/:3:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"4、请你说一下kubenetes针对pod资源对象的健康监测机制？ 答：K8s中对于pod资源对象的健康状态检测，提供了三类probe（探针）来执行对pod的健康监测： livenessProbe探针 可以根据用户自定义规则来判定pod是否健康，如果livenessProbe探针探测到容器不健康，则kubelet会根据其重启策略来决定是否重启，如果一个容器不包含livenessProbe探针，则kubelet会认为容器的livenessProbe探针的返回值永远成功。 ReadinessProbe探针 同样是可以根据用户自定义规则来判断pod是否健康，如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功。 startupProbe探针 启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可。 每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间： initialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败 periodSeconds：检查间隔，多久执行probe检查，默认为10s； timeoutSeconds：检查超时时长，探测应用timeout后为失败； successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。 ","date":"2022-02-16","objectID":"/k8s3/:4:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"上面两种探针都支持以下三种探测方法： Exec：通过执行命令的方式来检查服务是否正常，比如使用cat命令查看pod中的某个重要配置文件是否存在，若存在，则表示pod健康。反之异常。 Exec探测方式的yaml文件语法如下： spec: containers: - name: liveness image: k8s.gcr.io/busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: #选择livenessProbe的探测机制 exec: #执行以下命令 command: - cat - /tmp/healthy initialDelaySeconds: 5 #在容器运行五秒后开始探测 periodSeconds: 5 #每次探测的时间间隔为5秒 在上面的配置文件中，探测机制为在容器运行5秒后，每隔五秒探测一次，如果cat命令返回的值为“0”，则表示健康，如果为非0，则表示异常。 Httpget：通过发送http/htps请求检查服务是否正常，返回的状态码为200-399则表示容器健康（注http get类似于命令curl -I）。 Httpget探测方式的yaml文件语法如下： spec: containers: - name: liveness image: k8s.gcr.io/liveness livenessProbe: #采用livenessProbe机制探测 httpGet: #采用httpget的方式 scheme:HTTP #指定协议，也支持https path: /healthz #检测是否可以访问到网页根目录下的healthz网页文件 port: 8080 #监听端口是8080 initialDelaySeconds: 3 #容器运行3秒后开始探测 periodSeconds: 3 #探测频率为3秒 上述配置文件中，探测方式为项容器发送HTTP GET请求，请求的是8080端口下的healthz文件，返回任何大于或等于200且小于400的状态码表示成功。任何其他代码表示异常。 tcpSocket：通过容器的IP和Port执行TCP检查，如果能够建立TCP连接，则表明容器健康，这种方式与HTTPget的探测机制有些类似，tcpsocket健康检查适用于TCP业务。 tcpSocket探测方式的yaml文件语法如下： spec: containers: - name: goproxy image: k8s.gcr.io/goproxy:0.1 ports: - containerPort: 8080 #这里两种探测机制都用上了，都是为了和容器的8080端口建立TCP连接 readinessProbe: tcpSocket: port: 8080 initialDelaySeconds: 5 periodSeconds: 10 livenessProbe: tcpSocket: port: 8080 initialDelaySeconds: 15 periodSeconds: 20 在上述的yaml配置文件中，两类探针都使用了，在容器启动5秒后，kubelet将发送第一个readinessProbe探针，这将连接容器的8080端口，如果探测成功，则该pod为健康，十秒后，kubelet将进行第二次连接。 除了readinessProbe探针外，在容器启动15秒后，kubelet将发送第一个livenessProbe探针，仍然尝试连接容器的8080端口，如果连接失败，则重启容器。 探针探测的结果无外乎以下三者之一： Success：Container通过了检查； Failure：Container没有通过检查； Unknown：没有执行检查，因此不采取任何措施（通常是我们没有定义探针检测，默认为成功）。 若觉得上面还不够透彻，可以移步其官网文档：https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/ ","date":"2022-02-16","objectID":"/k8s3/:5:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"5、 如何控制滚动更新过程？ 答： 可以通过下面的命令查看到更新时可以控制的参数： [root@master yaml]# kubectl explain deploy.spec.strategy.rollingUpdate maxSurge ：此参数控制滚动更新过程，副本总数超过预期pod数量的上限。可以是百分比，也可以是具体的值。默认为1。 （上述参数的作用就是在更新过程中，值若为3，那么不管三七二一，先运行三个pod，用于替换旧的pod，以此类推） maxUnavailable：此参数控制滚动更新过程中，不可用的Pod的数量。 （这个值和上面的值没有任何关系，举个例子：我有十个pod，但是在更新的过程中，我允许这十个pod中最多有三个不可用，那么就将这个参数的值设置为3，在更新的过程中，只要不可用的pod数量小于或等于3，那么更新过程就不会停止）。 ","date":"2022-02-16","objectID":"/k8s3/:6:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"6、K8s中镜像的下载策略是什么？ 答：可通过命令“kubectl explain pod.spec.containers”来查看imagePullPolicy这行的解释。 K8s的镜像下载策略有三种：Always、Never、IFNotPresent； Always：镜像标签为latest时，总是从指定的仓库中获取镜像； Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像； IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。 默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。 ","date":"2022-02-16","objectID":"/k8s3/:7:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"7、 image的状态有哪些？ Running：Pod所需的容器已经被成功调度到某个节点，且已经成功运行， Pending：APIserver创建了pod资源对象，并且已经存入etcd中，但它尚未被调度完成或者仍然处于仓库中下载镜像的过程 Unknown：APIserver无法正常获取到pod对象的状态，通常是其无法与所在工作节点的kubelet通信所致。 ","date":"2022-02-16","objectID":"/k8s3/:8:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"8、 pod的重启策略是什么？ 答：可以通过命令“kubectl explain pod.spec”查看pod的重启策略。（restartPolicy字段） Always：但凡pod对象终止就重启，此为默认策略。 OnFailure：仅在pod对象出现错误时才重启 ","date":"2022-02-16","objectID":"/k8s3/:9:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"9、 Service这种资源对象的作用是什么？ 答：用来给相同的多个pod对象提供一个固定的统一访问接口，常用于服务发现和服务访问。 ","date":"2022-02-16","objectID":"/k8s3/:10:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"10、版本回滚相关的命令？ [root@master httpd-web]# kubectl apply -f httpd2-deploy1.yaml --record #运行yaml文件，并记录版本信息； [root@master httpd-web]# kubectl rollout history deployment httpd-devploy1 #查看该deployment的历史版本 [root@master httpd-web]# kubectl rollout undo deployment httpd-devploy1 --to-revision=1 #执行回滚操作，指定回滚到版本1 #在yaml文件的spec字段中，可以写以下选项（用于限制最多记录多少个历史版本）： spec: revisionHistoryLimit: 5 #这个字段通过 kubectl explain deploy.spec 命令找到revisionHistoryLimit \u003cinteger\u003e行获得 ","date":"2022-02-16","objectID":"/k8s3/:11:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"11、 标签与标签选择器的作用是什么？ 标签：是当相同类型的资源对象越来越多的时候，为了更好的管理，可以按照标签将其分为一个组，为的是提升资源对象的管理效率。 标签选择器：就是标签的查询过滤条件。目前API支持两种标签选择器： 基于等值关系的，如：“=”、“”“==”、“！=”（注：“==”也是等于的意思，yaml文件中的matchLabels字段）； 基于集合的，如：in、notin、exists（yaml文件中的matchExpressions字段）； 注：in:在这个集合中；notin：不在这个集合中；exists：要么全在（exists）这个集合中，要么都不在（notexists）； 使用标签选择器的操作逻辑： 在使用基于集合的标签选择器同时指定多个选择器之间的逻辑关系为“与”操作（比如：- {key: name,operator: In,values: [zhangsan,lisi]} ，那么只要拥有这两个值的资源，都会被选中）； 使用空值的标签选择器，意味着每个资源对象都被选中（如：标签选择器的键是“A”，两个资源对象同时拥有A这个键，但是值不一样，这种情况下，如果使用空值的标签选择器，那么将同时选中这两个资源对象） 空的标签选择器（注意不是上面说的空值，而是空的，都没有定义键的名称），将无法选择出任何资源； 在基于集合的选择器中，使用“In”或者“Notin”操作时，其values可以为空，但是如果为空，这个标签选择器，就没有任何意义了。 两种标签选择器类型（基于等值、基于集合的书写方法）： selector: matchLabels: #基于等值 app: nginx matchExpressions: #基于集合 - {key: name,operator: In,values: [zhangsan,lisi]} #key、operator、values这三个字段是固定的 - {key: age,operator: Exists,values:} #如果指定为exists，那么values的值一定要为空 ","date":"2022-02-16","objectID":"/k8s3/:12:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"12、 常用的标签分类有哪些？ 标签分类是可以自定义的，但是为了能使他人可以达到一目了然的效果，一般会使用以下一些分类： 版本类标签（release）：stable（稳定版）、canary（金丝雀版本，可以将其称之为测试版中的测试版）、beta（测试版）； 环境类标签（environment）：dev（开发）、qa（测试）、production（生产）、op（运维）； 应用类（app）：ui、as、pc、sc； 架构类（tier）：frontend（前端）、backend（后端）、cache（缓存）； 分区标签（partition）：customerA（客户A）、customerB（客户B）； 品控级别（Track）：daily（每天）、weekly（每周）。 ","date":"2022-02-16","objectID":"/k8s3/:13:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"13、 有几种查看标签的方式？ 答：常用的有以下三种查看方式： [root@master ~]# kubectl get pod --show-labels #查看pod，并且显示标签内容 [root@master ~]# kubectl get pod -L env,tier #显示资源对象标签的值 [root@master ~]# kubectl get pod -l env,tier #只显示符合键值资源对象的pod，而“-L”是显示所有的pod ","date":"2022-02-16","objectID":"/k8s3/:14:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"14、 添加、修改、删除标签的命令？ #对pod标签的操作 [root@master ~]# kubectl label pod label-pod abc=123 #给名为label-pod的pod添加标签 [root@master ~]# kubectl label pod label-pod abc=456 --overwrite #修改名为label-pod的标签 [root@master ~]# kubectl label pod label-pod abc- #删除名为label-pod的标签 [root@master ~]# kubectl get pod --show-labels #对node节点的标签操作 [root@master ~]# kubectl label nodes node01 disk=ssd #给节点node01添加disk标签 [root@master ~]# kubectl label nodes node01 disk=sss –overwrite #修改节点node01的标签 [root@master ~]# kubectl label nodes node01 disk- #删除节点node01的disk标签 ","date":"2022-02-16","objectID":"/k8s3/:15:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"15、 DaemonSet资源对象的特性？ DaemonSet这种资源对象会在每个k8s集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。所以，在其yaml文件中，不支持定义replicas，除此之外，与Deployment、RS等资源对象的写法相同。 它的一般使用场景如下： 在去做每个节点的日志收集工作； 监控每个节点的的运行状态； ","date":"2022-02-16","objectID":"/k8s3/:16:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"16、 说说你对Job这种资源对象的了解？ 答：Job与其他服务类容器不同，Job是一种工作类容器（一般用于做一次性任务）。使用常见不多，可以忽略这个问题。 #提高Job执行效率的方法： spec: parallelism: 2 #一次运行2个 completions: 8 #最多运行8个 template: metadata: ","date":"2022-02-16","objectID":"/k8s3/:17:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"17、描述一下pod的生命周期有哪些状态？ Pending：表示pod已经被同意创建，正在等待kube-scheduler选择合适的节点创建，一般是在准备镜像； Running：表示pod中所有的容器已经被创建，并且至少有一个容器正在运行或者是正在启动或者是正在重启； Succeeded：表示所有容器已经成功终止，并且不会再启动； Failed：表示pod中所有容器都是非0（不正常）状态退出； Unknown：表示无法读取Pod状态，通常是kube-controller-manager无法与Pod通信。 ","date":"2022-02-16","objectID":"/k8s3/:18:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"18、 创建一个pod的流程是什么？ 答： 1） 客户端提交Pod的配置信息（可以是yaml文件定义好的信息）到kube-apiserver； 2） Apiserver收到指令后，通知给controller-manager创建一个资源对象； 3） Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中； 4） Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。 5） Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。 ","date":"2022-02-16","objectID":"/k8s3/:19:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"19、 删除一个Pod会发生什么事情？ 答：Kube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作； 关闭流程如下： 1、 pod从service的endpoint列表中被移除； 2、 如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程； 3、 进程被发送TERM信号（kill -14） 4、 当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）。 ","date":"2022-02-16","objectID":"/k8s3/:20:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"20、 K8s的Service是什么？ 答：Pod每次重启或者重新部署，其IP地址都会产生变化，这使得pod间通信和pod与外部通信变得困难，这时候，就需要Service为pod提供一个固定的入口。 Service的Endpoint列表通常绑定了一组相同配置的pod，通过负载均衡的方式把外界请求分配到多个pod上 ","date":"2022-02-16","objectID":"/k8s3/:21:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"21、 k8s是怎么进行服务注册的？ 答：Pod启动后会加载当前环境所有Service信息，以便不同Pod根据Service名进行通信。 ","date":"2022-02-16","objectID":"/k8s3/:22:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"22、 k8s集群外流量怎么访问Pod？ 答：可以通过Service的NodePort方式访问，会在所有节点监听同一个端口，比如：30000，访问节点的流量会被重定向到对应的Service上面。 ","date":"2022-02-16","objectID":"/k8s3/:23:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"23、 k8s数据持久化的方式有哪些？ 答：1）EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume。 主要使用场景： 1） 只需要临时将数据保存在磁盘上，比如在合并/排序算法中； 2） 作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由同一个webserver容器对外提供这些页面。 emptyDir的特性： 同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。如果仅仅是容器被销毁，pod还在，则不会影响volume中的数据。 总结来说：emptyDir的数据持久化的生命周期和使用的pod一致。一般是作为临时存储使用。 2）Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式。 这种数据持久化方式，运用场景不多，因为它增加了pod与节点之间的耦合。 一般对于k8s集群本身的数据持久化和docker本身的数据持久化会使用这种方式，可以自行参考apiService的yaml文件，位于：/etc/kubernetes/main…目录下。 3）PersistentVolume（简称PV）： 基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理。 在一个PV的yaml文件中，可以对其配置PV的大小， 指定PV的访问模式： ReadWriteOnce：只能以读写的方式挂载到单个节点； ReadOnlyMany：能以只读的方式挂载到多个节点； ReadWriteMany：能以读写的方式挂载到多个节点。， 以及指定pv的回收策略： recycle：清除PV的数据，然后自动回收； Retain：需要手动回收； delete：删除云存储资源，云存储专用； #PS：这里的回收策略指的是在PV被删除后，在这个PV下所存储的源文件是否删除）。 若需使用PV，那么还有一个重要的概念：PVC，PVC是向PV申请应用所需的容量大小，K8s集群中可能会有多个PV，PVC和PV若要关联，其定义的访问模式必须一致。定义的storageClassName也必须一致，若群集中存在相同的（名字、访问模式都一致）两个PV，那么PVC会选择向它所需容量接近的PV去申请，或者随机申请。 ","date":"2022-02-16","objectID":"/k8s3/:24:0","tags":["k8s"],"title":"kubernetes面试题汇总","uri":"/k8s3/"},{"categories":["k8s"],"content":"Kubernetes 安装 ","date":"2022-02-13","objectID":"/k8s2/:0:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"环境配置 ","date":"2022-02-13","objectID":"/k8s2/:1:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"关闭防火墙： 如果是云服务器，需要设置安全组策略放行端口 systemctl stop firewalld systemctl disable firewalld ","date":"2022-02-13","objectID":"/k8s2/:1:1","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"修改 hostname hostnamectl set-hostname k8s-01 echo \"127.0.0.1 $(hostname)\" \u003e\u003e /etc/hosts reboot ","date":"2022-02-13","objectID":"/k8s2/:1:2","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"关闭 selinux： sed -i 's/enforcing/disabled/' /etc/selinux/config setenforce 0 ","date":"2022-02-13","objectID":"/k8s2/:1:3","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"关闭 swap： swapoff -a sed -ri 's/.*swap.*/#\u0026/' /etc/fstab ","date":"2022-02-13","objectID":"/k8s2/:1:4","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"修改 /etc/sysctl.conf # 如果有配置，则修改 sed -i \"s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g\" /etc/sysctl.conf sed -i \"s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g\" /etc/sysctl.conf sed -i \"s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g\" /etc/sysctl.conf sed -i \"s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g\" /etc/sysctl.conf sed -i \"s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g\" /etc/sysctl.conf sed -i \"s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g\" /etc/sysctl.conf sed -i \"s#^net.ipv6.conf.all.forwarding.*#net.ipv6.conf.all.forwarding=1#g\" /etc/sysctl.conf # 可能没有，追加 echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.bridge.bridge-nf-call-ip6tables = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.bridge.bridge-nf-call-iptables = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv6.conf.all.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv6.conf.default.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv6.conf.lo.disable_ipv6 = 1\" \u003e\u003e /etc/sysctl.conf echo \"net.ipv6.conf.all.forwarding = 1\" \u003e\u003e /etc/sysctl.conf # 执行命令以应用 sysctl -p ","date":"2022-02-13","objectID":"/k8s2/:1:5","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"安装docker sudo yum remove docker* sudo yum install -y yum-utils #配置docker yum 源 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #安装docker 19.03.9 yum install -y docker-ce-3:19.03.9-3.el7.x86_64 docker-ce-cli-3:19.03.9-3.el7.x86_64 containerd.io #安装docker 19.03.9 docker-ce 19.03.9 yum install -y docker-ce-19.03.9-3 docker-ce-cli-19.03.9 containerd.io #启动服务 systemctl start docker systemctl enable docker sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2022-02-13","objectID":"/k8s2/:2:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"安装k8s核心（都执行） ","date":"2022-02-13","objectID":"/k8s2/:3:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"配置K8S的yum源 cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes]ß name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF ","date":"2022-02-13","objectID":"/k8s2/:3:1","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"卸载旧版本,安装新版本 yum remove -y kubelet kubeadm kubectl # 查看可以安装的版本 yum list kubelet --showduplicates | sort -r # 安装kubelet、kubeadm、kubectl 指定版本 yum install -y kubelet-1.21.0 kubeadm-1.21.0 kubectl-1.21.0 # 开机启动kubelet systemctl enable kubelet \u0026\u0026 systemctl start kubelet ","date":"2022-02-13","objectID":"/k8s2/:3:2","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"初始化master节点 ","date":"2022-02-13","objectID":"/k8s2/:4:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"创建images.sh,vim images.sh粘贴以下命令 docker pull k8s.gcr.io/kube-apiserver:v1.21.9 docker pull k8s.gcr.io/kube-controller-manager:v1.21.9 docker pull k8s.gcr.io/kube-scheduler:v1.21.9 docker pull k8s.gcr.io/kube-proxy:v1.21.9 docker pull k8s.gcr.io/pause:3.4.1 docker pull k8s.gcr.io/etcd:3.4.13-0 docker pull k8s.gcr.io/coredns/coredns:v1.8.0 chmod +x images.shß sh images.sh ","date":"2022-02-13","objectID":"/k8s2/:4:1","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"kubeadm init master节点 kubeadm init \\ --apiserver-advertise-address=192.168.99.19 \\ --kubernetes-version v1.23.3 \\ --service-cidr=10.99.0.0/16 \\ --pod-network-cidr=10.124.0.0/16 ","date":"2022-02-13","objectID":"/k8s2/:4:2","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"复制相关文件夹 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ","date":"2022-02-13","objectID":"/k8s2/:4:3","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"导出环境变量 export KUBECONFIG=/etc/kubernetes/admin.conf ","date":"2022-02-13","objectID":"/k8s2/:4:4","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"部署一个pod网络 kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml ","date":"2022-02-13","objectID":"/k8s2/:4:5","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"命令检查 kubectl get pod -A ##获取集群中所有部署好的应用Pod kubectl get nodes ##查看集群所有机器的状态 ","date":"2022-02-13","objectID":"/k8s2/:4:6","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"初始化worker节点（worker执行） ##过期怎么办 kubeadm token create --print-join-command kubeadm join --token y1eyw5.ylg568kvohfdsfco --discovery-token-ca-cert-hash sha256: 6c35e4f73f72afd89bf1c8c303ee55677d2cdb1342d67bb23c852aba2efc7c73 ","date":"2022-02-13","objectID":"/k8s2/:5:0","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["k8s"],"content":"验证集群 #获取所有节点 kubectl get nodes ","date":"2022-02-13","objectID":"/k8s2/:5:1","tags":["k8s"],"title":"Kubernetes 安装","uri":"/k8s2/"},{"categories":["基础"],"content":"linux 常用命令 ","date":"2022-02-12","objectID":"/linux1/:0:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"软件操作命令 #软件包管理器 yum # 安装软件 yum install xxxx # 卸载软件 yum remove xxx # 搜索软件 yum search xxx # 清理缓存 yum clean packages # 列出已安装 yum list # 软件包信息 yum info ","date":"2022-02-12","objectID":"/linux1/:1:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"服务器硬件资源和磁盘操作 # 内存 free -h # 硬盘 df -h # 负载 w/top/htop # 查看cpu cat /proc/cpuinfo # 查看磁盘 fdisk -l ","date":"2022-02-12","objectID":"/linux1/:2:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"文件和文件夹操作命令 命令 解释 ls 查看目录下的文件 touch 新建文件 mkdir 新建目录 cd 进入目录 rm 删除文件和目录 cp 复制 mv 移动 pwd 显示路径 ","date":"2022-02-12","objectID":"/linux1/:3:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"系统用户操作命令 ","date":"2022-02-12","objectID":"/linux1/:4:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"防火墙相关设置 ","date":"2022-02-12","objectID":"/linux1/:5:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"提权操作sudo和文件传输 ","date":"2022-02-12","objectID":"/linux1/:6:0","tags":["运维"],"title":"linux常用命令","uri":"/linux1/"},{"categories":["基础"],"content":"linux 基础知识 ","date":"2022-02-11","objectID":"/linux/:0:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"1、简述Linux权限划分原则。 给文件或目录分配权限时，先考虑所有者和所属组 遵循最小化权限，用啥权限给啥权限 修改目录和子文件归属权限，注意递归 文件权限分配是最常用的安全防护手段 ","date":"2022-02-11","objectID":"/linux/:1:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"2、当用户user1，对/testdir目录有写和执行权限时，该目录下的只读文件file1是否可修改和删除？ 对file1不能修改也不能删除。（如果对目录有写权限和执行权限，则对file1不能修改可以删除） ","date":"2022-02-11","objectID":"/linux/:2:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"3、如果一个系统没有任何的备份策略，请写出一个较为全面合理的备份方案！ 增量备份：将相较于前一天增加的内容备份，适合每天改变量较大的数据。 差异备份：将相较于第一天改变的内容备份，适合原始数据量比较大，但是之后改变的比较小，即使中间哪一天的丢了也没事，只要最后一天，和第一天的在就行。 ","date":"2022-02-11","objectID":"/linux/:3:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"4、网站服务器每天产生的日志数量较大，请问如何备份? 使用logrotate滚动日志 split大文件切分处理 shell脚本处理日志 ","date":"2022-02-11","objectID":"/linux/:4:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"5、简述Raid 0、Raid 1、Raid 5的特点与原理。 RAID等级 最少硬盘 最大容错 可用容量 读取性能 写入性能 安全性 目的 应用产业 单一硬盘 (参考) 0 1 1 1 无 JBOD 1 0 n 1 1 无（同RAID 0） 增加容量 个人（暂时） 0 2 0 n n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 视频剪接缓存用途 1 2 n-1 1 n 1 高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 n-1 n-1 n-1 中下至中 追求最大容量、最小预算 个人、小型企业备份 6 4 2 n-2 n-2 n-2 中至中高,仅安全性较RAID 5高 同RAID 5，但较安全 个人、企业备份 10 4 高 综合RAID 0/1优点，理论速度较快 大型数据库、服务器 50 6 高 提升资料安全 60 8 高 提升资料安全 ","date":"2022-02-11","objectID":"/linux/:5:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"6、简述Raid6、Raid 10的特点与原理。 与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于RAID 5有更大的IO操作量和计算量，其“写性能”强烈取决于具体的实现方案，因此RAID 6通常不会通过软件方式来实现，而更可能通过硬件方式实现。 RAID 10是先分割资料再镜像，再将所有硬盘分为两组，视为以RAID 1作为最低组合，然后将每组RAID 1视为一个“硬盘”组合为RAID 0运作。当RAID 10有一个硬盘受损，其余硬盘会继续运作 ","date":"2022-02-11","objectID":"/linux/:6:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"7、软Raid与硬Raid的区别？ 硬RAID：通过用硬件来实现RAID功能的就是硬RAID，比如：各种RAID卡，还有主板集成能够做的RAID都是硬RAID。 软RAID：通过用操作系统来完成RAID功能的就是软RAID，比如：在Linux操作系统下，用3块硬盘做的RAID5. ","date":"2022-02-11","objectID":"/linux/:7:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"8、Linux中有许多系统资源需要监管，请问有哪些命令可以查看？ htop 查看系统信息 free -h 查看内存 ","date":"2022-02-11","objectID":"/linux/:8:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"9、简述CentOS 6.x的启动过程？ 加电自检，得到BIOS的硬件信息，获取第一个启动设备 读取第一个启动设备MBR的引导加载程序（grub）的启动信息 加载核心操作系统的核心信息，核心开始解压缩，并尝试驱动所有的硬件设备 运行init程序 运行系统初始化脚本 /etc/rc.d/rc.sysinit 启动核心的外挂模块 init执行运行各个批处理文件 init执行/etc/rc.d/rc.local 执行/bin/login程序，等待用户登录 登陆之后，打印登陆提示符，并开始shell控制主机 ","date":"2022-02-11","objectID":"/linux/:9:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"10、简述CentOS 7.x的启动过程？ 加电后系统固件（system firmware）,也就是BIOS或者UEFI进行加电测试，初始化部分硬件设备。 系统固件寻找可启动设备。 系统固件从disk上读取boot loader，CentOS7中的boot loader是grub2，之后系统固件把控制权交给boot loader。 boot loader从硬盘装载配置文件，向用户显示一个启动选择菜单。 用户选择启动项后，boot loader从硬盘加载选定的内核（kernel）和initramfs到内存中。initramfs中包括了在启动过程中所需的所有硬件的内核模块（modules）。它的配置文件是 /etc/dracut.conf 。 boot loader把启动时传入的参数如rd.break, 还有initramfs在内存中的地址，以及系统的控制权都移交给kernel。 kernel初始化所有硬件，然后从initramfs中执行 /sbin/init 把它作为PID 1. CentOS7中的init就是systemd。 来自initramfs中的systemd执行所有initrd.target中的unit。把根文件系统 / 挂载（mount）到 /sysroot. 内核的根文件系统从initramfs切换到刚才挂载的/sysroot上后，sysroot中的systemd会重新再执行一次。 systemd执行default.target, 系统启动完成。 ","date":"2022-02-11","objectID":"/linux/:10:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"11、如何进行Linux系统优化？ 永久关闭selinux vim /etc/selinux/config 将SELINUX=enforcing改为SELINUX=disabled，保存后退出,重启生效 设定系统runlevel为3 节约系统资源 grep 3:initdefault /etc/inittab id:3:initdefault: init 3 ","date":"2022-02-11","objectID":"/linux/:11:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"12、大文件如何删除？ 查看磁盘使用情况，查看是否需要扩容 df -h 查找大文件，使用du定位大文件位置 # 在根目录查找，展示第一层级的目录和文件，倒叙排列 ，展示前10名 du -h / --max-depth=1 | sort -hr | head -n 10 删除文件 # 删除文件可以直接用rm -rf 删除 rm -rf \u003c文件或目录\u003e # 按时间和名称删除 :找到目录下，超过10天的文件 删除名字后缀为.gz的文件 find /目录/* -mtime +10 -name \"*.gz\" -exec rm -rf {} \\ ","date":"2022-02-11","objectID":"/linux/:12:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["基础"],"content":"kill 的几种格式有什么区别？ 命令 参数 -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称 -a 当处理当前进程时，不限制命令名和进程号的对应关系 -p 指定kill 命令只打印相关进程的进程号，而不发送任何信号 -s 指定发送信号 -u 指定用户 列出所有信号名称 kill -l 常用信号 信号 数字 含义 HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \\） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） kill命令可以带信号号码选项，也可以不带。如果没有信号号码，kill命令就会发出终止信号(15)，这个信号可以被进程捕获，使得进程在退出之前可以清理并释放资源。 ","date":"2022-02-11","objectID":"/linux/:13:0","tags":["运维"],"title":"linux基础知识","uri":"/linux/"},{"categories":["日常"],"content":"网心云挂机教程 | 轻松实现睡后收入~ 首先，本文章只是分享，造成一切的后果，博主概不负责！都是成年人了…… 我采用docker 容器魔方来挂载网心云 ","date":"2022-02-11","objectID":"/wxyun/:0:0","tags":["网心云","外快"],"title":"网心云挂机教程 | 轻松实现睡后收入~","uri":"/wxyun/"},{"categories":["日常"],"content":"docker 部署 /mnt/money/wxedge_storage这个路径改为自己的存储路径建议\u003e200G docker run \\ --name=wxedge \\ --restart=always \\ --privileged \\ --net=host \\ --tmpfs /run \\ --tmpfs /tmp \\ -v /mnt/money/wxedge_storage:/storage:rw \\ -d \\ registry.cn-hangzhou.aliyuncs.com/onething/wxedge ","date":"2022-02-11","objectID":"/wxyun/:1:0","tags":["网心云","外快"],"title":"网心云挂机教程 | 轻松实现睡后收入~","uri":"/wxyun/"},{"categories":["日常"],"content":"设备绑定 进入dockerip地址 （http://127.0.0.1:18888) 下载app 扫码绑定 ","date":"2022-02-11","objectID":"/wxyun/:2:0","tags":["网心云","外快"],"title":"网心云挂机教程 | 轻松实现睡后收入~","uri":"/wxyun/"},{"categories":["日常"],"content":"成功 然后坐等第二天收益到账就可以了，记得19:00-23:00是收益高峰期尽量保持在线~ ","date":"2022-02-11","objectID":"/wxyun/:3:0","tags":["网心云","外快"],"title":"网心云挂机教程 | 轻松实现睡后收入~","uri":"/wxyun/"},{"categories":["docker"],"content":"清理Docker的container，image与volume Docker的镜像（image）、容器（container）、数据卷（volume）， 都是由daemon托管的。 因此，在需要清理时，也需要使用其自带的手段。 ","date":"2022-02-10","objectID":"/docker-clean/:0:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理技巧 清理所有停止运行的容器： docker container prune # or docker rm $(docker ps -aq) 清理所有悬挂（\u003cnone\u003e）镜像： docker image prune # or docker rmi $(docker images -qf \"dangling=true\") 清理所有无用数据卷： docker volume prune 由于prune操作是批量删除类的危险操作，所以会有一次确认。 如果不想输入y\u003cCR\u003e来确认，可以添加-f操作。慎用！ ","date":"2022-02-10","objectID":"/docker-clean/:1:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理停止的容器 docker rm -lv CONTAINER -l是清理link，v是清理volume。 这里的CONTAINER是容器的name或ID，可以是一个或多个。 参数列表： Name shorthand Default Description –force,-f false Force the removal of a running container (uses SIGKILL) –link, -l false Remove the specified link –volumes, -v false ","date":"2022-02-10","objectID":"/docker-clean/:2:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理所有停止的容器 通过docker ps可以查询当前运行的容器信息。 而通过docker ps -a，可以查询所有的容器信息，包括已停止的。 在需要清理所有已停止的容器时，通常利用shell的特性，组合一下就好。 docker rm $(docker ps -aq) 其中，ps的-q，是只输出容器ID，方便作为参数让rm使用。 假如给rm指定-f，则可以清理所有容器，包括正在运行的。 这条组合命令，等价于另一条命令： docker container prune container子命令，下面包含了所有和容器相关的子命令。 包括docker ps，等价于docker container ps或docker container ls。 其余还有start、stop、kill、cp等，一级子命令相当于二级子命令在外面的alias。 而prune则是特别提供的清理命令，这在其它的管理命令里还可以看到，比如image、volume。 ","date":"2022-02-10","objectID":"/docker-clean/:3:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"按需批量清理容器 清除所有已停止的容器，是比较常用的清理。 但有时会需要做一些特殊过滤。 这时就需要使用docker ps --filter。 比如，显示所有返回值为0，即正常退出的容器： docker ps -a --filter 'exited=0' 同理，可以得到其它非正常退出的容器。 目前支持的过滤器有： id (container’s id) label (label=\u003ckey\u003e or label=\u003ckey\u003e=\u003cvalue\u003e) name (container’s name) exited (int - the code of exited containers. Only useful with –all) status (created|restarting|running|removing|paused|exited|dead) ancestor (\u003cimage-name\u003e[:\u003ctag\u003e], \u003cimage id\u003e or \u003cimage@digest\u003e) - filters containers that were created from the given image or a descendant. before (container’s id or name) - filters containers created before given id or name since (container’s id or name) - filters containers created since given id or name isolation (default|process|hyperv) (Windows daemon only) volume (volume name or mount point) - filters containers that mount volumes. network (network id or name) - filters containers connected to the provided network health (starting|healthy|unhealthy|none) - filters containers based on healthcheck status ","date":"2022-02-10","objectID":"/docker-clean/:4:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理失败 如果在清理容器时发生失败，通过重启Docker的Daemon，应该都能解决问题。 # systemd sudo systemctl restart docker.service # initd sudo service docker restart ","date":"2022-02-10","objectID":"/docker-clean/:5:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理镜像 与清理容器的ps、rm类似，清理镜像也有images、rmi两个子命令。 images用来查看，rmi用来删除。 清理镜像前，应该确保该镜像的容器，已经被清除。 docker rmi IMAGE 其中，IMAGE可以是name或ID。 如果是name，不加TAG可以删除所有TAG。 另外，这两个命令也都属于alias。 docker images等价于docker image ls，而docker rmi等价于docker image rm。 按需批量清理镜像 ¶ 与ps类似，images也支持--filter参数。 与清理相关，最常用的，当属\u003cnone\u003e了。 docker images --filter \"dangling=true\" 这条命令，可以列出所有悬挂（dangling）的镜像，也就是显示为的那些。 docker rmi $(docker images -qf \"dangling=true\") 这条组合命令，如果不写入Bash的alias，几乎无法使用。 不过还有一条等价命令，非常容易使用。 docker image prune prune和images类似，也同样支持–filter参数。 其它的filter有： dangling (boolean - true or false) label (label=\u003ckey\u003e or label=\u003ckey\u003e=\u003cvalue\u003e) before (\u003cimage-name\u003e[:\u003ctag\u003e], \u003cimage id\u003e or \u003cimage@digest\u003e) - filter images created before given id or references since (\u003cimage-name\u003e[:\u003ctag\u003e], \u003cimage id\u003e or \u003cimage@digest\u003e) - filter images created since given id or references reference (pattern of an image reference) - filter images whose reference matches the specified pattern ","date":"2022-02-10","objectID":"/docker-clean/:6:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理所有无用镜像 这招要慎用，否则需要重新下载。 docker image prune -a ","date":"2022-02-10","objectID":"/docker-clean/:7:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"清理数据卷 数据卷不如容器或镜像那样显眼，但占的硬盘却可大可小。 数据卷的相关命令，都在docker volume中了。 一般用docker volume ls来查看，用docker volume rm VOLUME来删除一个或多个。 不过，绝大多数情况下，不需要执行这两个命令的组合。 直接执行docker volume prune就好，即可删除所有无用卷。 注意：这是一个危险操作！甚至可以说，这是本文中最危险的操作！ 一般真正有价值的运行数据，都在数据卷中。 （当然也可能挂载到了容器外的文件系统里，那就没关系。） 如果在关键服务停止期间，执行这个操作，很可能会丢失所有数据！ ","date":"2022-02-10","objectID":"/docker-clean/:8:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["docker"],"content":"从文件系统删除 除配置文件以为，Docker的内容相关文件，基本都放在/var/lib/docker/目录下。 该目录下有下列子目录，基本可以猜测出用途： aufs containers image network plugins swarm tmp trust volumes 一般不推荐直接操作这些目录，除非一些极特殊情况。 操作不当，后果难料，需要慎重。 ","date":"2022-02-10","objectID":"/docker-clean/:9:0","tags":["docker"],"title":"清理Docker的container，image与volume","uri":"/docker-clean/"},{"categories":["gitlab"],"content":"Jenkins 安装与使用 代码在本地修改—-》提交到远程gitlab—-》触发jenkins整个自动化构建流程（打包，测试，发布，部署） ","date":"2022-02-09","objectID":"/jenkins/:0:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"安装docker 安装docker ","date":"2022-02-09","objectID":"/jenkins/:1:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"docker安装jenkins docker run \\ -u root \\ -d \\ -p 8080:8080 \\ -p 50000:50000 \\ -v jenkins-data:/var/jenkins_home \\ -v /etc/localtime:/etc/localtime:ro \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --restart=always \\ jenkinsci/blueocean ","date":"2022-02-09","objectID":"/jenkins/:2:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"访问 http://localhost:8080 显示初始密码 docker exec -ti \u003c容器名称\u003e sh cat /var/jenkins_home/secrets/initialAdminPassword ","date":"2022-02-09","objectID":"/jenkins/:3:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"工作流程 先定义一个流水线项目，指定项目的git位置 git位置自动拉取代码 解析拉取代码里面的Jenkinsfile文件 按照Jenkinsfile指定的流水线开始加工项目 ","date":"2022-02-09","objectID":"/jenkins/:4:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"Jenkinsfile语法 基础语法,在仓库创建一个 Jenkinsfile 文件 pipeline { /* 全部的CICD流程都在这里定义 */ //任意代理可用就可以执行 agent any //定义流水线的加工流程 stages { /* 流水线的所有阶段 1.编译 \"常量\"'变量' 2.测试 3.打包 4.部署 */ stage('代码编译'){ steps { //要做的所有事情 echo \"编译……\" } } stage('代码测试'){ steps { //要做的所有事情 echo \"测试……\" } } stage('打包'){ steps { //要做的所有事情 echo \"打包……\" } } stage('部署'){ steps { //要做的所有事情 echo \"部署……\" } } } } ","date":"2022-02-09","objectID":"/jenkins/:5:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["gitlab"],"content":"构建远程触发 在jenkins上选择:项目-\u003e配置-\u003e构建触发器-\u003e勾选触发远程构建 新疆gitlab账户，登录新用户并天剑token令牌 找到gitlab 设置-\u003ewebhook 网站格式 http://\u003cUSER\u003e:\u003cTOKENAPI\u003e@\u003cJENKINS-URL\u003e/job/test-blog-demo/build?token=\u003cTOKEN\u003e ","date":"2022-02-09","objectID":"/jenkins/:6:0","tags":["gitlab"],"title":"Jenkins 安装与使用","uri":"/jenkins/"},{"categories":["数据库"],"content":"Navicat 查看密码方案 ","date":"2022-02-08","objectID":"/navicatforgetpassword/:0:0","tags":["mysql"],"title":"Navicat 查看导出连接的密码 | navicat查看密码方案","uri":"/navicatforgetpassword/"},{"categories":["数据库"],"content":"解决问题： 我们经常使用navicat连接数据库，有时候时间久了之后，会忘记之前的密码，那么现在我们有办法获得只要正常连接的数据库的密码 ","date":"2022-02-08","objectID":"/navicatforgetpassword/:1:0","tags":["mysql"],"title":"Navicat 查看导出连接的密码 | navicat查看密码方案","uri":"/navicatforgetpassword/"},{"categories":["数据库"],"content":"步骤： 导出连接connections.ncx，拿到保存到本地的connections.ncx文件中的Password，粘贴到下面的代码中 登陆https://tool.lu/coderunner/，使用PHP在线运行工具，粘贴下面添加密码后的代码 备用工具网址（https://zixuephp.net/tool-runcode.html） \u003c?php class NavicatPassword { protected $version = 0; protected $aesKey = 'libcckeylibcckey'; protected $aesIv = 'libcciv libcciv '; protected $blowString = '3DC5CA39'; protected $blowKey = null; protected $blowIv = null; public function __construct($version = 12) { $this-\u003eversion = $version; $this-\u003eblowKey = sha1('3DC5CA39', true); $this-\u003eblowIv = hex2bin('d9c7c3c8870d64bd'); } public function encrypt($string) { $result = FALSE; switch ($this-\u003eversion) { case 11: $result = $this-\u003eencryptEleven($string); break; case 12: $result = $this-\u003eencryptTwelve($string); break; default: break; } return $result; } protected function encryptEleven($string) { $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ''; $currentVector = $this-\u003eblowIv; for ($i = 0; $i \u003c $round; $i++) { $temp = $this-\u003eencryptBlock($this-\u003exorBytes(substr($string, 8 * $i, 8), $currentVector)); $currentVector = $this-\u003exorBytes($currentVector, $temp); $result .= $temp; } if ($leftLength) { $currentVector = $this-\u003eencryptBlock($currentVector); $result .= $this-\u003exorBytes(substr($string, 8 * $i, $leftLength), $currentVector); } return strtoupper(bin2hex($result)); } protected function encryptBlock($block) { return openssl_encrypt($block, 'BF-ECB', $this-\u003eblowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); } protected function decryptBlock($block) { return openssl_decrypt($block, 'BF-ECB', $this-\u003eblowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); } protected function xorBytes($str1, $str2) { $result = ''; for ($i = 0; $i \u003c strlen($str1); $i++) { $result .= chr(ord($str1[$i]) ^ ord($str2[$i])); } return $result; } protected function encryptTwelve($string) { $result = openssl_encrypt($string, 'AES-128-CBC', $this-\u003eaesKey, OPENSSL_RAW_DATA, $this-\u003eaesIv); return strtoupper(bin2hex($result)); } public function decrypt($string) { $result = FALSE; switch ($this-\u003eversion) { case 11: $result = $this-\u003edecryptEleven($string); break; case 12: $result = $this-\u003edecryptTwelve($string); break; default: break; } return $result; } protected function decryptEleven($upperString) { $string = hex2bin(strtolower($upperString)); $round = intval(floor(strlen($string) / 8)); $leftLength = strlen($string) % 8; $result = ''; $currentVector = $this-\u003eblowIv; for ($i = 0; $i \u003c $round; $i++) { $encryptedBlock = substr($string, 8 * $i, 8); $temp = $this-\u003exorBytes($this-\u003edecryptBlock($encryptedBlock), $currentVector); $currentVector = $this-\u003exorBytes($currentVector, $encryptedBlock); $result .= $temp; } if ($leftLength) { $currentVector = $this-\u003eencryptBlock($currentVector); $result .= $this-\u003exorBytes(substr($string, 8 * $i, $leftLength), $currentVector); } return $result; } protected function decryptTwelve($upperString) { $string = hex2bin(strtolower($upperString)); return openssl_decrypt($string, 'AES-128-CBC', $this-\u003eaesKey, OPENSSL_RAW_DATA, $this-\u003eaesIv); } }; //需要指定navacat版本两种，11或12 $navicatPassword = new NavicatPassword(12); //解密，括号里面写入navicat加密后的密码 $decode = $navicatPassword-\u003edecrypt('E75BF077AB8BAA3AC2D5'); echo $decode.\"\\n\"; ?\u003e 点击执行之后，就会得到真实密码 ","date":"2022-02-08","objectID":"/navicatforgetpassword/:2:0","tags":["mysql"],"title":"Navicat 查看导出连接的密码 | navicat查看密码方案","uri":"/navicatforgetpassword/"},{"categories":["问题库"],"content":"ProXmoX VE升级 apt-get update 报错 ","date":"2022-01-30","objectID":"/pveupdate/:0:0","tags":["error"],"title":"ProXmoX VE升级 apt-get update 报错","uri":"/pveupdate/"},{"categories":["问题库"],"content":"解决方法 vim /etc/apt/sources.list.d/pve-enterprise.list #注释掉 #deb https://enterprise.proxmox.com/debian/pve stretch pve-enterprise ","date":"2022-01-30","objectID":"/pveupdate/:1:0","tags":["error"],"title":"ProXmoX VE升级 apt-get update 报错","uri":"/pveupdate/"},{"categories":["问题库"],"content":"添加内容 echo \"deb http://download.proxmox.com/debian/pve stretch pve-no-subscription\" \u003e /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg ","date":"2022-01-30","objectID":"/pveupdate/:2:0","tags":["error"],"title":"ProXmoX VE升级 apt-get update 报错","uri":"/pveupdate/"},{"categories":["问题库"],"content":"更新系统 apt update \u0026\u0026 apt dist-upgrade ","date":"2022-01-30","objectID":"/pveupdate/:3:0","tags":["error"],"title":"ProXmoX VE升级 apt-get update 报错","uri":"/pveupdate/"},{"categories":["问题库"],"content":"结尾 升级完成后，可以执行pveversion -v查看下最新的软件版本。然后执行reboot重启物理服务器 ","date":"2022-01-30","objectID":"/pveupdate/:4:0","tags":["error"],"title":"ProXmoX VE升级 apt-get update 报错","uri":"/pveupdate/"},{"categories":["数据库"],"content":"mysql 学习笔记（2） ","date":"2022-01-21","objectID":"/mysql02/:0:0","tags":["mysql"],"title":"mysql 笔记（2）","uri":"/mysql02/"},{"categories":["数据库"],"content":"mysql 主从复制 MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。 ","date":"2022-01-21","objectID":"/mysql02/:1:0","tags":["mysql"],"title":"mysql 笔记（2）","uri":"/mysql02/"},{"categories":["数据库"],"content":"MySQL 主从复制的主要用途 读写分离 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换(主从切换) 高可用（HA） 架构扩展 ","date":"2022-01-21","objectID":"/mysql02/:2:0","tags":["mysql"],"title":"mysql 笔记（2）","uri":"/mysql02/"},{"categories":["数据库"],"content":"MySQL 主从复制的原理 MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示: 主节点 log dump 线程 当从节点连接主节点时，主节点会为其创建一个log dump 线程，用于发送和读取bin-log的内容。在读取bin-log中的操作时，log dump线程会对主节点上的bin-log加锁，当读取完成，在发送给从节点之前，锁会被释放。主节点会为自己的每一个从节点创建一个log dump 线程。 从节点 I/O线程 当从节点上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点的blog dump进程发来的更新之后，保存在本地relay-log（中继日志）中。 从节点 SQL线程 SQL线程负责读取relay-log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。 对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL进程还没有执行。如果在SQL进程执行之前从节点服务停止，至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同步。 要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。 ","date":"2022-01-21","objectID":"/mysql02/:3:0","tags":["mysql"],"title":"mysql 笔记（2）","uri":"/mysql02/"},{"categories":["日常"],"content":"Proxmox VE 在线扩容磁盘分区 ","date":"2022-01-19","objectID":"/pve1/:0:0","tags":["扩容磁盘","pve"],"title":"Proxmox VE 在线扩容磁盘分区","uri":"/pve1/"},{"categories":["日常"],"content":"添加磁盘大小 ","date":"2022-01-19","objectID":"/pve1/:1:0","tags":["扩容磁盘","pve"],"title":"Proxmox VE 在线扩容磁盘分区","uri":"/pve1/"},{"categories":["日常"],"content":"在VM上做扩容操作 安装 growpart yum install -y epel-release yum install -y cloud-utils 查看系统盘 路径 fdisk -l df -h 扩容设备并重启 growpart /dev/sda 2 #2代表是第二块系统分区，不是sda2,中间有空格 reboot 重启执行命令 xfs_growfs /dev/sda2 #(xfs 文件系统) resize2fs /dev/sda2 #(ext4 文件系统) 更新完成 df -h ","date":"2022-01-19","objectID":"/pve1/:2:0","tags":["扩容磁盘","pve"],"title":"Proxmox VE 在线扩容磁盘分区","uri":"/pve1/"},{"categories":["gitlab"],"content":"Gitlab批量导出用户 登陆Gitlab服务器进行数据库登陆、数据查询及信息导出操作。 ","date":"2022-01-14","objectID":"/exportuser/:0:0","tags":["自动化"],"title":"Gitlab批量导出用户","uri":"/exportuser/"},{"categories":["gitlab"],"content":"操作步骤 根据配置文件，定位数据库相关信息 cat /var/opt/gitlab/gitlab-rails/etc/database.yml 查看Gitlab对应的系统用户 cat /etc/passwd | grep gitlab 切换用户gitlab-psql su - gitlab-psql 登陆数据库（-h指定host，-d指定数据库） 使用第1步获取的信息 psql -h /var/opt/gitlab/postgresql -d gitlabhq_production (1) 查看帮助信息 gitlabhq_production=# \\h (2) 查看数据库 gitlabhq_production=# \\l (3) 查看库中的表（执行命令后，按回车键显示更多表信息） gitlabhq_production=# \\dt (4) 通过筛查，可在库中找到users表，相关用户信息都记录在表中！ gitlabhq_production=# \\d users (5) 查看表信息 gitlabhq_production=# SELECT * FROM users; (6) 查看users表中的name字段 gitlabhq_production=# SELECT name FROM users; (7)登出数据库 gitlabhq_production=# \\q 根据需要提取的信息，确定表users中的字段，进行导出操作 echo 'select name,username,email,state from users;' |psql -h /var/opt/gitlab/postgresql -d gitlabhq_production \u003e userinfo.txt 存储在/var/opt/gitlab/postgresql/userinfo.txt ","date":"2022-01-14","objectID":"/exportuser/:1:0","tags":["自动化"],"title":"Gitlab批量导出用户","uri":"/exportuser/"},{"categories":["k8s"],"content":"Harbor 搭建 Harbor 是一个开源可信的云原生注册表项目，用于存储、签名和扫描内容。用于存储docker image ","date":"2022-01-14","objectID":"/harbor/:0:0","tags":["k8s"],"title":"Harbor 搭建","uri":"/harbor/"},{"categories":["k8s"],"content":"要求 Linux主机 docker 17.06.0-ce 以上 docker-compose 1.18.0 以上 链接跳转：docker 安装 ","date":"2022-01-14","objectID":"/harbor/:1:0","tags":["k8s"],"title":"Harbor 搭建","uri":"/harbor/"},{"categories":["k8s"],"content":"安装 下载程序 在线安装包 wget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-online-installer-v1.10.10.tgz 离线安装包 wget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-offline-installer-v1.10.10.tgz 安装 mkdir -p /data cd /data tar -zxvf harbor-offline-installer-v1.10.10.tgz cd /harbor ./install.sh 接下来只要安静的等待安装就可以了 ","date":"2022-01-14","objectID":"/harbor/:2:0","tags":["k8s"],"title":"Harbor 搭建","uri":"/harbor/"},{"categories":["k8s"],"content":"配置 # Configuration file of Harbor # The IP address or hostname to access admin UI and registry service. # DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients. hostname: \u003c域名\u003e # http related config http: # port for http, default is 80. If https enabled, this port will redirect to https port port: 80 # https related config https: # https port for harbor, default is 443 port: 443 # SSL证书 certificate: /hub/ssl/bundle.pem private_key: /hub/ssl/key # Uncomment external_url if you want to enable external proxy # And when it enabled the hostname will no longer used # external_url: https://reg.mydomain.com:8433 # The initial password of Harbor admin # It only works in first time to install harbor # Remember Change the admin password from UI after launching Harbor. harbor_admin_password: \u003c密码\u003e # Harbor DB configuration database: # The password for the root user of Harbor DB. Change this before any production use. password: \u003c密码\u003e # The maximum number of connections in the idle connection pool. If it \u003c=0, no idle connections are retained. max_idle_conns: 50 # The maximum number of open connections to the database. If it \u003c= 0, then there is no limit on the number of open connections. # Note: the default number of connections is 100 for postgres. max_open_conns: 100 # The default data volume data_volume: /data # Harbor Storage settings by default is using /data dir on local filesystem # Uncomment storage_service setting If you want to using external storage # storage_service: # # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore # # of registry's and chart repository's containers. This is usually needed when the user hosts a internal storage with self signed certificate. # ca_bundle: # # storage backend, default is filesystem, options include filesystem, azure, gcs, s3, swift and oss # # for more info about this configuration please refer https://docs.docker.com/registry/configuration/ # filesystem: # maxthreads: 100 # # set disable to true when you want to disable registry redirect # redirect: # disabled: false # Clair configuration clair: # The interval of clair updaters, the unit is hour, set to 0 to disable the updaters. updaters_interval: 12 jobservice: # Maximum number of job workers in job service max_job_workers: 10 notification: # Maximum retry count for webhook job webhook_job_max_retry: 10 chart: # Change the value of absolute_url to enabled can enable absolute url in chart absolute_url: disabled # Log configurations log: # options are debug, info, warning, error, fatal level: info # configs for logs in local storage local: # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated. rotate_count: 50 # Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes. # If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G # are all valid. rotate_size: 200M # The directory on your host that store log location: /var/log/harbor # Uncomment following lines to enable external syslog endpoint. # external_endpoint: # # protocol used to transmit log to external endpoint, options is tcp or udp # protocol: tcp # # The host of external endpoint # host: localhost # # Port of external endpoint # port: 5140 #This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY! _version: 1.10.0 # Uncomment external_database if using external database. # external_database: # harbor: # host: harbor_db_host # port: harbor_db_port # db_name: harbor_db_name # username: harbor_db_username # password: harbor_db_password # ssl_mode: disable # max_idle_conns: 2 # max_open_conns: 0 # clair: # host: clair_db_host # port: clair_db_port # db_name: clair_db_name # username: clair_db_username # password: clair_db_password # ssl_mode: dis","date":"2022-01-14","objectID":"/harbor/:3:0","tags":["k8s"],"title":"Harbor 搭建","uri":"/harbor/"},{"categories":["监控"],"content":"prometheus+grafana+alertmanager 安装配置 服务器监控告警系统搭建，通过exporter获取节点信息到prometheus。prometheus配置规则，使garfana和alertmanager能够接受到数据，分别展示数据和发送告警 ","date":"2022-01-13","objectID":"/prometheus1/:0:0","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"参数 VM :192.168.99.78 端口 服务 9100 node_exporter 3000 grafana 9090 prometheus 9115 blackbox_exporter ","date":"2022-01-13","objectID":"/prometheus1/:1:0","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"安装 ","date":"2022-01-13","objectID":"/prometheus1/:2:0","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"grafa安装 docker安装 docker run -d -p 3000:3000 \\ --name=grafana \\ -v grafana-storage:/var/lib/grafana \\ grafana/grafana:8.3.3 ","date":"2022-01-13","objectID":"/prometheus1/:2:1","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"prometheus 安装 下载 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.32.1.linux-amd64 mkdir -p file_sd mkdir -p rules 运行 prometheus killall prometheus nohup ./prometheus --config.file=prometheus.yml \u0026 # 查看运行状况 tail -f nohup.out ","date":"2022-01-13","objectID":"/prometheus1/:2:2","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"node_exporter 安装 docker-compose 安装 version: \"3\" services: node-exporter: image: prom/node-exporter:v1.3.1 container_name: node-exporter restart: always ports: - \"9100:9100\" docker-compose up -d 二进制安装 wget https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz tar -zxvf node_exporter-1.3.1.linux-amd64.tar.gz cd node_exporter-1.3.1.linux-amd64 nohup ./node_exporter \u0026 ","date":"2022-01-13","objectID":"/prometheus1/:2:3","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"blackbox_exporter 二进制安装 wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.19.0/blackbox_exporter-0.19.0.linux-amd64.tar.gz tar -zxvf blackbox_exporter-0.19.0.linux-amd64.tar.gz cd blackbox_exporter-0.19.0.linux-amd64 nohup ./blackbox_exporter \u0026 ","date":"2022-01-13","objectID":"/prometheus1/:2:4","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"Alertmanager 二进制安装 wget https://github.com/prometheus/alertmanager/releases/download/v0.23.0/alertmanager-0.23.0.linux-amd64.tar.gz tar -zxvf alertmanager-0.23.0.linux-amd64.tar.gz cd alertmanager-0.23.0.linux-amd64 nohup ./alertmanager \u0026 docker-compose 安装 version: \"3\" services: alertmanager: image: \"prom/alertmanager:v0.22.2\" volumes: - \"/etc/localtime:/etc/localtime\" - \"./alertmanager.yml:/etc/alertmanager/alertmanager.yml\" ports: - \"9093:9093\" restart: \"always\" container_name: \"alertmanager\" ","date":"2022-01-13","objectID":"/prometheus1/:2:5","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"prometheus.yml 配置 global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor' # Alertmanager configuration # alerting: # alertmanagers: # - static_configs: # - targets: # - 192.168.99.78:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. # rule_files: # - \"./rules/blackbox.yaml\" # - \"./rules/node-exporter.yaml\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] - job_name: 'node-exporter' file_sd_configs: - files: - \"./file_sd/node-exporter.yaml\" refresh_interval: 5s - job_name: 'blackbox' metrics_path: /probe scrape_interval: 30s scrape_timeout: 30s params: module: [http_2xx] # Look for a HTTP 200 response. file_sd_configs: - files: - \"./file_sd/blackbox.yaml\" refresh_interval: 5s relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: 192.168.99.78:9115 ","date":"2022-01-13","objectID":"/prometheus1/:3:0","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"node-exporter.yaml - targets: ['192.168.99.78:9100'] labels: instance: \u003c实例名称\u003e - targets: ['\u003cIP\u003e:9100'] labels: instance: 实例名称 ","date":"2022-01-13","objectID":"/prometheus1/:3:1","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"blackbox.yaml - targets: - https://www.jobcher.com - https://\u003c域名\u003e ","date":"2022-01-13","objectID":"/prometheus1/:3:2","tags":["prometheus"],"title":"prometheus grafana alertmanager 安装配置","uri":"/prometheus1/"},{"categories":["监控"],"content":"prometheus 配置 Prometheus 是由 SoundCloud 开源监控告警解决方案 ","date":"2022-01-13","objectID":"/prometheus/:0:0","tags":["prometheus"],"title":"prometheus 配置","uri":"/prometheus/"},{"categories":["监控"],"content":"组件 Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。 client libraries，用于对接 Prometheus Server, 可以查询和上报数据。 push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。 各种汇报数据的 exporters ，例如汇报机器数据的 node_exporter, 汇报 MongoDB 信息的 MongoDB exporter 等等。 用于告警通知管理的 alertmanager 。 ","date":"2022-01-13","objectID":"/prometheus/:1:0","tags":["prometheus"],"title":"prometheus 配置","uri":"/prometheus/"},{"categories":["监控"],"content":"运行逻辑 Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。 Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。 Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。 ","date":"2022-01-13","objectID":"/prometheus/:2:0","tags":["prometheus"],"title":"prometheus 配置","uri":"/prometheus/"},{"categories":["监控"],"content":"安装prometheus 使用预编译的二进制文件安装 wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz cd prometheus-2.32.1.linux-amd64 使用docker 安装 mkdir -p opt/prometheus vim prometheus.yml docker run \\ -p 9090:9090 \\ -v /path/to/prometheus.yml:/opt/prometheus/prometheus.yml \\ prom/prometheus ","date":"2022-01-13","objectID":"/prometheus/:3:0","tags":["prometheus"],"title":"prometheus 配置","uri":"/prometheus/"},{"categories":["日常"],"content":"centos7.9 网络配置 解决centos 新机器网络不通的问题，CentOS7默认不启动网卡的。CentOS 安装成功后,进行一下 ping 的操作,验证网络是否联通. ping 1.1.1.1 ip addr # 查看ip网络名称 启用网卡 进入 /etc/sysconfig/network-scipts 文件夹下，找到IP网卡名称 cd /etc/sysconfig/network-scipts vim ifcfg-eth0 启用 ONBOOT #vim ifcfg-eth0 #修改 ONBOOT=YES # esc 并:wq退出保存 重启机器 shutdown -r now ","date":"2022-01-11","objectID":"/linux-network/:0:0","tags":["linux"],"title":"centos7.9 网络配置","uri":"/linux-network/"},{"categories":["日常"],"content":"结尾 centos用的挺别扭，不考虑性能和性价比，我还是喜欢用ubuntu……，简单的配置，初学者我建议还是先用ubuntu，会少踩很多坑。当然了，用x86不然初学者用树莓派和arm设备，会碰到很多兼容性的问题。 ","date":"2022-01-11","objectID":"/linux-network/:1:0","tags":["linux"],"title":"centos7.9 网络配置","uri":"/linux-network/"},{"categories":["问题库"],"content":"安装 docker 出现 ERROR: Unsupported distribution ‘ol’ 问题 部署docker 安装出现 ERROR: Unsupported distribution ‘ol’ 确认是不是arm架构 uname -r 确认使用的是不是oracle服务器系统,如果是请继续操作，安装依赖： dnf install -y dnf-utils zip unzip dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo 安装docker dnf remove -y runc dnf install -y docker-ce --nobest 完成docker 安装并检查 systemctl enable docker.service systemctl start docker.service #检查 systemctl status docker.service docker info docker version ","date":"2022-01-11","objectID":"/error1/:0:0","tags":["error"],"title":"安装 docker 出现 ERROR: Unsupported distribution 'ol' 问题","uri":"/error1/"},{"categories":["问题库"],"content":"结尾 该问题主要是oracle没有支持依赖导致的~oracle还是很不错的~ ","date":"2022-01-11","objectID":"/error1/:1:0","tags":["error"],"title":"安装 docker 出现 ERROR: Unsupported distribution 'ol' 问题","uri":"/error1/"},{"categories":["k8s"],"content":"Kubernetes 实验手册（1） 通过在pve创建5台虚拟机： 节点 IP 作用 node0 192.168.99.69 k8s-master01 node1 192.168.99.9 k8s-master02 node2 192.168.99.53 k8s-master03 node3 192.168.99.41 k8s-node01 node4 192.168.99.219 k8s-node02 node5 192.168.99.42 k8s-master-lb 配置信息 备注 系统版本 Ubuntu Docker 20.10.12 pod网段 172.168.0.0/12 service网段 10.96.0.0/12 VIP 不要和内网IP重复，VIP需要和主机在同一个局域网内 更新ansible连接 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.155 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.199 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.87 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.41 #ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.219 vim /etc/hosts 192.168.99.155 k8s-master01 192.168.99.199 k8s-master02 192.168.99.87 k8s-master03 #192.168.99.41 k8s-node01 #192.168.99.219 k8s-node02 ","date":"2022-01-07","objectID":"/k8s1/:0:0","tags":["k8s"],"title":"Kubernetes 实验手册（1）","uri":"/k8s1/"},{"categories":["k8s"],"content":"基本配置 安装基本软件包 apt install wget jq psmisc vim net-tools telnet lvm2 git -y # 关闭swap分区 vim /etc/fstab 注释掉swap 内容 并重启 reboot # 时间同步 apt install ntpdate -y # 查看时区 timedatectl set-timezone 'Asia/Shanghai' timedatectl date 安装docker curl -sSL https://get.daocloud.io/docker | sh systemctl restart docker 安装k8s组件 # 更新 apt 包索引并安装使用 Kubernetes sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl # 下载 Google Cloud 公开签名秘钥： sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg # 添加 Kubernetes apt 仓库 echo \"deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list # 更新 apt 包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本： sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl 安装keepalived和haproxy 所有Master节点安装HAProxy和KeepAlived apt install keepalived haproxy -y cp -rf /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak rm -rf /etc/haproxy/haproxy.cfg vim /etc/haproxy/haproxy.cfg 所有Master节点的HAProxy配置相同 global maxconn 2000 ulimit-n 16384 log 127.0.0.1 local0 err stats timeout 30s defaults log global mode http option httplog timeout connect 5000 timeout client 50000 timeout server 50000 timeout http-request 15s timeout http-keep-alive 15s frontend monitor-in bind *:33305 mode http option httplog monitor-uri /monitor frontend k8s-master bind 0.0.0.0:16443 bind 127.0.0.1:16443 mode tcp option tcplog tcp-request inspect-delay 5s default_backend k8s-master backend k8s-master mode tcp option tcplog option tcp-check balance roundrobin default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100 server k8s-master01 192.168.99.155:6443 check server k8s-master02 192.168.99.199:6443 check server k8s-master03 192.168.99.87:6443 check 所有Master节点配置KeepAlived，配置不一样，注意区分 注意每个节点的IP和网卡（interface参数） vim /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id LVS_DEVEL script_user root enable_script_security } vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" interval 5 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state MASTER interface ens18 #查看网关地址 mcast_src_ip 192.168.99.155 #本机IP virtual_router_id 51 priority 101 advert_int 2 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } virtual_ipaddress { 192.168.99.42 # vip地址 } # track_script { # chk_apiserver # } } 配置KeepAlived健康检查文件 vim /etc/keepalived/check_apiserver.sh #!/bin/bash err=0 for k in $(seq 1 3) do check_code=$(pgrep haproxy) if [[ $check_code == \"\" ]]; then err=$(expr $err + 1) sleep 1 continue else err=0 break fi done if [[ $err != \"0\" ]]; then echo \"systemctl stop keepalived\" /usr/bin/systemctl stop keepalived exit 1 else exit 0 fi chmod +x /etc/keepalived/check_apiserver.sh systemctl restart haproxy.service systemctl restart keepalived.service apt install kubeadm -y ","date":"2022-01-07","objectID":"/k8s1/:1:0","tags":["k8s"],"title":"Kubernetes 实验手册（1）","uri":"/k8s1/"},{"categories":["k8s"],"content":"集群初始化 Master01节点创建new.yaml配置文件如下： mkdir -p k8s \u0026\u0026 cd k8s vim new.yaml apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: 7t2weq.bjbawausm0jaxury ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.99.155 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s-master01 taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: certSANs: - 192.168.99.42 timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: 192.168.99.42:16443 controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: v1.23.1 networking: dnsDomain: cluster.local podSubnet: 172.168.0.0/16 serviceSubnet: 10.96.0.0/12 scheduler: {} kubeadm config images pull --config /root/k8s/new.yaml master01 节点生成初始化,初始化以后会在/etc/kubernetes目录下生成对应的证书和配置文件，之后其他Master节点加入Master01即可 systemctl enable --now kubelet kubeadm init --config /root/k8s/new.yaml --upload-certs 初始化成功以后，会产生Token值，用于其他节点加入时使用，因此要记录下初始化成功生成的token值（令牌值）： ","date":"2022-01-07","objectID":"/k8s1/:2:0","tags":["k8s"],"title":"Kubernetes 实验手册（1）","uri":"/k8s1/"},{"categories":["日常"],"content":"RocketMQ 安装和部署 部署RocketMQ ","date":"2022-01-07","objectID":"/rocketmq/:0:0","tags":["RocketMQ"],"title":"RocketMQ 安装和启动","uri":"/rocketmq/"},{"categories":["日常"],"content":"单机安装构建 安装JDK 1.8.0 yum install java-1.8.0-openjdk* 安装Maven wget http://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz tar -zxvf apache-maven-3.8.4-bin.tar.gz mv -f apache-maven-3.8.4 /usr/local/ vim /etc/profile # 末尾添加 export MAVEN_HOME=/usr/local/apache-maven-3.8.4 export PATH=${PATH}:${MAVEN_HOME}/bin # 保存 source /etc/profile # 查看maven是否正常 mvn -v ","date":"2022-01-07","objectID":"/rocketmq/:1:0","tags":["RocketMQ"],"title":"RocketMQ 安装和启动","uri":"/rocketmq/"},{"categories":["日常"],"content":"快速部署 #构建 DLedger git clone https://github.com/openmessaging/openmessaging-storage-dledger.git cd openmessaging-storage-dledger mvn clean install -DskipTests # 构建 RocketMQ git clone https://github.com/apache/rocketmq.git cd rocketmq git checkout -b store_with_dledger origin/store_with_dledger mvn -Prelease-all -DskipTests clean install -U # 部署 cd rocketmq/distribution/target/apache-rocketmq sh bin/dledger/fast-try.sh start # 通过 mqadmin 运维命令查看集群状态 sh bin/mqadmin clusterList -n 127.0.0.1:9876 启动单节点 cd distribution/target/rocketmq-4.9.3-SNAPSHOT/rocketmq-4.9.3-SNAPSHOT nohup sh bin/mqnamesrv \u0026 # 查看 Namesrv 日志 tail -f ~/logs/rocketmqlogs/namesrv.log 2022-01-07 14:59:29 INFO main - The Name Server boot success. serializeType=JSON # 启动 Broker nohup sh bin/mqbroker -c conf/broker.conf -n 127.0.0.1:9876 \u0026 # 查看 Broker 日志 tail -f ~/logs/rocketmqlogs/broker.log 如果提示找不到上面的日志文件，应该是没启动成功。 应该是内存不够，RocketMQ默认用8g内存，如果你服务器的内存比较小，可以修改下bin/runbroker.sh脚本，将 Broker JVM 内存调小。如：JAVA_OPT=\"${JAVA_OPT} -server -Xms2g -Xmx2g -Xmn1g\"。 再次启动broker，可以正常启动。 默认情况下，Broker 日志文件所在地址为~/logs/rocketmqlogs/broker.log。如果想要自定义，可以通过conf/logback_broker.xml配置文件来进行修改。 ","date":"2022-01-07","objectID":"/rocketmq/:2:0","tags":["RocketMQ"],"title":"RocketMQ 安装和启动","uri":"/rocketmq/"},{"categories":["日常"],"content":"安装 minIO ","date":"2022-01-07","objectID":"/minio/:0:0","tags":["minIO"],"title":"安装 minIO Azure S3网关","uri":"/minio/"},{"categories":["日常"],"content":"通过docker 安装 docker run -p 9000:9000 -p 41863:41863 -d --name azure-s3 \\ -e \"MINIO_ACCESS_KEY=azure存储账户\" \\ -e \"MINIO_SECRET_KEY=azure存储密码\" \\ minio/minio gateway azure --console-address \":41863\" ","date":"2022-01-07","objectID":"/minio/:1:0","tags":["minIO"],"title":"安装 minIO Azure S3网关","uri":"/minio/"},{"categories":["日常"],"content":"通过docker-compose 安装 version: \"3\" services: minio: image: \"minio/minio:RELEASE.2022-01-04T07-41-07Z.fips\" container_name: \"minio\" restart: \"always\" volumes: - \"/etc/localtime:/etc/localtime\" ports: - \"9000:9000\" - \"9001:9001\" environment: - \"MINIO_ROOT_USER=azure存储账户\" - \"MINIO_ROOT_PASSWORD=azure存储密码\" command: - --console-address \":41863\" ","date":"2022-01-07","objectID":"/minio/:2:0","tags":["minIO"],"title":"安装 minIO Azure S3网关","uri":"/minio/"},{"categories":["k8s"],"content":"Keepalived高可用 配置文件存放位置：/usr/share/doc/keepalived/samples VVRP 虚拟路由冗余协议 ","date":"2022-01-05","objectID":"/keepalived/:0:0","tags":["k8s"],"title":"Keepalived高可用","uri":"/keepalived/"},{"categories":["k8s"],"content":"组成 LB集群：Load Balancing，负载均衡集群，平均分配给多个节点 HA集群：High Availability，高可用集群，保证服务可用 HPC集群：High Performance Computing，高性能集群 ","date":"2022-01-05","objectID":"/keepalived/:1:0","tags":["k8s"],"title":"Keepalived高可用","uri":"/keepalived/"},{"categories":["k8s"],"content":"配置 keepalived+LVS+nginx 各节点时间必须同步：ntp, chrony 关闭防火墙及SELinux ","date":"2022-01-05","objectID":"/keepalived/:2:0","tags":["k8s"],"title":"Keepalived高可用","uri":"/keepalived/"},{"categories":["k8s"],"content":"同步各节点时间 #安装ntpdate apt install ntpdate #更改时区 timedatectl set-timezone 'Asia/Shanghai' #查看时间 timedatectl datetime ","date":"2022-01-05","objectID":"/keepalived/:2:1","tags":["k8s"],"title":"Keepalived高可用","uri":"/keepalived/"},{"categories":["k8s"],"content":"安装keepalived #安装 apt install keepalived #更改模板 cd /usr/share/doc/keepalived/samples ","date":"2022-01-05","objectID":"/keepalived/:2:2","tags":["k8s"],"title":"Keepalived高可用","uri":"/keepalived/"},{"categories":["gitlab"],"content":"ansible 安装和部署 Ansible默认通过 SSH 协议管理机器. ","date":"2021-12-30","objectID":"/ansible/:0:0","tags":["ansible"],"title":"ansible 安装和部署","uri":"/ansible/"},{"categories":["gitlab"],"content":"安装ansible 下载安装 # ubuntu 安装 apt-get install software-properties-common apt-add-repository ppa:ansible/ansible apt-get update apt-get install ansible # centos 安装 yum install ansible 检查文件 #检查 ansible --version ","date":"2021-12-30","objectID":"/ansible/:1:0","tags":["ansible"],"title":"ansible 安装和部署","uri":"/ansible/"},{"categories":["gitlab"],"content":"ansible 配置 添加主机 vim /etc/ansible/hosts #添加你需要添加的被控主机地址和IP 配置SSH key授权访问 # 控制主机生成ssh 密钥对（一路回车） ssh-keygen -t rsa # 复制公钥IP到被控主机 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.2 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.3 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.4 # ssh-copy-id命令会自动将id_rsa.pub文件的内容追加到远程主机root用户下.ssh/authorized_keys文件中。 更改ansible 配置 vim /etc/ansible/ansible.cfg #禁用每次执行ansbile命令检查ssh key host host_key_checking = False # 开启日志记录 log_path = /var/log/ansible.log 测试 # 控制主机 ansible all -m ping ","date":"2021-12-30","objectID":"/ansible/:2:0","tags":["ansible"],"title":"ansible 安装和部署","uri":"/ansible/"},{"categories":["gitlab"],"content":"Inventory 配置组别 vim /etc/ansible/hosts # 添加组别 [pve] 192.168.0.2 192.168.0.3 192.168.0.4 #测试 ansible pve -m ping Inventory 参数 把你的 inventory 文件 和 变量 放入 git repo 中,以便跟踪他们的更新,这是一种非常推荐的方式. 参数 作用 ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置. ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置. ansible_ssh_user 默认的 ssh 用户名 ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 –ask-pass 或 SSH 密钥) ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 –ask-sudo-pass) ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本) ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 ‘smart’,‘smart’ 方式会根据是否支持 ControlPersist, 来判断’ssh’ 方式是否可行. ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况. ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 ‘sh’ 语法,可设置为 ‘csh’ 或 ‘fish’. ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是\"/usr/bin/python\",比如 *BSD, 或者 /usr/bin/python ","date":"2021-12-30","objectID":"/ansible/:3:0","tags":["ansible"],"title":"ansible 安装和部署","uri":"/ansible/"},{"categories":["gitlab"],"content":"Roles Roles是基于已知文件结构自动加载某些变量文件，任务和处理程序的方法。按角色对内容进行分组，适合构建复杂的部署环境 Roles 目录结构： site.yml webservers.yml fooservers.yml roles/ common/ tasks/ handlers/ files/ templates/ vars/ defaults/ meta/ webservers/ tasks/ defaults/ meta/ tasks 包含角色要执行的任务的主要列表 handlers 包含处理程序，此角色甚至在此角色之外的任何地方都可以使用这些处理程序 defaults 角色的默认变量 vars 角色的其他变量 files 包含可以通过此角色部署的文件 templates 包含可以通过此角色部署的模版 meta 为此角色定义一些元数据 ","date":"2021-12-30","objectID":"/ansible/:4:0","tags":["ansible"],"title":"ansible 安装和部署","uri":"/ansible/"},{"categories":["基础"],"content":"yaml 语法 我们使用 YAML 是因为它像 XML 或 JSON 是一种利于人们读写的数据格式. 此外在大多数变成语言中有使用 YAML 的库.YAML 语法的基本概述, 它被用来描述一个 playbooks(我们的配置管理语言). 基本的 YAML 对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. 所以, 我们需要知道如何在 YAML 中编写列表和字典. YAML 还有一个小的怪癖. 所有的 YAML 文件(无论和 Ansible 有没有关系)开始行都应该是 —. 这是 YAML 格式的一部分, 表明一个文件的开始. --- # 一个美味水果的列表 - Apple - Orange - Strawberry - Mango ","date":"2021-12-30","objectID":"/yaml/:0:0","tags":["运维"],"title":"yaml 语法","uri":"/yaml/"},{"categories":["日常"],"content":"logrotate 日志滚动的使用 logrotate 日志滚动切割工具，是linux默认安装的工具，配置文件位置： /etc/logrotate.conf /etc/logrotate.d/ ","date":"2021-12-29","objectID":"/logrotate/:0:0","tags":["daliy"],"title":"logrotate 日志滚动的使用","uri":"/logrotate/"},{"categories":["日常"],"content":"参数 以nginx 配置为例 /opt/log/nginx/*.log { daily missingok rotate 14 errors \"nb@nbtyfood.com\" compress delaycompress notifempty create 0640 www-data adm sharedscripts prerotate if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\ run-parts /etc/logrotate.d/httpd-prerotate; \\ fi \\ endscript postrotate invoke-rc.d nginx rotate \u003e/dev/null 2\u003e\u00261 endscript } 参数 作用 compress 压缩日志文件的所有非当前版本 daily,weekly,monthly 按指定计划轮换日志文件 delaycompress 压缩所有版本，除了当前和下一个最近的 endscript 标记 prerotate 或 postrotate 脚本的结束 errors “emailid” 给指定邮箱发送错误通知 missingok 如果日志文件丢失，不要显示错误 notifempty 如果日志文件为空，则不轮换日志文件 olddir “dir” 指定日志文件的旧版本放在 “dir” 中 postrotate 引入一个在日志被轮换后执行的脚本 prerotate 引入一个在日志被轮换前执行的脚本 rotate ’n' 在轮换方案中包含日志的 n 个版本 sharedscripts 对于整个日志组只运行一次脚本 size=‘logsize’ 在日志大小大于 logsize（例如 100K，4M）时轮换 ","date":"2021-12-29","objectID":"/logrotate/:1:0","tags":["daliy"],"title":"logrotate 日志滚动的使用","uri":"/logrotate/"},{"categories":["docker"],"content":"安装docker 通过docker 脚本安装 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun curl -sSL https://get.daocloud.io/docker | sh ","date":"2021-12-28","objectID":"/docker/:0:0","tags":["docker"],"title":"docker 命令","uri":"/docker/"},{"categories":["docker"],"content":"docker-compose 安装 #下载安装 sudo curl -L \"https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose #可执行权限 sudo chmod +x /usr/local/bin/docker-compose #创建软链： sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose #测试是否安装成功 docker-compose --version ","date":"2021-12-28","objectID":"/docker/:1:0","tags":["docker"],"title":"docker 命令","uri":"/docker/"},{"categories":["docker"],"content":"docker命令 常用docker命令 #查看容器 docker ps #查看镜像 docker images #停止当前所有容器 docker stop $(docker ps -aq) #删除当前停止的所有容器 docker rm $(docker ps -aq) #删除镜像 docker rmi nginx ","date":"2021-12-28","objectID":"/docker/:2:0","tags":["docker"],"title":"docker 命令","uri":"/docker/"},{"categories":["gitlab"],"content":"gitlab与github同步项目 本地同步项目 git clone 创建一个同名的项目,命令行终端中添加remote地址 git remote add githubOrigin git@github.com:sjtfreaks/blog.git 项目同步到Github上 git push -u githubOrigin main 分别同步github与gitlab即可 git push -u githubOrigin main git push -u origin main ","date":"2021-12-27","objectID":"/gitrsync/:0:0","tags":["gitlab"],"title":"gitlab与github同步项目","uri":"/gitrsync/"},{"categories":["基础"],"content":"iptables 基础知识 内核包过滤与NAT管理工具.是linux系统中在用户空间中运行的运来配置内核防火墙的工具。它可以设置，维护和检查linux内核中的ipv4包过滤规则和管理网络地址转换（NAT）。 ipatbles命令仅支持ipv4，如果使用的IP协议是ipv6则需要使用专门的管理工具ip6tables。 ","date":"2021-12-27","objectID":"/iptable/:0:0","tags":["运维"],"title":"iptables 基础知识","uri":"/iptable/"},{"categories":["基础"],"content":"常用参数 参数 作用 -t\u003c表\u003e 指定要操纵的表 -A 向规则链中追加条目 -D 从规则链中删除条目 -I 向规则链中插入条目 -R 替换规则链中的相应条目 -L 显示规则链中的已有条目 -F 清除规则链中的现有条目。不改变规则链的默认目标策略 -Z 清空规则链中的数据包计数器和字节计数器 -N 创建新的用户自定义规则链 -P 定义规则链中的默认目标（策略） -h 显示帮助信息 -p\u003c协议\u003e 指定要匹配的数据包的协议类型 -s\u003c源地址\u003e 指定要匹配的数据包的源IP地址 -j\u003c目标\u003e 指定要跳转的目标 -i\u003c网络接口\u003e 指定数据包进入本机的网络接口 -o\u003c网络接口\u003e 指定数据包离开本机做使用的网络接口 -c\u003c包计数\u003e 在执行插入、追加和替换操作时初始化包计数器和字节计数器 ","date":"2021-12-27","objectID":"/iptable/:1:0","tags":["运维"],"title":"iptables 基础知识","uri":"/iptable/"},{"categories":["基础"],"content":"参考实例 显示内核当前的filter表： iptables -L 显示内核当前的nat表： iptables -L -t nat 禁止本机对192.168.20.20地址的访问： iptables -t filter -A OUTPUT -d 192.168.20.20 -j DROP 显示filter表的OUTPUT链： iptables -L OUTPUT -t filter ","date":"2021-12-27","objectID":"/iptable/:2:0","tags":["运维"],"title":"iptables 基础知识","uri":"/iptable/"},{"categories":["k8s"],"content":"k3s 升级版本 ","date":"2021-12-27","objectID":"/k3supgrade/:0:0","tags":["k3s"],"title":"k3s 升级版本","uri":"/k3supgrade/"},{"categories":["k8s"],"content":"停止所有的 K3s 容器（慎用） 从 server 节点运行 killall 脚本 /usr/local/bin/k3s-killall.sh ","date":"2021-12-27","objectID":"/k3supgrade/:1:0","tags":["k3s"],"title":"k3s 升级版本","uri":"/k3supgrade/"},{"categories":["k8s"],"content":"开始升级 使用安装脚本升级 K3s curl -sfL https://get.k3s.io | sh - #国内可用 curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 重启k3s sudo systemctl restart k3s ","date":"2021-12-27","objectID":"/k3supgrade/:2:0","tags":["k3s"],"title":"k3s 升级版本","uri":"/k3supgrade/"},{"categories":["日常"],"content":"安装配置 Terraform ","date":"2021-12-27","objectID":"/terraform/:0:0","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"安装 macOS 苹果系统安装 #安装 brew tap hashicorp/tap brew install hashicorp/tap/terraform # 更新 brew update brew upgrade hashicorp/tap/terraform #验证安装 terraform -help windows 系统安装 #安装 choco install terraform #直接到这个url里下载64位系统 https://www.terraform.io/downloads #验证安装 terraform -help Linux 安装 curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" sudo apt-get update \u0026\u0026 sudo apt-get install terraform #验证安装 terraform -help ","date":"2021-12-27","objectID":"/terraform/:1:0","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"terrafrom 控制proxmox虚拟机 来源：https://github.com/Telmate/terraform-provider-proxmox ","date":"2021-12-27","objectID":"/terraform/:2:0","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"首先你要有一台pve主机 安装过程本篇文章就不想了，主要是要写一下关于他的配置 https://pve.proxmox.com/pve-docs/ 下载 wget https://github.com/Telmate/terraform-provider-proxmox/releases/download/v2.9.3/terraform-provider-proxmox_2.9.3_linux_amd64.zip unzip terraform-provider-proxmox_2.9.3_linux_amd64.zip ","date":"2021-12-27","objectID":"/terraform/:2:1","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"编写terrafrom程序 虚拟机main.tf terraform { required_version = \"\u003e= 0.14\" required_providers { proxmox = { source = \"telmate/proxmox\" } } } provider \"proxmox\" { # 配置选项 pm_tls_insecure = true pm_api_url = \"https://localhost:8006/api2/json\" pm_user = \"root@pam\" pm_password = \"passwd\" pm_otp = \"\" } # 创建VM resource \"proxmox_vm_qemu\" \"cloudinit-test\" { name = \"terraform-test-vm\" desc = \"A test for using terraform and cloudinit\" #节点名称必须与集群内的名称相同 #这可能不包括 FQDN target_node = \"pve\" #新虚拟机的目标资源池 pool = \"pool0\" #从中克隆这个虚拟机的模板名称 clone = \"node0\" #为这个虚拟机激活 QEMU 代理 agent = 1 os_type = \"cloud-init\" cores = 2 sockets = 1 vcpus = 0 cpu = \"host\" memory = 2048 scsihw = \"lsi\" #设置磁盘 disk { size = 32 type = \"virtio\" storage = \"local-lvm\" storage_type = \"lvmthin\" iothread = 1 ssd = 1 discard = \"on\" } #设置网络接口并分配一个 vlan 标签：256 network { model = \"virtio\" bridge = \"vmbr0\" tag = 256 } } 运行terrafrom # 初始化 terraform init # 查看产生的变更 terraform plan # 运行 terraform apply ","date":"2021-12-27","objectID":"/terraform/:2:2","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"配置 配置这个terraform我们这个需要持续更新，首先我们先配置Azure吧 ","date":"2021-12-27","objectID":"/terraform/:3:0","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["日常"],"content":"Azure 配置 安装azurecli # linux curl -L https://aka.ms/InstallAzureCli | bash apt install azure-cli # macOS brew update \u0026\u0026 brew install azure-cli 登录azure # 中国区azure az cloud set --name AzureCloud az login -u \u003c账户\u003e -p \u003c密码\u003e #海外azure az cloud set --name AzureChinaCloud az login -u \u003c账户\u003e -p \u003c密码\u003e 创建terrafrom代码 创建main.tf # 正在使用的 Azure 提供程序源和版本 terraform { required_version = \"\u003e=0.12\" required_providers { azurerm = { source = \"hashicorp/azurerm\" version = \"~\u003e2.0\" } } } # 配置 Microsoft Azure 提供程序 provider \"azurerm\" { features {} } # 资源组前缀 resource \"random_pet\" \"rg-name\" { prefix = var.resource_group_name_prefix } # 创建资源组 resource \"azurerm_resource_group\" \"rg\" { name = random_pet.rg-name.id location = var.resource_group_location } 创建variable.tf variable \"resource_group_name_prefix\" { default = \"rg\" description = \"Prefix of the resource group name that's combined with a random ID so name is unique in your Azure subscription.\" } variable \"resource_group_location\" { default = \"eastus\" description = \"Location of the resource group.\" } ","date":"2021-12-27","objectID":"/terraform/:3:1","tags":["Terraform"],"title":"安装配置 Terraform","uri":"/terraform/"},{"categories":["美食"],"content":"孜然杏鲍菇-素食 ","date":"2021-12-26","objectID":"/eryngii/:0:0","tags":["美食"],"title":"孜然杏鲍菇-素食","uri":"/eryngii/"},{"categories":["美食"],"content":"准备食材 杏鲍菇 蒜 糖 白芝麻 孜然粉 老抽 生抽 蚝油 ","date":"2021-12-26","objectID":"/eryngii/:1:0","tags":["美食"],"title":"孜然杏鲍菇-素食","uri":"/eryngii/"},{"categories":["美食"],"content":"步骤 杏鲍菇切片 蒜切成末 热油下蒜爆香 杏鲍菇下锅把水分炒干 加一勺生抽、半勺老抽，半勺蚝油，一勺孜然粉，一勺白芝麻，半勺糖炒匀 ","date":"2021-12-26","objectID":"/eryngii/:2:0","tags":["美食"],"title":"孜然杏鲍菇-素食","uri":"/eryngii/"},{"categories":["数据库"],"content":"mysql数据库备份迁移 使用mydumper做数据备份迁移 ","date":"2021-12-24","objectID":"/mysqldump/:0:0","tags":["mysql"],"title":"mysql数据库备份迁移","uri":"/mysqldump/"},{"categories":["数据库"],"content":"备份数据库 安装 # 安装 centos yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el7.x86_64.rpm yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el8.x86_64.rpm # 安装 ubuntu apt-get install libatomic1 wget https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb dpkg -i mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb 备份 nohup mydumper -h '备份数据库' \\ -u '用户名' \\ -p '密码' \\ --threads=16 \\ -B 备份数据库 \\ -v 3 \\ --outputdir=./backup --rows=100000 \\ -L mydumper-logs.log \u0026 ","date":"2021-12-24","objectID":"/mysqldump/:1:0","tags":["mysql"],"title":"mysql数据库备份迁移","uri":"/mysqldump/"},{"categories":["数据库"],"content":"迁移数据库 还原数据 nohup myloader -h '迁移数据库' \\ -u '用户名' \\ -p '密码' \\ --directory=./backup \\ -s 来源数据库 \\ -B 还原数据库 \\ -t 16 \\ -v 3 \\ -e 2\u003emyloader-logs.log \u0026 ","date":"2021-12-24","objectID":"/mysqldump/:2:0","tags":["mysql"],"title":"mysql数据库备份迁移","uri":"/mysqldump/"},{"categories":["数据库"],"content":"mydumper/myloader 参数 mydumper Usage: mydumper [OPTION...] multi-threaded MySQL dumping Help Options: -?, --help Show help options Application Options: -B, --database 需要备份的数据库，一个数据库一条命令备份，要不就是备份所有数据库，包括mysql。 -T, --tables-list 需要备份的表，用逗号分隔。 -o, --outputdir 备份文件目录 -s, --statement-size 生成插入语句的字节数，默认1000000，这个参数不能太小，不然会报 Row bigger than statement_size for tools.t_serverinfo -r, --rows 试图用行块来分割表，该参数关闭--chunk-filesize -F, --chunk-filesize 行块分割表的文件大小，单位是MB -c, --compress 压缩输出文件 -e, --build-empty-files 即使表没有数据，也产生一个空文件 -x, --regex 正则表达式匹配，如'db.table' -i, --ignore-engines 忽略的存储引擎，用逗号分隔 -m, --no-schemas 不导出表结构 -d, --no-data 不导出表数据 -G, --triggers 导出触发器 -E, --events 导出事件 -R, --routines 导出存储过程 -k, --no-locks 不执行共享读锁 警告：这将导致不一致的备份 --less-locking 减到最小的锁在innodb表上. -l, --long-query-guard 设置长查询时间,默认60秒，超过该时间则会报错：There are queries in PROCESSLIST running longer than 60s, aborting dump -K, --kill-long-queries kill掉长时间执行的查询，备份报错：Lock wait timeout exceeded; try restarting transaction -D, --daemon 启用守护进程模式 -I, --snapshot-interval dump快照间隔时间，默认60s，需要在daemon模式下 -L, --logfile 使用日志文件，默认标准输出到终端 --tz-utc 备份的时候允许备份Timestamp，这样会导致不同时区的备份还原会出问题，默认关闭，参数：--skip-tz-utc to disable. --skip-tz-utc --use-savepoints 使用savepoints来减少采集metadata所造成的锁时间，需要SUPER权限 --success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn't exist --lock-all-tables 锁全表，代替FLUSH TABLE WITH READ LOCK -U, --updated-since Use Update_time to dump only tables updated in the last U days --trx-consistency-only Transactional consistency only -h, --host The host to connect to -u, --user Username with privileges to run the dump -p, --password User password -P, --port TCP/IP port to connect to -S, --socket UNIX domain socket file to use for connection -t, --threads 备份执行的线程数,默认4个线程 -C, --compress-protocol 在mysql连接上使用压缩协议 -V, --version Show the program version and exit -v, --verbose 更多输出, 0 = silent, 1 = errors, 2 = warnings, 3 = info, default 2 myloader Usage: myloader [OPTION...] multi-threaded MySQL loader Help Options: -?, --help Show help options Application Options: -d, --directory 备份文件所在的目录 -q, --queries-per-transaction 每个事务的query数量, 默认1000 -o, --overwrite-tables 如果表存在则先删除，使用该参数，需要备份时候要备份表结构，不然还原会找不到表 -B, --database 指定需要还原的数据库 -s, --source-db 还原的数据库 -e, --enable-binlog 启用二进制日志恢复数据 -h, --host The host to connect to -u, --user Username with privileges to run the dump -p, --password User password -P, --port TCP/IP port to connect to -S, --socket UNIX domain socket file to use for connection -t, --threads 使用的线程数量，默认4 -C, --compress-protocol 连接上使用压缩协议 -V, --version Show the program version and exit -v, --verbose 更多输出, 0 = silent, 1 = errors, 2 = warnings, 3 = info, default 2 ","date":"2021-12-24","objectID":"/mysqldump/:3:0","tags":["mysql"],"title":"mysql数据库备份迁移","uri":"/mysqldump/"},{"categories":["web 服务器"],"content":"nginx 编译参数详解 nginx编译参数 作用 –prefix= 指向安装目录 –sbin-path 指向（执行）程序文件（nginx） –conf-path= 指向配置文件（nginx.conf） –error-log-path= 指向错误日志目录 –pid-path= 指向 pid 文件（nginx.pid） –lock-path= 指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作。） –user= 指定程序运行时的非特权用户 –group= 指定程序运行时的非特权用户组 –builddir= 指向编译目录 –with-rtsig_module 启用 rtsig 模块支持（实时信号） –with-select_module 启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：–withoutselect_module –with-poll_module 启用 poll 模块支持（功能与 select 相同，与 select 特性相同，为一种轮询模式,不推荐在高载环境下使用） –with-file-aio 启用 file aio 支持（一种 APL 文件传输格式） –with-ipv6 启用 ipv6 支持 –with-http_ssl_module 启用 ngx_http_ssl_module 支持（使支持 https 请求，需已安装 openssl） –with-http_realip_module 启用 ngx_http_realip_module 支持（这个模块允许从请求标头更改客户端的 IP 地址值，默认为关） –with-http_addition_module 启用 ngx_http_addition_module 支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求） –with-http_xslt_module 启用 ngx_http_xslt_module 支持（过滤转换 XML 请求 –with-http_image_filter_module 启用 ngx_http_image_filter_module 支持（传输 JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd 库要用到） –with-http_geoip_module 启用 ngx_http_geoip_module 支持（该模块创建基于与 MaxMind GeoIP 二进制文件相配的客户端 IP 地址的 ngx_http_geoip_module 变量） –with-http_sub_module 启用 ngx_http_sub_module 支持（允许用一些其他文本替换 nginx 响应中的一些文本） –with-http_dav_module 启用 ngx_http_dav_module 支持（增加 PUT,DELETE,MKCOL：创建集合,COPY 和 MOVE 方法）默认情况下为关闭，需编译开启 –with-http_flv_module 启用 ngx_http_flv_module 支持（提供寻求内存使用基于时间的偏移量文件） –with-http_gzip_static_module 启用 ngx_http_gzip_static_module 支持（在线实时压缩输出数据流） –with-http_random_index_module 启用 ngx_http_random_index_module 支持（从目录中随机挑选一个目录索引） –with-http_secure_link_module 启用 ngx_http_secure_link_module 支持（计算和检查要求所需的安全链接网址） –with-http_degradation_module 启用 ngx_http_degradation_module 支持（允许在内存不足的情况下返回204 或 444 码） –with-http_stub_status_module 启用 ngx_http_stub_status_module 支持（获取 nginx 自上次启动以来的工作状态） –without-http_charset_module 禁用 ngx_http_charset_module 支持（重新编码 web 页面，但只能是一个方向–服务器端到客户端，并且只有一个字节的编码可以被重新编码） –without-http_gzip_module 禁用 ngx_http_gzip_module 支持（该模块同-with-http_gzip_static_module 功能一样） –without-http_ssi_module 禁用 ngx_http_ssi_module 支持（该模块提供了一个在输入端处理处理服务器包含文件（SSI）的过滤器，目前支持 SSI 命令的列表是不完整的） –without-http_userid_module 禁用 ngx_http_userid_module 支持（该模块用来处理用来确定客户端后续请求的 cookies） –without-http_access_module 禁用 ngx_http_access_module 支持（该模块提供了一个简单的基于主机的访问控制。允许/拒绝基于 ip 地址） –without-http_auth_basic_module 禁用 ngx_http_auth_basic_module（该模块是可以使用用户名和密码基于http 基本认证方法来保护你的站点或其部分内容） –without-http_autoindex_module 禁用 disable ngx_http_autoindex_module 支持（该模块用于自动生成目录列表，只在 ngx_http_index_module 模块未找到索引文件时发出请求。） –without-http_geo_module 禁用 ngx_http_geo_module 支持（创建一些变量，其值依赖于客户端的 IP 地址） –without-http_map_module 禁用 ngx_http_map_module 支持（使用任意的键/值对设置配置变量） –without-http_split_clients_module 禁用 ngx_http_split_clients_module 支持（该模块用来基于某些条件划分用户。条件如：ip 地址、报头、cookies 等等） –without-http_referer_module 禁用 disable ngx_http_referer_module 支持（该模块用来过滤请求，拒绝报 头中 Referer 值不正确的请求） –without-http_rewrite_module 禁用 ngx_http_rewrite_module 支持（该模块允许使用正则表达式改变 URI，并且根据变量来转向以及选择配置。如果在 server 级别设置该选项，那么他们将在 location 之前生效。如果在location 还有更进一步的重写规则，location 部分的规则依然会被执行。如果这个 URI 重写是因为 location 部分的规则造成的，那么 location 部分会再次被执行作为新的 URI。 这个循环会执行 10 次，然后 Nginx 会返回一个 500 错误。） –without-http_proxy_module 禁用 ngx_http_proxy_module 支持（有关代理服务器） –without-http_fastcgi_module 禁用 ngx_http_fastcgi_module 支持（该模块允许 Nginx 与 FastCGI 进程交互，并通过传递参数来控制 FastCGI 进程工作。 ）FastCGI 一个常驻型的公共网关接口。 –without-http_uwsgi_module 禁用 ngx_http_uwsgi_module 支持（该模块用来医用 uwsgi 协议，uWSGI 服务器相关） –without-http_scgi_module 禁用 ngx_http_scgi_module 支持（该模块用来启用 SCGI 协议支持，SCGI 协议是CGI 协议的替代。它是一种应用程序与 HTTP 服务接口标准。它有些像 FastCGI 但他的设计 更容易实现。） –without-http_memcached_module 禁用 ngx_http_memcached_module 支持（该模块用来提供简单的缓存，以提高系统效率） -without-http_limit_zone_module 禁用 ngx_http_limit_zone_module 支持（该模块可以针对条件，进行会话的并发连接数控制） –without-http_limit_req_module 禁用 ngx_http_limit_req_module 支持（该模块允许你对于一个地址进行请求数量的限制用一个给定的 session 或一个特定的事件） –without-http_empty_gif_module 禁用 ngx_http_empty_gif_module 支持（该模块在内存中常驻了一个 1*1 的透明 GIF 图像，可以被非常快速的调用） –without-http_browser_module 禁用 ngx_http_browser_module 支持（该模块用来创建依赖于请求报头的值。如果浏览器为 modern ，","date":"2021-12-24","objectID":"/nginx02/:0:0","tags":["nginx","linux"],"title":"nginx 编译参数详解","uri":"/nginx02/"},{"categories":["web 服务器"],"content":"nginx 重写规则 rewrite模块 ","date":"2021-12-24","objectID":"/nginx04/:0:0","tags":["nginx","linux"],"title":"nginx 重写规则 rewrite模块","uri":"/nginx04/"},{"categories":["web 服务器"],"content":"语法 语法 默认值 使用字段 作用 break none server, location, if 完成当前设置的重写规则，停止执行其他的重写规则。 set variable value none server, location, if 为给定的变量设置一个特定值。 return code none server, location, if 停止处理并为客户端返回状态码。非标准的 444 状态码将关闭连接，不发送任何响应头。可以使用的状态码有：204，400，402-406，408，410, 411, 413, 416 与 500-504。如果状态码附带文字段落，该文本将被放置在响应主体。相反，如果状态码后面是一个 URL，该 URL 将成为 location 头补值。没有状态码的 URL 将被视为一个 302状态码。 rewrite_log on rewrite_log off server, location, if 启用时将在 error log 中记录 notice 级别的重写日志。 rewrite regex replacement flag none server, location, if 按照相关的正则表达式与字符串修改 URI，指令按照在配置文件中出现的顺序执行。可以在重写指令后面添加标记。注意：如果替换的字符串以 http://开头，请求将被重定向，并且不再执行多余的 rewrite 指令。尾部的标记(flag)可以是以下的值：last – 停止处理重写模块指令，之后搜索 location 与更改后的 URI 匹配.break – 完成重写指令。redirect – 返回 302 临时重定向，如果替换字段用 http://开头则被使用。permanent – 返回 301 永久重定向。 if (condition) { … } none server, location 尽量考虑使用 trp_files 代替。判断的条件可以有以下值 一个变量的名称：空字符传”“或者一些“0”开始的字符串为 false。 字符串比较：使用=或!=运算符 正则表达式匹配：使用~(区分大小写)和~(不区分大小写)，取反运算!~和!~。 文件是否存在：使用-f 和!-f 操作符 目录是否存在：使用-d 和!-d 操作符 文件、目录、符号链接是否存在：使用-e 和!-e 操作符 文件是否可执行：使用-x 和!-x 操作符'| ","date":"2021-12-24","objectID":"/nginx04/:1:0","tags":["nginx","linux"],"title":"nginx 重写规则 rewrite模块","uri":"/nginx04/"},{"categories":["web 服务器"],"content":"rewrite 重写规则 正则表达式 ","date":"2021-12-24","objectID":"/nginx04/:2:0","tags":["nginx","linux"],"title":"nginx 重写规则 rewrite模块","uri":"/nginx04/"},{"categories":["web 服务器"],"content":"nginx.conf 配置文件详解 # vim nginx.conf user nobody nobody; # 运行 nginx 的所属组和所有者 worker_processes 2; # 开启两个 nginx 工作进程,一般几个 CPU 核心就写几 error_log logs/error.log notice; # 错误日志路径 pid logs/nginx.pid; # pid 路径 events { worker_connections 1024; # 一个进程能同时处理 1024 个请求 } http { include mime.types; default_type application/octet-stream; log_format main ‘$remote_addr – $remote_user [$time_local] “$request” ‘ ‘$status $body_bytes_sent “$http_referer” ‘ ‘”$http_user_agent” “$http_x_forwarded_for”‘; access_log logs/access.log main; # 默认访问日志路径 sendfile on; keepalive_timeout 65; # keepalive 超市时间 # 开始配置一个域名,一个 server 配置段一般对应一个域名 server { listen 80; # # 在本机所有 ip 上监听 80,也可以写为 192.168.1.202:80,这样的话,就只监听 192.168.1.202 上的 80 口 server_name www.nbtyfood.com; # 域名 root /www/html/www.nbtyfood.com; # 站点根目录（程序目录） index index.html index.htm; # 索引文件 location / { # 可以有多个 location root /www/html/www.nbtyfood.com; # 站点根目录（程序目录） } error_page 500 502 503 504 /50x.html; # 定义错误页面,如果是 500 错误,则把站点根目录下的 50x.html 返回给用户 location = /50x.html { root /www/html/www.nbtyfood.com; } } # 开始配置站点 bbs.nbtyfood.com server { listen 80; server_name bbs.nbtyfood.com; root /www/html/bbs.nbtyfood.com; index index.html index.htm; # 索引文件 location / { root /www/html/bbs.nbtyfood.com; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /www/html/bbs.nbtyfood.com; } } } ","date":"2021-12-24","objectID":"/nginx03/:0:0","tags":["nginx","linux"],"title":"nginx.conf 配置文件详解","uri":"/nginx03/"},{"categories":["基础"],"content":"网络基础知识 ","date":"2021-12-23","objectID":"/network/:0:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"1、简述ISO/OSI七层模型的分层与作用 分层 作用 应用层 应用系统，提供用户服务 例如：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 表示层 把数据转换为能与接收者的系统格式兼容并适合传输的格式，数据表示，加密，压缩 会话层 负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。确定数据是否需要进行网络传递 分流网络传递还是本地保存 传输层 对数据分组，对报文进行分组(发送时)、组装(接收时)提供传输协议的选择：TCP (传输控制协议) :可靠的，面向连接的传输协议 (可靠，准确) (慢)UDP (用户数据报协议) :不可靠的，面向无连接的传输协议 (快) (不可靠)。端口封装，差错校验，滑动窗口，留空 网络层 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络资料。例如:互联网协议（IP）等。1.IP地址编址2.路由选择3.静态路由4.动态路由 数据链路层 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。1.MAC地址编址2.MAC地址寻址3.差错校验 物理层 物理层（Physical Layer）在局域网上发送数据帧（Data Frame）1.数据实际传输2.电气特性定义 ","date":"2021-12-23","objectID":"/network/:1:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"2、TCP/IP四层模型与作用？ 分层 协议 应用层 HTTP、HTTPS、FTP、Telnet、SSH、SMTP、DNS 传输层 TCP、UDP 网络层 ICMP、IGMP、IP、ARP、RARP 数据链路层、物理层 PPP、PPPOE ","date":"2021-12-23","objectID":"/network/:2:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"3、TCP协议与UDP协议工作在哪一层，作用是什么？ 传输层，对报文进行分组(发送时)、组装(接收时)提供 当进程需要传输可靠的数据时应使用TCP，当进程需要高效传输数据，可以忽略可靠性时应使用UDP协议。 ","date":"2021-12-23","objectID":"/network/:3:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"4、简述TCP三次握手的过程。 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 ","date":"2021-12-23","objectID":"/network/:4:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"5、简述TCP包头的内容。 源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址 序号/序列号（Sequense Number，SN）：在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。该字段表示本报文段所发送的数据的第一个字节的序号。初始序号称为 Init Sequense Number, ISN（序号/序列号这个字段很重要，大家留个印象，下文会详细讲解） 例如，一报文段的序号是 101，共有 100 字节的数据。这就表明：本报文段的数据的第一个字节的序号是 101，最后一个字节的序号是 200。显然，下一个报文段的数据序号应当从 201 开始，即下一个报文段的序号字段值应为 201。 确认号 ack：期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。 数据偏移（首部长度）：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。 保留：占 6 位，应置为 0，保留为今后使用。 标志位： 标志位 作用 URG 紧急指针（urgent pointer）有效。 ACK 确认序号有效 PSH 接收方应该尽快将这个报文交给应用层。 RST 重置连接。 SYN 发起一个新连接。 FIN 释放一个连接。 不要将确认序号Ack与标志位中的ACK搞混了。 确认方Ack=发起方Req+1，两端配对。 ","date":"2021-12-23","objectID":"/network/:5:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"6、简述TCP四次挥手的过程。 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 ","date":"2021-12-23","objectID":"/network/:6:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"7、172.22.141.231/26，该IP位于哪个网段？该网段拥有多少可用IP地址？广播地址是什么？ A类IP 10.1.1.1 标准子网掩码: 255.0.0.0 子网掩码二进制: 1111111.00000000.00000000.00000000 IP地址前8位是网络地址,后24位是主机地址 10.0.0.0-10.255.255.255 B类IP 172.16.1.1 标准子网掩码: 255.255.0.0 子网掩码二进制: 1111111.11111111.00000000.00000000 IP地址前16位是网络地址,后16位是主机地址 172.16.0.0-172.31.255.255 C类IP 192.168.1.1 标准子网掩码: 255.255.255.0 子网掩码二进制: 11111111.1111111.11111111.00000000 IP地址前24位是网络地址，后8位是主机地址 192.168.0.0-192.168.255.255 ","date":"2021-12-23","objectID":"/network/:7:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"8、简述IP地址的分类。 A类：（1.0.0.0-126.0.0.0）（默认子网掩码：255.0.0.0或 0xFF000000） 第一个字节为网络号，后三个字节为主机号。该类IP地址的最前面为“0”，所以地址的网络号取值于1~126之间。 一般用于大型网络。 B类：（128.1.0.0-191.255.0.0）（默认子网掩码：255.255.0.0或0xFFFF0000） 前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为“10”，所以地址的网络号取值于128~191之间。 一般用于中等规模网络。 C类：（192.0.1.0-223.255.255.0）（子网掩码：255.255.255.0或 0xFFFFFF00 前三个字节为网络号，最后一个字节为主机号。该类IP地址的最前面为“110”，所以地址的网络号取值于192~223之间。 一般用于小型网络。 D类：是多播地址。该类IP地址的最前面为“1110”，所以地址的网络号取值于224~239之间。一般用于多路广播用户[1] 。 E类：是保留地址。该类IP地址的最前面为“1111”，所以地址的网络号取值于240~255之间。 ","date":"2021-12-23","objectID":"/network/:8:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["基础"],"content":"9、简述私有IP地址的作用。 在全球范围内不具有唯一性，因此不能唯一标识一台联网的计算机。无需担心私有IP地址在全球范围内的冲突问题。 私有IP地址的路由信息不能对外发布，外部的IP数据包无法路由到私有IP地址的计算机上。 IP数据包中的源地址和目的地址是私有IP地址的, 不能在Internet上的路由器间进行存储转发的操作。 ","date":"2021-12-23","objectID":"/network/:9:0","tags":["运维"],"title":"网络基础知识","uri":"/network/"},{"categories":["docker"],"content":"docker 安装kong 网关 ","date":"2021-12-22","objectID":"/docker-kong/:0:0","tags":["docker"],"title":"docker 安装kong 网关","uri":"/docker-kong/"},{"categories":["docker"],"content":"建立数据库 创建网络 docker network create kong-net 建立数据库 docker run -d --name kong-database \\ --network=kong-net \\ -p 5432:5432 \\ -e \"POSTGRES_USER=kong\" \\ -e \"POSTGRES_DB=kong\" \\ -e \"POSTGRES_PASSWORD=kong123\" \\ postgres:9.6 创建kong数据 docker run --rm --network=kong-net \\ -e \"KONG_DATABASE=postgres\" \\ -e \"KONG_PG_HOST=kong-database\" \\ -e \"KONG_PG_PASSWORD=kong123\" \\ -e \"KONG_PASSWORD=kong123\" \\ kong:latest kong migrations bootstrap ","date":"2021-12-22","objectID":"/docker-kong/:1:0","tags":["docker"],"title":"docker 安装kong 网关","uri":"/docker-kong/"},{"categories":["docker"],"content":"创建 kong 创建kong gateway docker run -d --name kong \\ --network=kong-net \\ -e \"KONG_DATABASE=postgres\" \\ -e \"KONG_PG_HOST=kong-database\" \\ -e \"KONG_PG_USER=kong\" \\ -e \"KONG_PG_PASSWORD=kong123\" \\ -e \"KONG_CASSANDRA_CONTACT_POINTS=kong-database\" \\ -e \"KONG_PROXY_ACCESS_LOG=/dev/stdout\" \\ -e \"KONG_ADMIN_ACCESS_LOG=/dev/stdout\" \\ -e \"KONG_PROXY_ERROR_LOG=/dev/stderr\" \\ -e \"KONG_ADMIN_ERROR_LOG=/dev/stderr\" \\ -e \"KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\" \\ -p 8000:8000 \\ -p 8443:8443 \\ -p 127.0.0.1:8001:8001 \\ -p 127.0.0.1:8444:8444 \\ kong:latest ","date":"2021-12-22","objectID":"/docker-kong/:2:0","tags":["docker"],"title":"docker 安装kong 网关","uri":"/docker-kong/"},{"categories":["docker"],"content":"安装konga docker pull pantsel/konga:latest docker run --rm pantsel/konga:latest \\ -c prepare \\ -a postgres \\ -u postgresql://kong:kong123@172.18.0.1:5432/konga docker run -d -p 1337:1337 \\ --network kong-net \\ --name konga \\ -e \"NODE_ENV=production\" \\ -e \"DB_ADAPTER=postgres\" \\ -e \"DB_URI=postgresql://kong:kong123@172.18.0.1:5432/konga\" \\ pantsel/konga ","date":"2021-12-22","objectID":"/docker-kong/:3:0","tags":["docker"],"title":"docker 安装kong 网关","uri":"/docker-kong/"},{"categories":["docker"],"content":"搭建docker registry 镜像仓库 ","date":"2021-12-22","objectID":"/docker-registry/:0:0","tags":["docker"],"title":"搭建docker registry 镜像仓库","uri":"/docker-registry/"},{"categories":["docker"],"content":"获取镜像 docker pull registry:2.7.1 docker pull hyper/docker-registry-web ","date":"2021-12-22","objectID":"/docker-registry/:1:0","tags":["docker"],"title":"搭建docker registry 镜像仓库","uri":"/docker-registry/"},{"categories":["docker"],"content":"容器运行 mkdir -p /opt/data/registry docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --name registry registry:2.7.1 docker run -d -p 8080:8080 --name registry-web --link registry \\ -e REGISTRY_URL=http://192.168.99.146:5000/v2 \\ -e REGISTRY_TRUST_ANY_SSL=true \\ -e REGISTRY_BASIC_AUTH=\"GjhYGDGi2HhkJB\" \\ -e REGISTRY_NAME=192.168.99.146:5000 \\ hyper/docker-registry-web ","date":"2021-12-22","objectID":"/docker-registry/:2:0","tags":["docker"],"title":"搭建docker registry 镜像仓库","uri":"/docker-registry/"},{"categories":["docker"],"content":"上传容器 vim /etc/docker/daemon.json { \"insecure-registries\": [\"192.168.99.146:5000\"] } docker tag sjtfreaks/hogo-nginx:v1.1 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 docker push 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 ","date":"2021-12-22","objectID":"/docker-registry/:3:0","tags":["docker"],"title":"搭建docker registry 镜像仓库","uri":"/docker-registry/"},{"categories":["日常"],"content":"rsync 文件同步 rsync 是一个常用的Linux应用程序，用于文件同步 ","date":"2021-12-20","objectID":"/rsync/:0:0","tags":["daliy","rsync"],"title":"rsync 文件同步","uri":"/rsync/"},{"categories":["日常"],"content":"安装 # Debian or Ubuntu $ sudo apt-get install rsync # Red Hat $ sudo yum install rsync # Arch Linux $ sudo pacman -S rsync ","date":"2021-12-20","objectID":"/rsync/:1:0","tags":["daliy","rsync"],"title":"rsync 文件同步","uri":"/rsync/"},{"categories":["日常"],"content":"基本用法 使用 rsync 命令时，可以作为cp和mv命令的替代方法，将源目录同步到目标目录。 -r 表示递归，即包含子目录。注意，-r是必须的，否则 rsync 运行不会成功。source目录表示源目录，destination表示目标目录。 -a 参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新 rsync -r source destination 远程同步 rsync -av \u003c源地址\u003e/ \u003c用户名\u003e@\u003cip地址\u003e:/\u003c目标地址\u003e 友情地址：mysql迁移 ","date":"2021-12-20","objectID":"/rsync/:2:0","tags":["daliy","rsync"],"title":"rsync 文件同步","uri":"/rsync/"},{"categories":["k8s"],"content":"helm 安装 ","date":"2021-12-16","objectID":"/helm/:0:0","tags":["k8s"],"title":"helm 安装","uri":"/helm/"},{"categories":["k8s"],"content":"脚本安装 curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh #或者可以使用这个命令 curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash helm help ","date":"2021-12-16","objectID":"/helm/:1:0","tags":["k8s"],"title":"helm 安装","uri":"/helm/"},{"categories":["k8s"],"content":"二进制安装 wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz tar -zxvf helm-v3.7.2-linux-amd64.tar.gz cd helm-v3.7.2-linux-amd64 mv linux-amd64/helm /usr/local/bin/helm helm help ","date":"2021-12-16","objectID":"/helm/:2:0","tags":["k8s"],"title":"helm 安装","uri":"/helm/"},{"categories":["k8s"],"content":"k8s 部署loki日志 ","date":"2021-12-16","objectID":"/k8sloki/:0:0","tags":["k8s"],"title":"k8s 部署loki日志","uri":"/k8sloki/"},{"categories":["k8s"],"content":"helm 拉取loki #加源 helm repo add grafana https://grafana.github.io/helm-charts helm repo update #拉取 helm fetch grafana/loki-stack --untar --untardir . cd loki-stack # 生成 k8s 配置 helm template loki . \u003e loki.yaml # 部署（如果要修改默认配置必须要修改一下yaml） k3s kubectl apply -f loki.yaml ","date":"2021-12-16","objectID":"/k8sloki/:1:0","tags":["k8s"],"title":"k8s 部署loki日志","uri":"/k8sloki/"},{"categories":["日常"],"content":"自动判断跳转不同网站 根据用户目前的浏览器配置语言进行显示 供语言切换按钮，用户自定义选择不同的语言显示 根据识别用户的浏览器语言，自动判断并跳转到相应的语言网页，让你的网站更加灵动。 以下需要将代码放在 HTML 的内即可，然后自行制作多语言页面。 代码如下： \u003cscript type=\"text/javascript\"\u003e //获取用户语言的顺序是 //1.获取本地缓存里的内容 //2.用户浏览器的语言设置 //如果上面2个都没有获取到，就直接使用'en'作为用户选择的语言 var language = localStorage.getItem('locale') || window.navigator.language.toLowerCase() || 'en' //把用户的语言写入缓存，供下次获取使用 localStorage.setItem('locale', language) //判断用户的语言，跳转到不同的地方 if (language.indexOf(\"zh-\") !== -1) { window.location = '/zh-cn/index.html' } else if (language.indexOf('en') !== -1) { window.location = '/en/index.html' } else { //其它的都使用英文 window.location = '/en/index.html' } \u003c/script\u003e 核心代码 其实核心代码就是利用 navigator 的 language 属性 navigator.language ","date":"2021-12-16","objectID":"/auto/:0:0","tags":["javascript"],"title":"获取用户浏览器默认语言设置，自动判断跳转不同网站","uri":"/auto/"},{"categories":["日常"],"content":"第二种解决方案 可以通过获取用户的 IP，然后把 IP 放到 IP 库里查询所在地，从而加载对应的资源，这样的方案回更加准确！有的第三方会直接返回所在国家的编码，比如 cn / en 等就更好了 但是这样的方案也有一个弊端：如果用户通过科学上网，全局模式下，会被认为属于美国 / 日本等等（看梯子的 IP 而定了），那么会导致访问非常慢；但是这种偏差，很多翻墙的人都是了解的，没人会故意用美国的 IP 访问国内的淘宝 / 百度等网站的，除非是忘记切换回来了； IP 判断 市场上有很多 IP 判断的，拿 IP 倒是非常好做的一件事；比如我现在可以拿到用户访问本网站时候的 IP； ","date":"2021-12-16","objectID":"/auto/:1:0","tags":["javascript"],"title":"获取用户浏览器默认语言设置，自动判断跳转不同网站","uri":"/auto/"},{"categories":["基础"],"content":"linux服务基础知识 ","date":"2021-12-15","objectID":"/service/:0:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"1、哪些设置能够提升SSH远程管理的安全等级 ","date":"2021-12-15","objectID":"/service/:1:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"2、ssh连接时认证时间过长如何解决？ ","date":"2021-12-15","objectID":"/service/:2:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"3、scp和rsync进行远程文件复制有什么区别？ ","date":"2021-12-15","objectID":"/service/:3:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"4、请描述通过DHCP服务器获取IP地址的过程。 ","date":"2021-12-15","objectID":"/service/:4:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"5、简单描述FTP的主动模式和被动模式的区别？ ","date":"2021-12-15","objectID":"/service/:5:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"6、集群环境中，如何保证所有服务器之间的时间误差较小。 ","date":"2021-12-15","objectID":"/service/:6:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"7、请描述用户访问网站时DNS的解析过程。 ","date":"2021-12-15","objectID":"/service/:7:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"8、解释权威DNS和递归DNS的含义，并描述智能DNS的实现原理。 ","date":"2021-12-15","objectID":"/service/:8:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"9、公司里有一台服务器，需要在上面跑两个网站，并且其中一个网站需要更换新域名，请问如何处理？ 网站1：www.a.com 网站2：www.b.com（旧） www.d.com（新） 10、简述Apache的三种工作模式？ 11、请写出工作中常见的Apache优化策略。 12、有哪些技术可以提高网站的安全和效率？ 13、Apache和Nginx各有什么优缺点，应该如何选择？ 14、为什么Nginx的并发能力强，资源消耗低？ 15、写出几个Nginx的常用模块，并描述其功能。 16、请解释Nginx是如何连接PHP进行页面解析的？ 17、请描述Nginx和Tomcat之间的数据传输过程？ 18、请写出几个常见的HTTP状态码，并解释出现原因。 ","date":"2021-12-15","objectID":"/service/:9:0","tags":["运维"],"title":"linux服务基础知识","uri":"/service/"},{"categories":["基础"],"content":"mysql基础知识 ","date":"2021-12-15","objectID":"/mysql/:0:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"1、库表student.report,有3个字段，姓名、学科、成绩，记录如下，根据要求完成SQL语句： Name Subject Result 李白 Math 95 张三 English 83 王五 Math 79 李六 Math 85 张二 English 74 查询姓李的同学的个数。 查询表中数学成绩大于80的前2名同学的名字，并按分数从大到小的顺序排列。 ","date":"2021-12-15","objectID":"/mysql/:1:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"2、MYSQL集群一主多从，主库宕机，如何合理切换到从库，其它从库如何处理？ ","date":"2021-12-15","objectID":"/mysql/:2:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"3、单台MySQL达到性能瓶颈时，如何击碎性能瓶颈？ ","date":"2021-12-15","objectID":"/mysql/:3:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"4、MySQL什么时候创建索引？ ","date":"2021-12-15","objectID":"/mysql/:4:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"5、误操作drop语句导致数据库数据破坏，请给出恢复的实际大体步骤。 ","date":"2021-12-15","objectID":"/mysql/:5:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"6、如何保证Redis能永久保存数据？ ","date":"2021-12-15","objectID":"/mysql/:6:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"7、如何利用Redis对MySQL进行性能优化？ ","date":"2021-12-15","objectID":"/mysql/:7:0","tags":["运维"],"title":"mysql基础知识","uri":"/mysql/"},{"categories":["基础"],"content":"shell基础知识 ","date":"2021-12-15","objectID":"/shell/:0:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["基础"],"content":"1、有一个b.txt文本(内容如下)，要求将所有域名截取出来，并统计重复域名出现的次数： http://www.baidu.com/index.html https://www.atguigu.com/index.html http://www.sina.com.cn/1024.html https://www.atguigu.com/2048.html http://www.sina.com.cn/4096.html https://www.atguigu.com/8192.html ","date":"2021-12-15","objectID":"/shell/:1:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["基础"],"content":"2、统计当前服务器正在连接的IP地址，并按连接次数排序 ","date":"2021-12-15","objectID":"/shell/:2:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["基础"],"content":"3、使用循环在/atguigu目录下创建10个txt文件，要求文件名称由6位随机小写字母加固定字符串（_gg）组成，例如：pzjebg_gg.txt。 ","date":"2021-12-15","objectID":"/shell/:3:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["基础"],"content":"4、生成随机数字。 ","date":"2021-12-15","objectID":"/shell/:4:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["基础"],"content":"5、批量检查多个网站是否可以正常访问，要求使用shell数组实现，检测策略尽量模拟用户真实访问模式。 http://www.atguigu.com http://www.gulixueyuan.com http://www.baidu.com ","date":"2021-12-15","objectID":"/shell/:5:0","tags":["运维"],"title":"shell基础知识","uri":"/shell/"},{"categories":["k8s"],"content":"Kubernetes 创建nfs存储类 首先你需要在别的终端上创建nfs服务并能提供nfs访问 Kubernetes 不包含内部 NFS 驱动。你需要使用外部驱动为 NFS 创建 StorageClass。 https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner 安装nfs驱动 ","date":"2021-12-13","objectID":"/k8snfs/:0:0","tags":["k8s"],"title":"Kubernetes 创建nfs存储类","uri":"/k8snfs/"},{"categories":["k8s"],"content":"安装nfs驱动 #安装nfs客户端 apt-get install nfs-common git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git cd nfs-subdir-external-provisioner/deploy k3s kubectl create -f rbac.yaml vim deployment.yaml 编辑 deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: k8s-sigs.io/nfs-subdir-external-provisioner - name: NFS_SERVER value: 192.168.99.235 - name: NFS_PATH value: /volume2/nfs-k8s volumes: - name: nfs-client-root nfs: server: 192.168.99.235 path: /volume2/nfs-k8s 定义存储类 k3s kubectl create -f deployment.yaml k3s kubectl create -f class.yaml ","date":"2021-12-13","objectID":"/k8snfs/:1:0","tags":["k8s"],"title":"Kubernetes 创建nfs存储类","uri":"/k8snfs/"},{"categories":["k8s"],"content":"测试存储是否正常 k3s kubectl create -f test-claim.yaml -f test-pod.yaml k3s kubectl delete -f test-claim.yaml -f test-pod.yaml ","date":"2021-12-13","objectID":"/k8snfs/:2:0","tags":["k8s"],"title":"Kubernetes 创建nfs存储类","uri":"/k8snfs/"},{"categories":["k8s"],"content":"创建有状态pods（mysql） 创建mysql-deployment.yaml apiVersion: v1 kind: Service metadata: name: mysql spec: ports: - port: 3306 targetPort: 3306 selector: app: mysql clusterIP: None type: LoadBalancer --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql spec: selector: matchLabels: app: mysql strategy: type: Recreate template: metadata: labels: app: mysql spec: containers: - image: mysql:5.7 name: mysql env: # Use secret in real usage - name: MYSQL_ROOT_PASSWORD value: password ports: - containerPort: 3306 name: mysql volumeMounts: - name: mysql-persistent-storage mountPath: /var/lib/mysql volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: mysql-pv-claim 创建mysql-pv.yaml apiVersion: v1 kind: PersistentVolume metadata: name: mysql-pv-volume spec: storageClassName: managed-nfs-storage capacity: storage: 20Gi accessModes: - ReadWriteOnce nfs: server: 192.168.99.235 path: \"/volume2/nfs-k8s\" --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysql-pv-claim spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteMany resources: requests: storage: 20Gi ","date":"2021-12-13","objectID":"/k8snfs/:3:0","tags":["k8s"],"title":"Kubernetes 创建nfs存储类","uri":"/k8snfs/"},{"categories":["k8s"],"content":"部署 mysql k3s kubectl apply -f mysql-pv.yaml k3s kubectl apply -f mysql-deployment.yaml k3s kubectl describe deployment mysql ","date":"2021-12-13","objectID":"/k8snfs/:4:0","tags":["k8s"],"title":"Kubernetes 创建nfs存储类","uri":"/k8snfs/"},{"categories":["web 服务器"],"content":"nginx 日志配置 ","date":"2021-12-13","objectID":"/nginx01/:0:0","tags":["nginx","linux"],"title":"nginx 日志格式整理","uri":"/nginx01/"},{"categories":["web 服务器"],"content":"语法 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 设置访问日志 access_log off; # 关闭访问日志 例子： access_log /var/logs/nginx-access.log access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m ","date":"2021-12-13","objectID":"/nginx01/:1:0","tags":["nginx","linux"],"title":"nginx 日志格式整理","uri":"/nginx01/"},{"categories":["web 服务器"],"content":"使用log_format 自定义日志格式 Nginx预定义了名为combined日志格式，如果没有明确指定日志格式默认使用该格式： log_format combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; 如果不想使用Nginx预定义的格式，可以通过log_format指令来自定义。 ","date":"2021-12-13","objectID":"/nginx01/:2:0","tags":["nginx","linux"],"title":"nginx 日志格式整理","uri":"/nginx01/"},{"categories":["web 服务器"],"content":"语法 log_format name [escape=default|json] string ...; 变量 含义 $bytes_sent 发送给客户端的总字节数 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 $connection 连接序列号 $connection_requests 当前通过连接发出的请求数量 $msec 日志写入时间，单位为秒，精度是毫秒 $pipe 如果请求是通过http流水线发送，则其值为\"p\"，否则为“.\" $request_length 请求长度（包括请求行，请求头和请求体） $request_time 请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止 $status 响应状态码 $time_iso8601 标准格式的本地时间,形如“2017-05-24T18:31:27+08:00” $time_local 通用日志格式下的本地时间，如\"24/May/2017:18:31:27 +0800\" $http_referer 请求的referer地址。 $http_user_agent 客户端浏览器信息。 $remote_addr 客户端IP $http_x_forwarded_for 当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。 $request 完整的原始请求行，如 “GET / HTTP/1.1” $remote_user 客户端用户名称，针对启用了用户认证的请求 $request_uri 完整的请求地址，如 “https://daojia.com/\" 例子： access_log /var/logs/nginx-access.log main log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; ","date":"2021-12-13","objectID":"/nginx01/:2:1","tags":["nginx","linux"],"title":"nginx 日志格式整理","uri":"/nginx01/"},{"categories":["日常"],"content":"linux系统开启root权限 修改ssh服务配置文件 sudo su - sudo vim /etc/ssh/sshd_config 增加权限 在# Authentication: 下输入 PermitRootLogin yes 更改root密码，重启服务 sudo passwd root service sshd restart ","date":"2021-12-12","objectID":"/resetsystem/:0:0","tags":["linux"],"title":"linux系统开启root权限","uri":"/resetsystem/"},{"categories":["数据库"],"content":"mysql 学习笔记（1） 本文章不涉及到关于mysql开放上的问题，主要记录关于mysql出现的问题，以及如何去维护mysql数据的日常。 ","date":"2021-12-12","objectID":"/mysql01/:0:0","tags":["mysql"],"title":"mysql 笔记（1）","uri":"/mysql01/"},{"categories":["数据库"],"content":"mysql各类信息的收集 收集变量信息 show global variables; 收集进程信息 show PROCESSLIST; 收集错误日志 show global variables like 'log_error'; 收集慢日志信息 show global variables like 'slow_querry_log_file'; 收集锁信息，高峰时期运行三次，每次间隔10s SELECT locked_table, locked_index, locked_type, blocking_pid, T2.USER blocking_user, T2.HOST blocking_host, blocking_lock_mode, blocking_trx_rows_modified, waiting_pid, T3.USER waiting_user, T3.HOST waiting_host, waiting_lock_mode, waiting_trx_row_modified, wait_age_secs, waiting_query FROM sys.x$innodb_lock_waits T1 LEFT JOIN INFROMATION_SCHEMA.processlist T2 ON T1.blocking_pid=T2.ID LEFT JOIN INFROMATION_SCHEMA.processlist T3 ON T3.ID=T1.waiting_pid; 收集mysql状态信息 show global status; show engine innodb status; show engine innodb mutex; ","date":"2021-12-12","objectID":"/mysql01/:1:0","tags":["mysql"],"title":"mysql 笔记（1）","uri":"/mysql01/"},{"categories":["数据库"],"content":"mysql 基础语法 连接数据库 mysql -u \u003c用户名\u003e -p 创建数据库 CREATE DATABASE \u003c数据库名称\u003e; 删除数据库 drop database \u003c数据库名称\u003e; 选择数据库 use \u003c数据库名称\u003e; 创建表 CREATE table \u003c数据表名\u003e ( \u003c字段名1\u003e \u003c数据类型\u003e [约束条件], \u003c字段名2\u003e \u003c数据类型\u003e [约束条件], \u003c字段名3\u003e \u003c数据类型\u003e [约束条件] ) #例如 CREATE TABLE IF NOT EXISTS `nbtyfood_tbl`( `nbtyfood_id` INT UNSIGNED AUTO_INCREMENT, `nbtyfood_title` VARCHAR(100) NOT NULL, `nbtyfood_author` VARCHAR(40) NOT NULL, `submission_date` DATE, PRIMARY KEY ( `nbtyfood_id` ) )ENGINE=InnoDB DEFAULT CHARSET=utf8; 删除表 DROP TABLE \u003c数据表名\u003e; 插入数据 INSERT INTO table_name ( field1, field2,...fieldN ) VALUES value1, value2,...valueN ); 更新数据 UPDATE \u003c数据表名\u003e SET \u003c字段名1\u003e='更新' WHERE \u003c字段名2\u003e=3; 删除数据 DELETE FROM \u003c数据表名\u003e WHERE \u003c字段名2\u003e=3; 查询数据 select * from \u003c数据表名\u003e; ","date":"2021-12-12","objectID":"/mysql01/:2:0","tags":["mysql"],"title":"mysql 笔记（1）","uri":"/mysql01/"},{"categories":["日常"],"content":"163企业邮箱设置教程 请进入这个网站 https://qiye.163.com/help/l-11.html ","date":"2021-12-10","objectID":"/qyyemail163/:0:0","tags":["daliy"],"title":"163企业邮箱设置教程","uri":"/qyyemail163/"},{"categories":["gitlab"],"content":"git技巧 Git 是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 “页面内查找” 的方式进行快速查询：Ctrl/Command+f。 ","date":"2021-12-10","objectID":"/gitlab/:0:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"开卷必读 如果之前未使用过 Git，可以学习 Git 小白教程入门 一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 如果喜欢这个项目，欢迎 Star、提交 Pr、反馈问题😊 ","date":"2021-12-10","objectID":"/gitlab/:1:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"目录 脑图 展示帮助信息 回到远程仓库的状态 重设第一个commit 查看冲突文件列表 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 查看远程分支和本地分支的对应关系 远程删除了分支本地也想删除 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit 修改上一个 commit 的描述 查看 commit 历史 显示本地更新过 HEAD 的 git 命令记录 修改作者名 修改远程仓库的 url 增加远程仓库 列出所有远程仓库 查看两个星期内的改动 把 A 分支的某一个 commit，放到 B 分支上 给 git 命令起别名 存储当前的修改，但不用提交 commit 保存当前状态，包括 untracked 的文件 展示所有 stashes 回到某个 stash 的状态 回到最后一个 stash 的状态，并删除这个 stash 删除所有的 stash 从 stash 中拿出某个文件的修改 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 强制删除 untracked 的目录 展示简化的 commit 历史 查看某段代码是谁写的 把某一个分支导出成一个文件 从包中导入分支 执行 rebase 之前自动 stash 从远程仓库根据 ID，拉下某一状态，到本地分支 详细展示一行中的修改 清除 .gitignore 文件中记录的文件 展示所有 alias 和 configs 展示忽略的文件 commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit 在 commit log 中显示 GPG 签名 删除全局设置 新建并切换到新分支上，同时这个分支没有任何 commit 展示任意分支某一文件的内容 clone 下来指定的单一分支 clone 最新一次提交 忽略某个文件的改动 忽略文件的权限变化 以最后提交的顺序列出所有 Git 分支 在 commit log 中查找相关内容 把暂存区的指定 file 放到工作区中 强制推送 git 配置 http 和 socks 代理 git 配置 ssh 代理 优雅的Commit信息 commit工具 声明 ","date":"2021-12-10","objectID":"/gitlab/:2:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示帮助信息 git help -g The command output as below: The common Git guides are: attributes Defining attributes per path cli Git command-line interface and conventions core-tutorial A Git core tutorial for developers cvs-migration Git for CVS users diffcore Tweaking diff output everyday A useful minimum set of commands for Everyday Git glossary A Git Glossary hooks Hooks used by Git ignore Specifies intentionally untracked files to ignore modules Defining submodule properties namespaces Git namespaces repository-layout Git Repository Layout revisions Specifying revisions and ranges for Git tutorial A tutorial introduction to Git tutorial-2 A tutorial introduction to Git: part two workflows An overview of recommended workflows with Git 'git help -a' and 'git help -g' list available subcommands and some concept guides. See 'git help \u003ccommand\u003e' or 'git help \u003cconcept\u003e' to read about a specific subcommand or concept. ","date":"2021-12-10","objectID":"/gitlab/:3:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"回到远程仓库的状态 抛弃本地所有的修改，回到远程仓库的状态。 git fetch --all \u0026\u0026 git reset --hard origin/master ","date":"2021-12-10","objectID":"/gitlab/:4:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"重设第一个 commit 也就是把所有的改动都重新放回工作区，并清空所有的 commit，这样就可以重新提交第一个 commit 了 git update-ref -d HEAD ","date":"2021-12-10","objectID":"/gitlab/:5:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看冲突文件列表 展示工作区的冲突文件列表 git diff --name-only --diff-filter=U ","date":"2021-12-10","objectID":"/gitlab/:6:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示工作区和暂存区的不同 输出工作区和暂存区的 different (不同)。 git diff 还可以展示本地仓库中任意两个 commit 之间的文件变动： git diff \u003ccommit-id\u003e \u003ccommit-id\u003e ","date":"2021-12-10","objectID":"/gitlab/:7:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示暂存区和最近版本的不同 输出暂存区和本地最近的版本 (commit) 的 different (不同)。 git diff --cached ","date":"2021-12-10","objectID":"/gitlab/:8:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示暂存区、工作区和最近版本的不同 输出工作区、暂存区 和本地最近的版本 (commit) 的 different (不同)。 git diff HEAD ","date":"2021-12-10","objectID":"/gitlab/:9:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"快速切换到上一个分支 git checkout - ","date":"2021-12-10","objectID":"/gitlab/:10:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除已经合并到 master 的分支 git branch --merged master | grep -v '^\\*\\| master' | xargs -n 1 git branch -d ","date":"2021-12-10","objectID":"/gitlab/:11:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示本地分支关联远程仓库的情况 git branch -vv ","date":"2021-12-10","objectID":"/gitlab/:12:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"关联远程分支 关联之后，git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接：git push，不需要指定远程仓库了。 git branch -u origin/mybranch 或者在 push 时加上 -u 参数 git push origin/mybranch -u ","date":"2021-12-10","objectID":"/gitlab/:13:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"列出所有远程分支 -r 参数相当于：remote git branch -r ","date":"2021-12-10","objectID":"/gitlab/:14:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"列出本地和远程分支 -a 参数相当于：all git branch -a ","date":"2021-12-10","objectID":"/gitlab/:15:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看远程分支和本地分支的对应关系 git remote show origin ","date":"2021-12-10","objectID":"/gitlab/:16:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"远程删除了分支本地也想删除 git remote prune origin ","date":"2021-12-10","objectID":"/gitlab/:17:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:18:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"从远程分支中创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e origin/\u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:19:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除本地分支 git branch -d \u003clocal-branchname\u003e ","date":"2021-12-10","objectID":"/gitlab/:20:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除远程分支 git push origin --delete \u003cremote-branchname\u003e 或者 git push origin :\u003cremote-branchname\u003e ","date":"2021-12-10","objectID":"/gitlab/:21:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"重命名本地分支 git branch -m \u003cnew-branch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:22:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看标签 git tag 展示当前分支的最近的 tag git describe --tags --abbrev=0 ","date":"2021-12-10","objectID":"/gitlab/:23:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看标签详细信息 git tag -ln ","date":"2021-12-10","objectID":"/gitlab/:24:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"本地创建标签 git tag \u003cversion-number\u003e 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag： $ git tag -a \u003cversion-number\u003e -m \"v1.0 发布(描述)\" \u003ccommit-id\u003e ","date":"2021-12-10","objectID":"/gitlab/:25:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"推送标签到远程仓库 首先要保证本地创建好了标签才可以推送标签到远程仓库： git push origin \u003clocal-version-number\u003e 一次性推送所有标签，同步到远程仓库： git push origin --tags ","date":"2021-12-10","objectID":"/gitlab/:26:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除本地标签 git tag -d \u003ctag-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:27:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除远程标签 git push origin --delete tag \u003ctagname\u003e ","date":"2021-12-10","objectID":"/gitlab/:28:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"切回到某个标签 一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回到某一标签下的状态： git checkout -b branch_name tag_name ","date":"2021-12-10","objectID":"/gitlab/:29:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"放弃工作区的修改 git checkout \u003cfile-name\u003e 放弃所有修改： git checkout . ","date":"2021-12-10","objectID":"/gitlab/:30:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"恢复删除的文件 git rev-list -n 1 HEAD -- \u003cfile_path\u003e #得到 deleting_commit git checkout \u003cdeleting_commit\u003e^ -- \u003cfile_path\u003e #回到删除文件 deleting_commit 之前的状态 ","date":"2021-12-10","objectID":"/gitlab/:31:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"以新增一个 commit 的方式还原某一个 commit 的修改 git revert \u003ccommit-id\u003e ","date":"2021-12-10","objectID":"/gitlab/:32:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"回到某个 commit 的状态，并删除后面的 commit 和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit git reset \u003ccommit-id\u003e #默认就是-mixed参数。 git reset --mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便和HEAD相匹配，但是也到此为止。工作区不会被更改。 git reset --soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之前保持一致。如果还要提交，直接commit即可 git reset --hard \u003ccommit-id\u003e #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定commit-id版本的内容 ","date":"2021-12-10","objectID":"/gitlab/:33:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"修改上一个 commit 的描述 如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit git commit --amend ","date":"2021-12-10","objectID":"/gitlab/:34:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看 commit 历史 git log ","date":"2021-12-10","objectID":"/gitlab/:35:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看某段代码是谁写的 blame 的意思为‘责怪’，你懂的。 git blame \u003cfile-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:36:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"显示本地更新过 HEAD 的 git 命令记录 每次更新了 HEAD 的 git 命令比如 commit、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。 这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之后的状态。 git reflog ","date":"2021-12-10","objectID":"/gitlab/:37:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"修改作者名 git commit --amend --author='Author Name \u003cemail@address.com\u003e' ","date":"2021-12-10","objectID":"/gitlab/:38:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"修改远程仓库的 url git remote set-url origin \u003cURL\u003e ","date":"2021-12-10","objectID":"/gitlab/:39:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"增加远程仓库 git remote add origin \u003cremote-url\u003e ","date":"2021-12-10","objectID":"/gitlab/:40:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"列出所有远程仓库 git remote ","date":"2021-12-10","objectID":"/gitlab/:41:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"查看两个星期内的改动 git whatchanged --since='2 weeks ago' ","date":"2021-12-10","objectID":"/gitlab/:42:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"把 A 分支的某一个 commit，放到 B 分支上 这个过程需要 cherry-pick 命令，参考 git checkout \u003cbranch-name\u003e \u0026\u0026 git cherry-pick \u003ccommit-id\u003e ","date":"2021-12-10","objectID":"/gitlab/:43:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"给 git 命令起别名 简化命令 git config --global alias.\u003chandle\u003e \u003ccommand\u003e 比如：git status 改成 git st，这样可以简化命令 git config --global alias.st status ","date":"2021-12-10","objectID":"/gitlab/:44:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"存储当前的修改，但不用提交 commit 详解可以参考廖雪峰老师的 git 教程 git stash ","date":"2021-12-10","objectID":"/gitlab/:45:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"保存当前状态，包括 untracked 的文件 untracked 文件：新建的文件 git stash -u ","date":"2021-12-10","objectID":"/gitlab/:46:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示所有 stashes git stash list ","date":"2021-12-10","objectID":"/gitlab/:47:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"回到某个 stash 的状态 git stash apply \u003cstash@{n}\u003e ","date":"2021-12-10","objectID":"/gitlab/:48:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"回到最后一个 stash 的状态，并删除这个 stash git stash pop ","date":"2021-12-10","objectID":"/gitlab/:49:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除所有的 stash git stash clear ","date":"2021-12-10","objectID":"/gitlab/:50:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"从 stash 中拿出某个文件的修改 git checkout \u003cstash@{n}\u003e -- \u003cfile-path\u003e ","date":"2021-12-10","objectID":"/gitlab/:51:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示所有 tracked 的文件 git ls-files -t ","date":"2021-12-10","objectID":"/gitlab/:52:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示所有 untracked 的文件 git ls-files --others ","date":"2021-12-10","objectID":"/gitlab/:53:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示所有忽略的文件 git ls-files --others -i --exclude-standard ","date":"2021-12-10","objectID":"/gitlab/:54:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"强制删除 untracked 的文件 可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。clean 命令，注意两点： clean 后，删除的文件无法找回 不会影响 tracked 的文件的改动，只会删除 untracked 的文件 git clean \u003cfile-name\u003e -f ","date":"2021-12-10","objectID":"/gitlab/:55:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"强制删除 untracked 的目录 可以用来删除新建的目录，注意:这个命令也可以用来删除 untracked 的文件。详情见上一条 git clean \u003cdirectory-name\u003e -df ","date":"2021-12-10","objectID":"/gitlab/:56:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示简化的 commit 历史 git log --pretty=oneline --graph --decorate --all ","date":"2021-12-10","objectID":"/gitlab/:57:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"把某一个分支导出成一个文件 git bundle create \u003cfile\u003e \u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:58:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"从包中导入分支 新建一个分支，分支内容就是上面 git bundle create 命令导出的内容 git clone repo.bundle \u003crepo-dir\u003e -b \u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:59:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"执行 rebase 之前自动 stash git rebase --autostash ","date":"2021-12-10","objectID":"/gitlab/:60:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"从远程仓库根据 ID，拉下某一状态，到本地分支 git fetch origin pull/\u003cid\u003e/head:\u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:61:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"详细展示一行中的修改 git diff --word-diff ","date":"2021-12-10","objectID":"/gitlab/:62:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"清除 gitignore 文件中记录的文件 git clean -X -f ","date":"2021-12-10","objectID":"/gitlab/:63:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示所有 alias 和 configs 注意： config 分为：当前目录（local）和全局（golbal）的 config，默认为当前目录的 config git config --local --list (当前目录) git config --global --list (全局) ","date":"2021-12-10","objectID":"/gitlab/:64:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示忽略的文件 git status --ignored ","date":"2021-12-10","objectID":"/gitlab/:65:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit git log Branch1 ^Branch2 ","date":"2021-12-10","objectID":"/gitlab/:66:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"在 commit log 中显示 GPG 签名 git log --show-signature ","date":"2021-12-10","objectID":"/gitlab/:67:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"删除全局设置 git config --global --unset \u003centry-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:68:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"新建并切换到新分支上，同时这个分支没有任何 commit 相当于保存修改，但是重写 commit 历史 git checkout --orphan \u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:69:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"展示任意分支某一文件的内容 git show \u003cbranch-name\u003e:\u003cfile-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:70:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"clone 下来指定的单一分支 git clone -b \u003cbranch-name\u003e --single-branch https://github.com/user/repo.git ","date":"2021-12-10","objectID":"/gitlab/:71:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"clone 最新一次提交 只会 clone 最近一次提交，将减少 clone 时间 git clone --depth=1 https://github.com/user/repo.git ","date":"2021-12-10","objectID":"/gitlab/:72:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"忽略某个文件的改动 关闭 track 指定文件的改动，也就是 Git 将不会在记录这个文件的改动 git update-index --assume-unchanged path/to/file 恢复 track 指定文件的改动 git update-index --no-assume-unchanged path/to/file ","date":"2021-12-10","objectID":"/gitlab/:73:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"忽略文件的权限变化 不再将文件的权限变化视作改动 git config core.fileMode false ","date":"2021-12-10","objectID":"/gitlab/:74:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"以最后提交的顺序列出所有 Git 分支 最新的放在最上面 git for-each-ref --sort=-committerdate --format='%(refname:short)' refs/heads/ ","date":"2021-12-10","objectID":"/gitlab/:75:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"在 commit log 中查找相关内容 通过 grep 查找，given-text：所需要查找的字段 git log --all --grep='\u003cgiven-text\u003e' ","date":"2021-12-10","objectID":"/gitlab/:76:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"把暂存区的指定 file 放到工作区中 不添加参数，默认是 -mixed git reset \u003cfile-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:77:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"强制推送 git push -f \u003cremote-name\u003e \u003cbranch-name\u003e ","date":"2021-12-10","objectID":"/gitlab/:78:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"git 配置 http 和 socks 代理 git config --global https.proxy 'http://127.0.0.1:8001' # 适用于 privoxy 将 socks 协议转为 http 协议的 http 端口 git config --global http.proxy 'http://127.0.0.1:8001' git config --global socks.proxy \"127.0.0.1:1080\" ","date":"2021-12-10","objectID":"/gitlab/:79:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"git 配置 ssh 代理 $ cat ~/.ssh/config Host gitlab.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p # 直接使用 shadowsocks 提供的 socks5 代理端口 Host github.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p ","date":"2021-12-10","objectID":"/gitlab/:80:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"脑图 ","date":"2021-12-10","objectID":"/gitlab/:81:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"优雅的Commit信息 使用Angular团队提交规范 主要有以下组成 标题行: 必填, 描述主要修改类型和内容 主题内容: 描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释: 放 Breaking Changes 或 Closed Issues 常用的修改项 type: commit 的类型 feat: 新特性 fix: 修改问题 refactor: 代码重构 docs: 文档修改 style: 代码格式修改, 注意不是 css 修改 test: 测试用例修改 chore: 其他修改, 比如构建流程, 依赖管理. scope: commit 影响的范围, 比如: route, component, utils, build… subject: commit 的概述 body: commit 具体修改内容, 可以分为多行 footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接. ","date":"2021-12-10","objectID":"/gitlab/:82:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["gitlab"],"content":"commit工具 可以使用cz-cli工具代替 git commit 全局安装 npm install -g commitizen cz-conventional-changelog echo '{ \"path\": \"cz-conventional-changelog\" }' \u003e ~/.czrc 全局安装后使用 git cz 代替 git commit就可以了,如下图 ⬆ 返回顶部 ","date":"2021-12-10","objectID":"/gitlab/:83:0","tags":["gitlab"],"title":"git技巧","uri":"/gitlab/"},{"categories":["docker"],"content":"docker image镜像上传 登入docker hub，在https://hub.docker.com上注册你的账号。 docker login username：#输入你的用户名 password：#输入你的密码 ","date":"2021-12-09","objectID":"/dockerimage/:0:0","tags":["docker"],"title":"docker image镜像上传","uri":"/dockerimage/"},{"categories":["docker"],"content":"上传镜像 docker tag nginx:hugo sjtfreaks/hogo-nginx:v1 docker push sjtfreaks/hogo-nginx:v1 ","date":"2021-12-09","objectID":"/dockerimage/:1:0","tags":["docker"],"title":"docker image镜像上传","uri":"/dockerimage/"},{"categories":["docker"],"content":"docker 进阶使用 dockerfile和docker compose的配置 Dockerfile 使用 Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 例子： FROM nginx RUN echo '这是一个本地构建的nginx镜像' \u003e /usr/share/nginx/html/index.html 保存Dockerfile文件并在本地路径执行 docker build -t nginx:v1-test . docker run -name docker run --name nginx-test -d -p 8080:80 nginx:v1-test 浏览nginx页面确认更新内容 curl 127.0.0.1:8080 输出： 这是一个本地构建的nginx镜像 ","date":"2021-12-09","objectID":"/docker01/:0:0","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"Docker命令详解 ","date":"2021-12-09","objectID":"/docker01/:1:0","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"COPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 COPY [--chown=\u003cuser\u003e:\u003cgroup\u003e] \u003c源路径1\u003e... \u003c目标路径\u003e COPY [--chown=\u003cuser\u003e:\u003cgroup\u003e] [\"\u003c源路径1\u003e\",... \"\u003c目标路径\u003e\"] \u003c源路径\u003e：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如： COPY hom* /mydir/ COPY hom?.txt /mydir/ ","date":"2021-12-09","objectID":"/docker01/:1:1","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"FROM FROM：定制的镜像都是基于 FROM 的镜像 FROM nginx ","date":"2021-12-09","objectID":"/docker01/:1:2","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"RUN RUN：用于执行后面跟着的命令行命令 shell： RUN \u003c命令行命令\u003e # \u003c命令行命令\u003e 等同于，在终端操作的 shell 命令。 exec： RUN [\"可执行文件\", \"参数1\", \"参数2\"] # 例如： # RUN [\"./test.php\", \"dev\", \"offline\"] 等价于 RUN ./test.php dev offline ","date":"2021-12-09","objectID":"/docker01/:1:3","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"ADD ADD 指令和 COPY 的使用格类似 ADD 的优点：在执行 \u003c源文件\u003e 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 \u003c目标路径\u003e。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 ","date":"2021-12-09","objectID":"/docker01/:1:4","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"CMD 类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build。 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。 CMD \u003cshell 命令\u003e CMD [\"\u003c可执行文件或命令\u003e\",\"\u003cparam1\u003e\",\"\u003cparam2\u003e\",...] CMD [\"\u003cparam1\u003e\",\"\u003cparam2\u003e\",...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 ","date":"2021-12-09","objectID":"/docker01/:1:5","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["docker"],"content":"通过dockerfile文件封装hugo dokcerfile文件 FROM nginx:1.21 COPY public/ /usr/share/nginx/html docker.sh文件 #/!bin/bash echo \"删除旧的docker\" docker ps docker stop nginx-hugo docker rm nginx-hugo docker rmi nginx:hugo echo \"生成新的docker\" hugo -t LoveIt -D docker build -t nginx:hugo . docker run --name nginx-hugo -d -p 8080:80 nginx:hugo echo \"显示端口\" netstat -lntp 执行脚本： sh update.sh ","date":"2021-12-09","objectID":"/docker01/:2:0","tags":["docker","dockerfile","DockerCompose"],"title":"docker进阶使用","uri":"/docker01/"},{"categories":["k8s"],"content":"Kubernetes k8s 组件 ","date":"2021-12-09","objectID":"/kubernetes/:0:0","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 ","date":"2021-12-09","objectID":"/kubernetes/:1:0","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"kube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 ","date":"2021-12-09","objectID":"/kubernetes/:1:1","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"etcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 ","date":"2021-12-09","objectID":"/kubernetes/:1:2","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"kube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 ","date":"2021-12-09","objectID":"/kubernetes/:1:3","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"kube-controller-manager 运行控制器进程的控制平面组件。 ","date":"2021-12-09","objectID":"/kubernetes/:1:4","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"cloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。 ","date":"2021-12-09","objectID":"/kubernetes/:1:5","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"Node 组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 ","date":"2021-12-09","objectID":"/kubernetes/:2:0","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"kubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 ","date":"2021-12-09","objectID":"/kubernetes/:2:1","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"kube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 ","date":"2021-12-09","objectID":"/kubernetes/:2:2","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["k8s"],"content":"容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。 Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 ","date":"2021-12-09","objectID":"/kubernetes/:2:3","tags":["k8s"],"title":"Kubernetes k8s 组件","uri":"/kubernetes/"},{"categories":["日常"],"content":"2021年第50周周记 这周完成了以下任务 搭建hugo博客 使用docker封装了blog 搭建k3s环境 计划： 学习k8s 总结：没啥好总结，刚开始写周记，就随便写一点吧 ","date":"2021-12-08","objectID":"/20211210/:0:0","tags":["daliy"],"title":"2021年第50周记","uri":"/20211210/"},{"categories":["web 服务器"],"content":"nginx 汇总 各类nginx 问题汇总 ","date":"2021-12-08","objectID":"/nginx/:0:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"安装nginx #centos yum install nginx #ubuntu apt install nginx ","date":"2021-12-08","objectID":"/nginx/:1:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"http代理 ","date":"2021-12-08","objectID":"/nginx/:2:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"正向代理 server { listen 80; server_name www.nbtyfood.com; location / { proxy_pass http://127.0.0.1:8080; } } ","date":"2021-12-08","objectID":"/nginx/:2:1","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"反向代理 ","date":"2021-12-08","objectID":"/nginx/:2:2","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"负载均衡 upstream mysvr { server 192.168.10.121:3333; server 192.168.10.122:3333; } server { .... location ~*^.+$ { proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 } } 热备 如果你有2台服务器，当一台服务器发生事故时，才启用第二台服务器给提供服务。服务器处理请求的顺序：AAAAAA突然A挂啦，BBBBBBBBBBBBBB….. upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 } 轮询 nginx默认就是轮询其权重都默认为1，服务器处理请求的顺序：ABABABABAB…. upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333; } 加权轮询 跟据配置的权重的大小而分发给不同服务器不同数量的请求。如果不设置，则默认为1。下面服务器的请求顺序为：ABBABBABBABBABB…. upstream mysvr { server 127.0.0.1:7878 weight=1;w server 192.168.10.121:3333 weight=2; } ip_hash nginx会让相同的客户端ip请求相同的服务器。 upstream mysvr { server 127.0.0.1:7878; server 192.168.10.121:3333; ip_hash; } ","date":"2021-12-08","objectID":"/nginx/:3:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"web缓存 location /images/ { proxy_cache my_cache; proxy_ignore_headers Cache-Control; proxy_cache_valid any 30m; # ... } ","date":"2021-12-08","objectID":"/nginx/:4:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["web 服务器"],"content":"重定向 rewrite ^/(.*) http://www.nbtyfood.com/$1 permanent; ","date":"2021-12-08","objectID":"/nginx/:5:0","tags":["nginx","linux"],"title":"nginx 汇总","uri":"/nginx/"},{"categories":["基础"],"content":"TCP/IP协议 ","date":"2021-12-08","objectID":"/tcpip/:0:0","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["基础"],"content":"什么是TCP/IP协议 OSI七层架构 TCP/IP四层模型 协议 应用层 HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS 表示层 应用层 XDR、ASN.1、NCP、TLS、ASCII 会话层 sockets、SOCKS、PAP 传输层 传输层 TCP、UDP、RTP、SCTP 网络层 网络互连层 IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP 数据链路层 网络访问（链接）层 以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11 物理层 调制解调器、无线电、光纤 ","date":"2021-12-08","objectID":"/tcpip/:1:0","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["基础"],"content":"报文结构 TCP报文段首部格式 源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址 序号/序列号（Sequense Number，SN）：在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。该字段表示本报文段所发送的数据的第一个字节的序号。初始序号称为 Init Sequense Number, ISN（序号/序列号这个字段很重要，大家留个印象，下文会详细讲解） 例如，一报文段的序号是 101，共有 100 字节的数据。这就表明：本报文段的数据的第一个字节的序号是 101，最后一个字节的序号是 200。显然，下一个报文段的数据序号应当从 201 开始，即下一个报文段的序号字段值应为 201。 确认号 ack：期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。 数据偏移（首部长度）：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。 保留：占 6 位，应置为 0，保留为今后使用。 ","date":"2021-12-08","objectID":"/tcpip/:1:1","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["基础"],"content":"TCP三次握手 ","date":"2021-12-08","objectID":"/tcpip/:2:0","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["基础"],"content":"TCP四次挥手 ","date":"2021-12-08","objectID":"/tcpip/:3:0","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["基础"],"content":"TCP/IP其他问题 TCP与UDP的区别 （1）TCP：面向连接，可靠的，速度慢，效率低。 （2）UDP：无连接、不可靠、速度快、效率高。 当进程需要传输可靠的数据时应使用TCP，当进程需要高效传输数据，可以忽略可靠性时应使用UDP协议。 ","date":"2021-12-08","objectID":"/tcpip/:4:0","tags":["TCP/IP"],"title":"TCP/IP详解","uri":"/tcpip/"},{"categories":["日常"],"content":"内网穿透 文章中使用的内网穿透前提是必须具有公网IP的云服务器，不符合条件的同学可以跳过了。 ","date":"2021-12-08","objectID":"/nps/:0:0","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"nps内网穿透 nps是一款轻量级、高性能、功能强大的内网穿透代理服务器。 ","date":"2021-12-08","objectID":"/nps/:1:0","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"在公网服务器上安装nps sever端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_server.tar.gz tar -zxvf linux_amd64_server.tar.gz sudo ./nps install sudo nps start ","date":"2021-12-08","objectID":"/nps/:1:1","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"在控制端安装npc client端 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_client.tar.gz tar -zxvf linux_amd64_client.tar.gz sudo ./npc -server=ip:port -vkey=web界面中显示的密钥 sudo npc start npc安装完成可以进入web页面穿透端口和域名 http://localhost:8080 ","date":"2021-12-08","objectID":"/nps/:1:2","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"frps内网穿透 frps 相对于nps的劣势是有断流的风险 frps 相对于nps的优势是对于高流量的媒体服务能够提供更可靠的支持 ","date":"2021-12-08","objectID":"/nps/:2:0","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"安装frps wget https://code.aliyun.com/MvsCode/frps-onekey/raw/master/install-frps.sh -O ./install-frps.sh chmod 700 ./install-frps.sh ./install-frps.sh install 卸载 frps服务 ./install-frps.sh uninstall 更新 frps服务 ./install-frps.sh update Server management（服务管理器） Usage: /etc/init.d/frps {start|stop|restart|status|config|version} ","date":"2021-12-08","objectID":"/nps/:2:1","tags":["内网穿透","nps"],"title":"自建服务器内网穿透","uri":"/nps/"},{"categories":["日常"],"content":"树莓派安装k3s ","date":"2021-12-06","objectID":"/rasberry/:0:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"1.安装k3s ","date":"2021-12-06","objectID":"/rasberry/:1:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"控制节点 curl -sfL https://get.k3s.io | sh - cat /var/lib/rancher/k3s/server/node-token ","date":"2021-12-06","objectID":"/rasberry/:1:1","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"工作节点 curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh - 树莓派特别要注意一个坑，就是关于内存的问题这个之后再讲 k3s kubectl get nodes #显示正确的节点表示完成 ","date":"2021-12-06","objectID":"/rasberry/:1:2","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"卸载 k3s #server 节点 /usr/local/bin/k3s-uninstall.sh #agent 节点 /usr/local/bin/k3s-agent-uninstall.sh ","date":"2021-12-06","objectID":"/rasberry/:1:3","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"2.安装dashboard k3s面板 ","date":"2021-12-06","objectID":"/rasberry/:2:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"部署 Kubernetes 仪表盘 GITHUB_URL=https://github.com/kubernetes/dashboard/releases VERSION_KUBE_DASHBOARD=$(curl -w '%{url_effective}' -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e 's|.*/||') sudo k3s kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/${VERSION_KUBE_DASHBOARD}/aio/deploy/recommended.yaml ","date":"2021-12-06","objectID":"/rasberry/:2:1","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"仪表盘 RBAC 配置 创建以下资源清单文件： dashboard.admin-user.yml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard dashboard.admin-user-role.yml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 部署admin-user 配置： sudo k3s kubectl create -f dashboard.admin-user.yml -f dashboard.admin-user-role.yml 获得 Bearer Token sudo k3s kubectl -n kubernetes-dashboard describe secret admin-user-token | grep '^token' 现在可以通过以下网址访问仪表盘： sudo k3s kubectl proxy http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ ","date":"2021-12-06","objectID":"/rasberry/:2:2","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"连接lens cat /etc/rancher/k3s/k3s.yaml 更改本地host 穿透服务器IP local ","date":"2021-12-06","objectID":"/rasberry/:2:3","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"3.安装 kube—prometheus 监控 ","date":"2021-12-06","objectID":"/rasberry/:3:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"一键安装 wget https://github.com/prometheus-operator/kube-prometheus/archive/refs/tags/v0.9.0.tar.gz tar -zxvf v0.9.0.tar.gz cd kube-prometheus-0.9.0/manifests k3s kubectl apply -f setup/ k3s kubectl get pod -n monitoring k3s kubectl apply -f . ","date":"2021-12-06","objectID":"/rasberry/:3:1","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"一键卸载 cd kube-prometheus/manifests k3s kubectl delete -f . k3s kubectl delete -f setup/ ","date":"2021-12-06","objectID":"/rasberry/:3:2","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"4.安装 nfs外部驱动挂载storageclass ","date":"2021-12-06","objectID":"/rasberry/:4:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["日常"],"content":"5.创建有状态pods（mysql） ","date":"2021-12-06","objectID":"/rasberry/:5:0","tags":["树莓派","k3s"],"title":"树莓派搭建k3s","uri":"/rasberry/"},{"categories":["Mac"],"content":"brew 安装配置 ","date":"2021-12-03","objectID":"/brew/:0:0","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"一.安装 ","date":"2021-12-03","objectID":"/brew/:1:0","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"1.在ubuntu上安装 brew /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" ","date":"2021-12-03","objectID":"/brew/:1:1","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"2.在centos上安装 brew /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" ","date":"2021-12-03","objectID":"/brew/:1:2","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"3.在MacOS上安装 brew /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" ","date":"2021-12-03","objectID":"/brew/:1:3","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"二、使用 ","date":"2021-12-03","objectID":"/brew/:2:0","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"1.安装 wget brew install wget Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local $ cd /usr/local $ find Cellar Cellar/wget/1.16.1 Cellar/wget/1.16.1/bin/wget Cellar/wget/1.16.1/share/man/man1/wget.1 $ ls -l bin bin/wget -\u003e ../Cellar/wget/1.16.1/bin/wget ","date":"2021-12-03","objectID":"/brew/:2:1","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"2.创建你自己的 Homebrew 包 $ brew create https://foo.com/bar-1.0.tgz Created /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula/bar.rb ","date":"2021-12-03","objectID":"/brew/:2:2","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["Mac"],"content":"3.撤销你的变更或与上游更新合并 $ brew edit wget # 使用 $EDITOR 编辑! ","date":"2021-12-03","objectID":"/brew/:2:3","tags":["brew"],"title":"brew 安装配置","uri":"/brew/"},{"categories":["gitlab"],"content":"gitlab CI/CD 的使用 我将使用gitlab的流水线自动实现hugo blog 文章的自动发布。 ","date":"2021-12-03","objectID":"/gitlab-cicd/:0:0","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"一、基础知识 ","date":"2021-12-03","objectID":"/gitlab-cicd/:1:0","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"二、安装过程 ","date":"2021-12-03","objectID":"/gitlab-cicd/:2:0","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"1.安装gitlab runner 首先需要安装 gitlab runner 进入服务器A 安装方法： 容器部署 手动二进制文件部署 通过rpm/deb包部署 docker方式安装 安装文档：https://docs.gitlab.com/runne… docker run -dit \\ --name gitlab-runner \\ --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner 1.1 设置信息 docker exec -it gitlab-runner gitlab-runner register 非docker方式安装 2.1 安装GitLab Runner 安装环境：Linux 其他环境参考：https://docs.gitlab.com/runne… 下载 curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64 添加权限 chmod +x /usr/local/bin/gitlab-runner 新建gitlab-runner用户 sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash 安装 安装时需要指定我们上面新建的用户 gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner 启动 gitlab-runner start # Download the binary for your system sudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64 # Give it permissions to execute sudo chmod +x /usr/local/bin/gitlab-runner # Create a GitLab CI user sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash # Install and run as service sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner sudo gitlab-runner start ","date":"2021-12-03","objectID":"/gitlab-cicd/:2:1","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"2.配置 docker shell链接 ssh-keygen -t rsa cd .ssh/ cat id_rsa.pub \u003e\u003eauthorized_keys docker cp id_rsa gitlab-runner:/root docker exec -it gitlab-runner /bin/bash chmod 600 /root/id_rsa vim /etc/systemd/system/gitlab-runner.service \"--syslog\" \"--user\" \"root\" #修改为root wq保存退出 systemctl daemon-reload systemctl restart gitlab-runner ","date":"2021-12-03","objectID":"/gitlab-cicd/:2:2","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"3.配置.gitlab-ci.yml文件 vim .gitlab-ci.yml stages: - build - test - deploy build-job: stage: build script: - echo \"上传代码\" - echo \"上传完成.\" unit-test-job: stage: test script: - echo - sleep 60 - echo \"Code coverage is 90%\" lint-test-job: stage: test script: - echo \"Linting code... This will take about 10 seconds.\" - sleep 10 - echo \"No lint issues found.\" deploy-job: stage: deploy script: - echo \"Deploying application...\" - echo \"Application successfully deployed.\" ","date":"2021-12-03","objectID":"/gitlab-cicd/:2:3","tags":["gitlab"],"title":"gitlab CI/CD 的使用","uri":"/gitlab-cicd/"},{"categories":["gitlab"],"content":"Markdown教程 参考：https://www.runoob.com/markdown ","date":"2021-12-03","objectID":"/markdown/:0:0","tags":["Markdown"],"title":"Markdown教程","uri":"/markdown/"},{"categories":["hugo"],"content":"hugo命令大全 ","date":"2021-12-01","objectID":"/first/:0:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"安装hugo ","date":"2021-12-01","objectID":"/first/:1:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"二进制安装 brew install hugo ","date":"2021-12-01","objectID":"/first/:1:1","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"源码安装 export GOPATH=$HOME/go go get -v github.com/spf13/hugo go get -u -v github.com/spf13/hugo #更新依赖库 ","date":"2021-12-01","objectID":"/first/:1:2","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"生成站点 hugo new site /opt/blog cd /opt/blog ","date":"2021-12-01","objectID":"/first/:2:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"创建文章 hugo new about.md vim about.md hugo new post/first.md ","date":"2021-12-01","objectID":"/first/:3:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"安装皮肤 cd /opt/blog/themes git clone https://github.com/dillonzq/LoveIt.git ","date":"2021-12-01","objectID":"/first/:4:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"运行hugo hugo server -t LoveIt -D ","date":"2021-12-01","objectID":"/first/:5:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"部署 你要部署在github Page上 hugo --theme=hyde --baseUrl=\"http://coderzh.github.io/\" cd public $ git init $ git remote add origin https://github.com/coderzh/coderzh.github.io.git $ git add -A $ git commit -m \"first commit\" $ git push -u origin master ","date":"2021-12-01","objectID":"/first/:6:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"hugo 添加搜索插件 [outputs] home = [\"HTML\", \"RSS\", \"JSON\"] ","date":"2021-12-01","objectID":"/first/:7:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"搜索配置 [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # LoveIt 新增 | 0.2.1 最大结果数目 maxResultLength = 10 # LoveIt 新增 | 0.2.3 结果内容片段长度 snippetLength = 50 # LoveIt 新增 | 0.2.1 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # LoveIt 新增 | 0.2.4 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" ","date":"2021-12-01","objectID":"/first/:7:1","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["hugo"],"content":"常用命令 nohup hugo server -e production -t LoveIt -D \u0026 ","date":"2021-12-01","objectID":"/first/:8:0","tags":["hugo"],"title":"hugo 命令大全","uri":"/first/"},{"categories":["基础"],"content":"运维图谱 ","date":"2021-12-01","objectID":"/yunwei/:0:0","tags":["运维"],"title":"运维知识图谱","uri":"/yunwei/"},{"categories":["基础"],"content":"云原生平台基础 Docker、Docker Compose：容器化技术 Kubernetes：大规模容器编排 Helm：云原生应用商店 Rancher： 易用的容器管理平台 KubeSphere：一站式容器云平台 OpenTracing：云原生链路追踪标准 Jaeger：云原生链路追踪实现产品 Istio：ServiceMesh下的服务流量治理 Jenkins、JenkinsX、Jenkins-BlueOcean：老牌的CI/CD平台 Gtilab/hub-CICD：Gitlab/hub自带的CICD Argo：kubernetes声明式持续集成 Nexus：Maven私库 Harbor：Docker私库 Prometheus+Granfana：监控与可视化平台 ElasticSearch+Fluentd+Kibana：日志与可视化方案 Serverless：无服务器上云方案（不用去管服务器，不是不需要服务器） SpringCloud Kubernetes：微服务上云方案 熟练掌握docker和k8s技术 devops掌握jenkins和gitlab ","date":"2021-12-01","objectID":"/yunwei/:1:0","tags":["运维"],"title":"运维知识图谱","uri":"/yunwei/"},{"categories":["基础"],"content":"应用12要素 名称 英文 描述 基准代码 codebase 一份基准代码，多份部署 依赖 Dependencies 显示声明依赖关系 配置 config 在环境中存储配置 后端服务 backing services 把后端服务当做附加资源 构建，发布，运行 build，release，run 严格分离构建和运行 进程 Processes 以一个或多个无状态进程运行应用 端口绑定 port binding 通过端口绑定来提供服务 并发 concurrency 通过进程模型进行扩展 易处理 disposability 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 Dev/prod parity 尽可能保持开发、预发布、线上环境 日志 log 把日志当做事件流 管理进程 admin processes 后台管理任务当做一次性进程处理 ","date":"2021-12-01","objectID":"/yunwei/:2:0","tags":["运维"],"title":"运维知识图谱","uri":"/yunwei/"},{"categories":null,"content":"关于 后台就是花式curd工程师 前端就是抠图工程师 大数据就是sql工程师 算法就是调参工程师 中间件就是客服热线接线员 ","date":"2021-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"只有运维才能拯救世界！ ","date":"2021-01-01","objectID":"/about/:0:1","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"兴趣爱好： 游泳，干饭 ","date":"2021-01-01","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"最近看的书： 《荒野求生》 ","date":"2021-01-01","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"破窑赋 天有不测风云，人有旦夕祸福。蜈蚣百足，行不及蛇；雄鸡两翼，飞不过鸦。马有千里之程，无骑不能自往；人有冲天之志，非运不能自通。 盖闻：人生在世，富贵不能淫，贫贱不能移。文章盖世，孔子厄于陈邦；武略超群，太公钓于渭水。颜渊命短，殊非凶恶之徒；盗跖年长，岂是善良之辈。尧帝明圣，却生不肖之儿；瞽叟愚顽，反生大孝之子。张良原是布衣，萧何称谓县吏。晏子身无五尺，封作齐国宰相；孔明卧居草庐，能作蜀汉军师。楚霸虽雄，败于乌江自刎；汉王虽弱，竟有万里江山。李广有射虎之威，到老无封；冯唐有乘龙之才，一生不遇。韩信未遇之时，无一日三餐，及至遇行，腰悬三尺玉印，一旦时衰，死于阴人之手。 有先贫而后富，有老壮而少衰。满腹文章，白发竟然不中；才疏学浅，少年及第登科。深院宫娥，运退反为妓妾；风流妓女，时来配作夫人。 青春美女，却招愚蠢之夫；俊秀郎君，反配粗丑之妇。蛟龙未遇，潜水于鱼鳖之间；君子失时，拱手于小人之下。衣服虽破，常存仪礼之容；面带忧愁，每抱怀安之量。时遭不遇，只宜安贫守份；心若不欺，必然扬眉吐气。初贫君子，天然骨骼生成；乍富小人，不脱贫寒肌体。 天不得时，日月无光；地不得时，草木不生；水不得时，风浪不平；人不得时，利运不通。注福注禄，命里已安排定，富贵谁不欲？人若不依根基八字，岂能为卿为相？ 吾昔寓居洛阳，朝求僧餐，暮宿破窖，思衣不可遮其体，思食不可济其饥，上人憎，下人厌，人道我贱，非我不弃也。今居朝堂，官至极品，位置三公，身虽鞠躬于一人之下，而列职于千万人之上，有挞百僚之杖，有斩鄙吝之剑，思衣而有罗锦千箱，思食而有珍馐百味，出则壮士执鞭，入则佳人捧觞，上人宠，下人拥。人道我贵，非我之能也，此乃时也、运也、命也。 嗟呼！人生在世，富贵不可尽用，贫贱不可自欺，听由天地循环，周而复始焉。 ","date":"2021-01-01","objectID":"/about/:3:0","tags":null,"title":"关于我","uri":"/about/"}]
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>博客 on 打工人日志</title><link>https://www.jobcher.com/blog/</link><description>Recent content in 博客 on 打工人日志</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright>Copyright © 2022-{year} All Rights Reserved.</copyright><atom:link href="https://www.jobcher.com/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>通知：《打工人日报》迁移到独立板块</title><link>https://www.jobcher.com/notice-1/</link><pubDate>Sat, 13 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/notice-1/</guid><description>通知：《打工人日报》迁移到独立板块 考虑到近期的一些情况，我决定将《打工人日报》迁移到独立板块，将不在首页展示，后续的更新将在独立板块中进行。不影响原文章的阅读和订阅邮件的推送。感谢各位的支持和关注！！！
访问地址 访问链接 首页点击访问</description></item><item><title>KyBook 3 | calibre-web - IOS系统最佳图书伴侣</title><link>https://www.jobcher.com/kybook3/</link><pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/kybook3/</guid><description>背景 calibre-web 支持opds协议，ip+端口/opds就是opds路径，所有支持opds的客户端都可以。安卓下推荐静读天下，ios推荐kybook 3，我这边主要介绍一下，kybook 3。
KyBook 3 支持几乎所有主要的电子书格式，包括：
EPub、FictionBook（fb2，fb2.zip）、纯文本和富文本（txt，rtf）、PDF、漫画（CBR，CBZ，CBT）、MobiPocket、Kindle（mobi，azw3）以及有声读物（mp3，m4a，m4b）。
基本上你在网络上找到的书籍资源，都可以用 KyBook 3 打开。
下载 KyBook 3 下载 添加OPDS源 打开KyBook 3 -&amp;gt; 底部目录 -&amp;gt; 添加 添加源地址 https://ip:port/opds 例如 https://192.168.1.1:8080/opds
2. 输入密码
添加书籍 总结 亚马逊 Kindle 一直是受欢迎的电子书阅读器，在我看来，它的巨大优势之一在于亚马逊丰富的线上资源，可以很方便地购买，并在 PC、移动端和实体 Kindle 上同步观看。
KyBooks 3 相比之下，最强大的在于对不同文件格式的支持，以及丰富的阅读自定义设置。
不足 当然，Kybooks 3 也存在一些问题，比如不少人都反馈无法注册，从而影响同步，这应该和 KyBook 的服务器设置有关。还有它仅支持iOS端，平台多少有些单一了。
你可以在 Appstore 免费下载 KyBook 3，它提供了「专业版」与「高级订阅」两个内购的选项：「专业版」包含去广告（不过免费版目前并没有广告）、用户辞典、手写标注、自动滚动等功能，花费 4.99$ 可永久升级，你可以免费体验 14 天以绝对是否购买。
「高级订阅」在解锁了全部「专业版」功能外，还允许用户使用 KyBook 服务器在不同设备间同步数据，年费为 14.99$，但因为前面所说的登陆问题，同步功能的体验可能会受到影响。</description></item><item><title>Tmux 安装和使用教程</title><link>https://www.jobcher.com/tmux/</link><pubDate>Thu, 13 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/tmux/</guid><description>tmux 是一个终端 multiplexer，它可以让你在一个终端中开启多个会话，并且可以在一个终端中切换多个会话。
安装 tmux 安装很简单，直接在终端中输入以下命令即可：
1# Ubuntu 或 Debian 2sudo apt-get install tmux 3 4# CentOS 或 Fedora 5sudo yum install tmux 6 7# Mac 8brew install tmux 使用 安装完成后，键入tmux命令，就进入了 Tmux 窗口。
1tmux 按下Ctrl+d或者显式输入exit命令，就可以退出 Tmux 窗口。
1exit 前缀键 Tmux 窗口有大量的快捷键。所有快捷键都要通过前缀键唤起。默认的前缀键是Ctrl+b，即先按下Ctrl+b，快捷键才会生效。
举例来说，帮助命令的快捷键是Ctrl+b ?。它的用法是，在 Tmux 窗口中，先按下Ctrl+b，再按下?，就会显示帮助信息。
然后，按下 ESC 键或q键，就可以退出帮助。
快捷键 面板（pane）指令 前缀 指令 描述 Ctrl+b &amp;quot; 当前面板上下一分为二，下侧新建面板 Ctrl+b % 当前面板左右一分为二，右侧新建面板 Ctrl+b x 关闭当前面板（关闭前需输入y or n确认） Ctrl+b z 最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增） Ctrl+b ! 将当前面板移动到新的窗口打开（原窗口中存在两个及以上面板有效） Ctrl+b ; 切换到最后一次使用的面板 Ctrl+b q 显示面板编号，在编号消失前输入对应的数字可切换到相应的面板 Ctrl+b { 向前置换当前面板 Ctrl+b } 向后置换当前面板 Ctrl+b Ctrl+o 顺时针旋转当前窗口中的所有面板 Ctrl+b 方向键 移动光标切换面板 Ctrl+b o 选择下一面板 Ctrl+b 空格键 在自带的面板布局中循环切换 Ctrl+b Alt+方向键 以5个单元格为单位调整当前面板边缘 Ctrl+b Ctrl+方向键 以1个单元格为单位调整当前面板边缘（Mac下被系统快捷键覆盖） Ctrl+b t 显示时钟 系统指令 前缀 指令 描述 Ctrl+b ?</description></item><item><title>DockerHub 加速镜像部署 - 使用cloudflare 代理</title><link>https://www.jobcher.com/docker-proxy/</link><pubDate>Wed, 12 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-proxy/</guid><description>背景 6 月 6 日，上海交大的 Docker Hub 镜像加速器宣布因收到通知要求被下架。声明称：“即时起我们将中止对 dockerhub 仓库的镜像。docker 相关工具默认会自动处理失效镜像的回退，如果对官方源有访问困难问题，建议尝试使用其他仍在服务的镜像源。我们对给您带来的不便表示歉意，感谢您的理解与支持。”Docker Hub 是目前最大的容器镜像社区，去年 5 月起国内用户报告 Docker Hub 官网无法访问，其网址解析返回了错误 IP 地址。
因为不能直接访问国外的镜像仓库，下载国外的docker镜像速度一直很慢, 国内从 Docker Hub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。
使用 我这边已经部署好了加速镜像节点，同学们如果不想自己部署，可以使用我的加速节点，但是，不能保证节点长期有效。
1https://dockerhub.jobcher.com 第一步：代理拉取镜像 假如我们下载node镜像，那么我们可以这样写：
1docker pull dockerhub.jobcher.com/library/node:latest 2# 或者 3docker pull dockerhub.jobcher.com/bitnami/node:latest 第二步：重命名镜像 1docker tag dockerhub.jobcher.com/library/node:latest node:latest 2# 或者 3docker tag dockerhub.jobcher.com/bitnami/node:latest node:latest 第三步：删除代理镜像 1docker rmi dockerhub.jobcher.com/library/node:latest 2# 或者 3docker rmi dockerhub.jobcher.com/bitnami/node:latest 或者直接配置到镜像仓库 1sudo mkdir -p /etc/docker 2sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&amp;#39;EOF&amp;#39; 3{ 4 &amp;#34;registry-mirrors&amp;#34;: [ 5 &amp;#34;https://dockerhub.</description></item><item><title>docker的零停机部署</title><link>https://www.jobcher.com/docker-rollout/</link><pubDate>Mon, 01 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-rollout/</guid><description>背景 使用 docker compose up 部署新版本的服务会导致停机，因为应用容器在创建新容器之前已停止。如果你的应用程序需要一段时间才能启动，用户可能会注意到这一点。为了保障服务用户无感，可以使用docker rollout
适合没必要用 K8S 轻量级小项目
安装 项目地址
1# 为 Docker cli 插件创建目录 2mkdir -p ~/.docker/cli-plugins 3 4# 下载 docker-rollout 脚本到 Docker cli 插件目录 5curl https://github.jobcher.com/gh/https://raw.githubusercontent.com/wowu/docker-rollout/master/docker-rollout -o ~/.docker/cli-plugins/docker-rollout 6 7# 使脚本可执行 8chmod +x ~/.docker/cli-plugins/docker-rollout 使用 注意事项！！！ 服务不能在 docker-compose.yml 中定义 container_name 和 ports ，因为不可能运行具有相同名称或端口映射的多个容器。 需要像 Traefik 或 nginx-proxy 这样的代理来路由流量。 每次部署都会增加容器名称中的索引（例如 project-web-1 -&amp;gt; project-web-2 ） 使用示范 1# 下载代码 2git pull 3# 构建新的应用程序映像 4docker compose build web 5# 运行数据库迁移 6docker compose run web rake db:migrate 7# 部署新版本 8docker rollout web 或者使用docker-compose.</description></item><item><title>SD-webui 批量处理图片</title><link>https://www.jobcher.com/stable-diffusion-03/</link><pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/stable-diffusion-03/</guid><description>背景 Stable Diffusion 在训练数据集之前，需要先对数据进行预处理。
本篇文章就是介绍如何对图像进行批量预处理。
图片上传 上传图像到你指定目录，我的目录时/mnt/smb/
打开SD-web地址，进入192.168.1.232:7861，选择附加功能，进行图像预处理
批量抠图 选择从目录进行批量处理 填写输入目录和输出目录 举例：
原本我的共享文件夹 地址是\\192.168.1.249\DB Training\ai-pre-photo\out-photo 将所有的 \\192.168.1.249\DB Training\ 改为 /mnt/smb/ 所有的 \ 改为 / 因此 需填写地址如下图：
选择抠图模型 滑倒最底部选择背景去除算法,选择你要使用的算法，我这边选择silueta算法,可以根据你自己的需求使用算法
执行生成 点击生成按钮，开始对图像批量处理
查看生成的图像 在对应的共享文件夹也可以查看</description></item><item><title>ubuntu 安装 ComfyUI</title><link>https://www.jobcher.com/stable-diffusion-02/</link><pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/stable-diffusion-02/</guid><description>背景 ComfyUI 是用于稳定扩散的基于节点的用户界面。ComfyUI 由 Comfyanonymous 于 2023 年 1 月创建，他创建了该工具来学习稳定扩散的工作原理。
效果 webui和ComfyUI之间的区别,相比较webUI，ComfyUI更工业化，更符合高级使用者的配置
安装 安装本体 下载软件
1mkdir ~/sd-web 2cd ~/sd-web 3git clone https://github.jobcher.com/gh/https://github.com/comfyanonymous/ComfyUI.git 环境依赖
1cd ~/sd-web/ComfyUI 2conda create -n ComfyUI python=3.10 3pip install -r requirements.txt -i https://pypi.douban.com/simple --trusted-host=pypi.douban.com 下载sd_xl_turbo模型
1aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.jobcher.com/https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0_fp16.safetensors -d ~/sd-web/ComfyUI/models/checkpoints -o sd_xl_turbo_1.0_fp16.safetensors 启动服务
1cd ~/sd-web/ComfyUI 2python main.py --listen --port 6006 --cuda-device 1 webUI共享模型 1cd 2mv extra_model_paths.yaml..example extra_model_paths.yaml 编辑参数
1vim extra_model_paths.yaml 修改 base_path: path/to/stable-diffusion-webui/ 改为你的webui实际地址，例如： base_path: ~/sd-web/stable-diffusion-webui/ 1#config for a1111 ui 2#all you have to do is change the base_path to where yours is installed 3a111: 4 base_path: path/to/stable-diffusion-webui/ ## 这里改为你实际的webui地址 5 6 checkpoints: models/Stable-diffusion 7 configs: models/Stable-diffusion 8 vae: models/VAE 9 loras: | 10 models/Lora 11 models/LyCORIS 12 upscale_models: | 13 models/ESRGAN 14 models/RealESRGAN 15 models/SwinIR 16 embeddings: embeddings 17 hypernetworks: models/hypernetworks 18 controlnet: models/ControlNet 重启服务</description></item><item><title>ubuntu 安装 stable-diffusion-webui</title><link>https://www.jobcher.com/stable-diffusion-01/</link><pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/stable-diffusion-01/</guid><description>背景 Stable Diffusion (稳定扩散) 是一个扩散模型，2022年8月由德国CompVis协同Stability AI和Runway发表论文，并推出相关程序。
AUTOMATIC1111开发了图形化界面：「Stable Diffusion WebUI」，这是能用AI技术生成图片的开源软件，只要给定一组描述文本，AI就会开始绘图(准确的说是「算图」或「生图」)；亦能模仿现有的图片，生成另一张图片。甚至给它一部分涂黑的图片，AI也能按照你的意愿将图片填上适当的内容。除此之外还支持自行训练模型加强生图效果。
本篇文章就是介绍如何安装 stable-diffusion-webui
安装conda 在 Ubuntu 上安装 Anaconda 的步骤如下：
首先，你需要下载 Anaconda 的安装包。你可以从 Anaconda 的官方网站上下载最新版本的 Anaconda for Linux。选择适合你的系统的版本（Python 3.x）。
访问下载链接：https://www.anaconda.com/products/distribution#download-section
下载完成后，你可以在终端中导航到下载的文件所在的目录。你可以使用 cd 命令来改变目录。例如，如果你的下载文件在 Downloads 文件夹中，你可以输入以下命令：
1cd ~/Downloads 然后，你需要运行 bash 命令来安装 Anaconda。假设你下载的 Anaconda 文件名为 &amp;ldquo;Anaconda3-2020.02-Linux-x86_64.sh&amp;rdquo;，你可以输入以下命令： 1bash Anaconda3-2020.02-Linux-x86_64.sh 请注意，你需要将上述命令中的 &amp;ldquo;Anaconda3-2020.02-Linux-x86_64.sh&amp;rdquo; 替换为你实际下载的文件名。
4. 接下来，你会看到 Anaconda 的许可协议。按 Enter 键滚动到底部，然后输入 &amp;lsquo;yes&amp;rsquo; 来接受许可协议。
5. 然后，你需要确认 Anaconda 的安装位置。你可以选择默认位置或输入新的位置。 6. 安装完成后，你会看到一个提示，询问你是否希望 Anaconda3 添加到你的 PATH。你应该输入 &amp;lsquo;yes&amp;rsquo;。 7. 最后，你需要激活安装。你可以通过关闭并重新打开终端或运行以下命令来完成此操作：
1source ~/.bashrc 验证安装。在终端中输入以下命令： 1conda list 如果安装成功，这个命令会显示一个已安装的包的列表。</description></item><item><title>测试策略：微服务架构</title><link>https://www.jobcher.com/test-way/</link><pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/test-way/</guid><description>可以从两个方面来保障微服务的质量：
选取合适的测试策略模型，确保测试活动全面且有效；
建立质量保障体系，使质量保障内化为企业的组织能力。
如何选择合适的测试策略模型？ 要想使面向微服务的测试活动全面且有效，可以借用“测试金字塔”的思想，针对不同类型和颗粒度的测试投入不同的精力，达到一个最佳平衡：
测试需要分层，每一层的测试颗粒度有所不同；
不同层次的测试比重有差异，通常来说，层次越高，测试比重应越少。
需要说明的是，传统意义下的测试金字塔，在微服务架构下不再完全奏效。因为微服务中最大的复杂性不在于服务本身，而在于微服务之间的交互方式，这一点值得特别注意。
因此，针对微服务架构，常见的测试策略模型有如下几种。
（1） 微服务“测试金字塔”
基于微服务架构的特点和测试金字塔的原理，Toby Clemson 有一篇关于“微服务架构下的测试策略”的文章，其中通过分析阐述了微服务架构下的通用测试策略。
如图，该策略模型依然是金字塔形状，从下到上依次为单元测试、集成测试、组件测试、端到端测试、探索式测试。
（2） 微服务“测试蜂巢”
这种策略模型是蜂巢形状，它强调重点关注服务间的集成测试，而单元测试和端到端测试的占比较少。
（3） 微服务“测试钻石”
这种策略模型是钻石形状的，组件测试和契约测试是重点，单元测试比率减少，另外增加了安全和性能等非功能的测试类型。
我想，有多少个基于微服务架构的测试团队大概就有多少个测试策略模型吧。“测试金字塔”是一种测试策略模型和抽象框架，当技术架构、系统特点、质量痛点、团队阶段不同时，每种测试的比例也不尽相同，而且最关键的，并不一定必须是金字塔结构。
理解了测试策略模型的思考框架，我们看下应如何保障测试活动的全面性和有效性。
全面性 微服务架构下，既需要保障各服务内部每个模块的完整性，又需要关注模块间、服务间的交互。只有这样才能提升测试覆盖率和全面性，因此，可以通过如下的分层测试来保证微服务的全面性。
单元测试（Unit Test） ：从服务中最小可测试单元视角验证代码行为符合预期，以便测试出方法、类级别的缺陷。
集成测试（Integration Test）：验证当前服务与外部模块之间的通信方式或者交互符合预期，以便测试出接口缺陷。
组件测试 （Component Test）：将测试范围限制在被测系统的一部分（一般是单个服务），使用测试替身（test doubles）将其与其他组件隔离，以便测试出被测代码的缺陷。
契约测试（Contracts Test）：验证当前服务与外部服务之间的交互，以表明它符合消费者服务所期望的契约。
端到端测试（End-to-end Test）：从用户视角验证整个系统的功能能否符合用户的预期。
可见，上述测试策略模型中的测试方法，是自下而上逐层扩大测试范围和边界，力保微服务架构的模块内、模块间交互、服务内、服务间交互、系统范围等维度的功能符合预期。
有效性 确定了分层测试方法，我们应该如何选取每种测试方法的比例，来确保该测试策略的有效性呢？
首先必须要明确的是不存在普适性的测试组合比例。我们都知道，测试的目的是解决企业的质量痛点、交付高质量的软件。因此不能为了测试而测试，更不能为了质量而不惜一切代价，需要考虑资源的投入产出比。
测试策略如同测试技术、技术架构一样，并不是一成不变，它会随着业务或项目所处的阶段，以及基于此的其他影响因素的变化而不断演进。但归根结底，还是要从质量保障的目标出发，制定出适合当时的测试策略，并阶段性地对策略进行评估和度量，进而不断改进和优化测试策略。因此，选取测试策略一定要基于现实情况的痛点出发，结果导向，通过调整测试策略来解决痛点。
比如，在项目早期阶段或某 MVP 项目中，业务的诉求是尽快发布到线上，对功能的质量要求不太高，但对发布的时间节点要求非常严格。那这种情况下快速地用端到端这种能模拟用户真实价值的测试方法保障项目质量也未尝不可；随着项目逐渐趋于平稳后，时间要求渐渐有了节奏，对功能的质量要求会逐渐变高，那么这时候可以再根据实际情况引入其他测试方法，如契约测试或组件测试等。
你要永远记住，适合自身项目阶段和团队的测试策略才是“完美”的策略。
如何建立质量保障体系？ 上述分层的测试策略只是尽可能地对微服务进行全面的测试，确保系统的所有层次都被覆盖到，它更多体现在测试活动本身的全面性和有效性方面。要想将质量保障内化为企业的组织能力，就需要通过技术和管理手段形成系统化、标准化和规范化的机制，这就需要建设质量保障体系。
质量保障体系：通过一定的流程规范、测试技术和方法，借助于持续集成/持续交付等技术把质量保障活动有效组合，进而形成系统化、标准化和规范化的保障体系。 同时，还需要相应的度量、运营手段以及组织能力的保障。
如下几个方面是质量保障体系的关键，后续课程也将按如下方式展开讲解。
流程规范：没有规矩不成方圆，好的流程规范是保障质量中非常关键的一环。当出现交付质量差的情况时，过程质量也一定是差的。通常会出现某些关键动作未执行或执行不到位、对事情的不当处理等情况，而这些情况可以通过建立闭环、分工明确的流程规范完全可以避免。另外，研发过程中，过程质量跟执行人的质量意识、个人能力等直接相关，那么就需要建立易执行的流程规范，降低人员的执行门槛。同时需要特别注意，规范的不断完善是几乎所有团队的常态，但当规范执行效果不好时一定要及时跟进，分析其根本原因，必要时要进行简化。
测试技术： 测试策略模型中的分层测试方法可以使面向微服务的测试活动具有一定的全面性和有效性，使得被测内容在功能方面符合预期。除功能性之外，软件质量还有其他很多属性，如可靠性、易用性、可维护性、可移植性等，而这些质量属性就需要通过各种专项测试技术来保障了。同时，还有许多测试技术的首要价值在于提升测试效率。因此合理地组合这些测试技术，形成测试技术矩阵，有利于最大化发挥它们的价值。
持续集成与持续交付：微服务的优势需要通过持续集成和持续交付的支持才能充分发挥出来，这就要求在执行测试活动时提高反馈效率、尽快发现问题。一方面要明确各种“类生产环境”在交付流程中的位置和用途差异点，保证它们的稳定可用。另一方面需要将各种测试技术和自动化技术集成起来，使代码提交后能够自动进行构建、部署和测试等操作，形成工具链，实现真正意义上的持续集成和持续交付。
度量与运营：管理学大师德鲁克曾经说过“你如果无法度量它，就无法管理它（It you can’t measure it, you can’t manage it)”。要想能有效管理和改进，就难以绕开度量这个话题。对于研发过程来说，度量无疑是比较难的，它是一个脑力密集型的过程，指标多维度，且很多维度的内容难以清晰地度量。在质量保障体系中，我将基于质量、效率、价值等多维度视角建立起基础的度量体系，并结合定期运营做定向改进，形成 PDCA 正向循环，促使各项指标稳步提升。同时，需要特别警惕的是，度量是一把双刃剑，这里我也会告诉一些我的经验教训和踩过的坑，避免走错方向。
组织保障：产品的交付离不开组织中每个参与部门成员的努力。正如质量大师戴明所说，质量是设计出来的，不是测试出来的。因此在组织中树立起“质量文化”至关重要。在这部分内容里，我将介绍常见的参与方的角色、职责和协作过程中的常见问题、对策，以及如何营造质量文化等内容。
总结 谈到了基于微服务架构下的各种质量挑战，可以从两个方面有效且高效地保障微服务的质量：确保面向微服务的测试活动具备全面性和有效性，质量保障需要内化为企业的组织能力。</description></item><item><title>单元测试：测试单元质量提升</title><link>https://www.jobcher.com/unit-test/</link><pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/unit-test/</guid><description>单元测试的价值 单元测试是一种白盒测试技术，通常由开发人员在编码阶段完成，目的是验证软件代码中的每个单元（方法或类等）是否符合预期，即尽早在尽量小的范围内暴露问题。
我们都知道，问题发现得越早，修复的代价越小。毫无疑问，在开发阶段进行正确的单元测试可以极大地节省时间和金钱。如果跳过单元测试，会导致在后续更高级别的测试阶段产生更高的缺陷修复成本。
如图，假如有一个只包含两个单元 A 和 B 的程序，且只执行端到端测试，如果在测试过程中发现了缺陷，则可能有如下多种原因：
该缺陷由单元 A 中的缺陷引起；
该缺陷由单元 B 中的缺陷引起；
该缺陷由单元 A 和单元 B 中的缺陷共同引起；
该缺陷由单元 A 和单元 B 之间接口的缺陷引起；
该缺陷是测试方法或测试用例的错误导致的。
由此可见，忽略单元测试会导致后续发现缺陷时，要花费较高的成本来确认缺陷原因。
单元测试除了能够在较早阶段识别软件中的错误，它还有如下价值。
反馈速度快：单元测试通常以自动化形式运行，执行速度非常快，可以快速反馈结果，跟持续集成结合起来，形成有效的反馈环。
重构的有力保障：系统需要大规模重构时，单测可以确保对已有逻辑的兼容，如果单元测试都通过，基本上可以保证重构没有破坏原来代码逻辑的正确性。
使更熟悉代码：写单元测试的过程本身就是一个审视代码的过程，可以发现一些设计上的问题（代码设计的不可测试）、代码编写方面的问题（边界条件的处理不当）等。
既然单元测试由开发人员来设计和执行，那作为测试人员是不是就不需要学习这门技术了？不知道你是怎样看待这个想法的，我的观点是：
单元测试只是通常情况下由开发人员完成，并不是绝对的，在一些公司或项目里也存在测试人员完成的情况；
在你负责的模块或服务里，第一级别的测试不是你来完成的，那么你更有必要去了解它的设计思路和执行情况，这能帮助你发现单元测试可能存在的问题点，也有利于你设计和执行后续高级别的测试类型；
开发人员总是不太擅长做测试类的工作，当你掌握了单元测试的技能，你便更有机会去帮助和影响到开发人员，赢得他对你的尊重，也有利于你们更好地合作；
这种想法是测试人员的常见想法，所以掌握单元测试技能在测试人员群体中也会是稀缺技能，因此，掌握它将会获得额外的锻炼机会和个人影响力，要知道，机会总是留给有准备的人。
微服务下的单元测试类型 就像之前课程所说：微服务中最大的复杂性不在于服务本身，而在于微服务之间的交互方式，服务与服务之间常常互相调用以实现更多更复杂的功能。
举个例子，我们需要测试的是订单类（Order）中的获取总价方法（getTotalPrice()），而在该方法中除了自有的一些代码逻辑外，通常需要去调用其他类的方法。比如这里调用的是用户类（User）的优惠等级方法（reductionLevel ()）和商品类（Goods）中的商品价格方法（getUnitPrice()）。很显然，优惠等级方法或商品价格方法，只要一方有错误，就会导致订单类获取总价方法的测试失败。基于这种情况，可以有两种单元测试类型。
1. 社交型单元测试（Sociable Unit Testing） 如图，测试订单类的获取总价方法（Order.getTotalPrice()）时会真实调用用户类的优惠等级方法（User.reductionLevel()）和商品类的商品单价方法（Goods.getUnitPrice()）。将被测试单元视为黑盒子，直接对其进行测试，这种单元测试称之为社交型单元测试（Sociable Unit Testing）。
2. 孤立型单元测试（Solitary Unit Testing） 如图，如果测试订单类的获取总价方法（Order.getTotalPrice()）时，使用测试替身 （test doubles） 技术来替代用户类的优惠等级方法（User.reductionLevel()）和商品类的商品单价方法（Goods.getUnitPrice()）的效果。对象及其依赖项之间的交互和协作被测试替身代替，这种单元测试称之为孤立型单元测试（Solitary Unit Testing）。
另外，上述提到的测试替身是一种在测试中使用对象代替实际对象的技术，常用的技术如下。
桩代码（Stubs）：当在对象上调用特定方法时，会对其进行硬编码（临时代码）的方式来代替真实代码提供固定响应。比如，某函数 X 的实现中调用了一个函数 Y，而 Y 不能调用，为了对函数 X 进行测试，就需要模拟一个函数 Y，那么函数 Y 的实现就是所谓的桩代码。
模拟代码（Mocks）：模拟代码跟桩代码类似，它除了代替真实代码的能力之外，更强调是否使用了特定的参数调用了特定方法，因此，这种对象成为我们测试结果的基础。
根据被测单元是否与其交互者隔离，会产生以上两种单元测试类型，这两种类型的单元测试在微服务测试中都起着重要作用，它们用来解决不同的测试问题。</description></item><item><title>端到端测试：模拟用户体验</title><link>https://www.jobcher.com/user-test/</link><pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/user-test/</guid><description>端到端测试详解 定义 端到端测试（End-to-end Test）是一种用于测试整个应用程序的流程是否符合预期的测试技术。 它模拟用户真实的使用场景，通过用户界面测试应用程序，如图所示：
与其他类型的测试相反，端到端测试是面向业务的，其目的是验证应用程序系统整体上是否符合业务目标。为了实现这一目标，该系统通常被视为黑盒子：尽可能完整地部署系统中的微服务，并主要通过 GUI 和 API 等公共接口对其进行操作。
GUI：Graphical User Interface，又称图形用户界面或图形用户接口。它是采用图形方式显示的计算机操作用户界面，是一种人与计算机通信的界面显示格式，允许用户使用鼠标等输入设备操纵屏幕上的图标或菜单选项，以选择命令、调用文件、启动程序或执行其他一些日常任务。
API：Application Programming Interface，又称呼应用程序编程接口或应用程序接口。它是一组定义、程序及协议的集合，通过 API接口实现计算机软件之间的相互通信。API 的一个主要功能是提供通用功能集，同时也是一种中间件，为各种不同平台提供数据共享。
由于微服务架构包含多个具有相同行为的活动部件，因此端到端测试为服务之间传递消息的正确性提供了更多的信心，而且还可以确保正确配置了其他网络基础结构，例如防火墙、代理或负载均衡等。
测试范围 通过微服务的分层测试策略可知，端到端测试的范围比其他类型的测试大得多。
分层测试策略-测试范围
绝大多数情况下，微服务应用系统会依赖一个或多个由外部管理的微服务。通常，这些外部服务包含在端到端测试范围内。 但是，在极少数情况下，也可以主动排除它们。因为如果外部服务由第三方管理，可能会经常出现稳定性和可靠性问题，这会导致端到端测试因不可控的原因而失败。
微服务应用的典型示例 比如，某个应用程序系统依赖公安部门的背景审查服务，通过调用该服务来查询用户是否有过违法前科。首先这样的服务通常会按调用次数付费（每次 5-10 元），具有较高的测试成本，其次背景审查服务不总是稳定可用的。在这种情况下，通过服务虚拟化技术模拟背景审查服务是个不错的选择，这虽然多少会降低端到端测试的信心，但增加了测试用例套件的稳定性。
测试入口 因为端到端测试是面向业务的，那么测试时要从真实用户的使用场景来进行测试，根据应用程序系统是否有 GUI，可以分为两种情况：
应用程序系统有 GUI，这种情况下用户可以直接操作 GUI 来使用系统，那么诸如 Selenium WebDriver 之类的工具可以帮助驱动 GUI 触发系统内的特定行为。
应用程序系统没有 GUI，这种情况下，使用 HTTP 客户端通过其公共的 API 直接操作微服务。没有真实的 GUI，不能直观地看到业务功能行为，但可以通过后台数据来确定系统的正确性，比如 API 的返回结果、持久化数据的变化情况，等等。
测试设计 确定测试范围和测试入口后，可以进一步梳理出要测试的功能列表或用例集，并对其按业务能力、优先级、重要性等维度进行分组。这样可以将它们拆分为较小的任务，以便整个团队可以排序处理，比如可以首先实施优先级较高的用例组，或按紧急程度处理关键的用例，这有助于我们尽早消除潜在的障碍。
另外，由于端到端测试的目标是完全集成后的系统的行为，使得编写和维护测试用例会比其他类型的测试更加困难：
端到端测试涉及的活动部件比其他测试多得多；
端到端测试须考虑系统中的异步处理。
这些因素都可能给端到端测试带来挑战，比如测试过程不稳定、测试时间过长、测试用例集的维护成本高，等等。因此，应尽可能以最粗粒度进行端到端的测试设计。
如何开展端到端测试？ 熟悉了端到端测试的基本内容，我们来看下如何开展端到端测试，主要有如下几类：
UI 自动化
对于带有 GUI 的应用程序系统，在进行端到端测试时，可以通过 UI 自动化的方式进行。如果 GUI 是 Web 形式，则 Selenium 是首选工具；如果 GUI 是 Native 形式，则可以使用 Appium。</description></item><item><title>Kubernetes — containerd 安装和部署</title><link>https://www.jobcher.com/container/</link><pubDate>Wed, 13 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/container/</guid><description>containerd 现在很多人说起容器都会说到docker，docker凭借镜像（images）快捷的部署，占领了极大的技术市场，docker公司将自己的核心依赖 Contanerd 捐给了 CNCF，这个就是contanerd的由来，containerd 在kubernetes在 v1.24之后的版本作为底层核心进行使用。
Containerd架构 可以看到 Containerd 仍然采用标准的 C/S 架构，服务端通过 GRPC 协议提供稳定的 API，客户端通过调用服务端的 API 进行高级的操作。 为了解耦，Containerd 将不同的职责划分给不同的组件，每个组件就相当于一个子系统（subsystem）。连接不同子系统的组件被称为模块。 总体上 Containerd 被划分为两个子系统：
Bundle : 在 Containerd 中，Bundle 包含了配置、元数据和根文件系统数据，你可以理解为容器的文件系统。而 Bundle 子系统允许用户从镜像中提取和打包 Bundles。 Runtime : Runtime 子系统用来执行 Bundles，比如创建容器。 其中，每一个子系统的行为都由一个或多个模块协作完成（架构图中的 Core 部分）。每一种类型的模块都以插件的形式集成到 Containerd 中，而且插件之间是相互依赖的。例如，上图中的每一个长虚线的方框都表示一种类型的插件，包括 Service Plugin、Metadata Plugin、GC Plugin、Runtime Plugin 等，其中 Service Plugin 又会依赖 Metadata Plugin、GC Plugin 和 Runtime Plugin。每一个小方框都表示一个细分的插件，例如 Metadata Plugin 依赖 Containers Plugin、Content Plugin 等。 总之，万物皆插件，插件就是模块，模块就是插件。
常用插件 Content Plugin : 提供对镜像中可寻址内容的访问，所有不可变的内容都被存储在这里。 Snapshot Plugin : 用来管理容器镜像的文件系统快照。镜像中的每一个 layer 都会被解压成文件系统快照，类似于 Docker 中的 graphdriver。 Metrics : 暴露各个组件的监控指标。 安装 卸载docker 首先要保证环境干净整洁，如果你有安装docker服务，需要先卸载docker，如果没有安装可以跳过</description></item><item><title>CI/CD 可观察性-基于grafana</title><link>https://www.jobcher.com/cicd-obser/</link><pubDate>Tue, 12 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/cicd-obser/</guid><description>背景 什么是 CI/CD 可观察性，我们如何为更多可观察的管道铺平道路？可观察性不仅仅是观察错误或监控基本健康信号。相反，它会更深入，以便您可以了解系统内行为背后的“原因”。
CI/CD 可观察性在其中发挥着关键作用。这是关于深入了解持续集成和部署系统的整个管道——查看每个代码签入、每个测试、每个构建和每个部署。当您组合所有这些数据时，您可以全面了解整个软件交付过程，揭示效率领域、瓶颈和潜在故障点。
CI/CD 可观察性是可观察性的一个子集，专注于软件开发生命周期。它有助于以多种方式确保流程可靠、相关且易于理解：
积极主动解决问题。没有可观察性，我们只能对问题做出反应。有了它，我们可以在问题升级之前预见并解决问题，从而节省时间和资源。 更好的决策。通过了解 CI/CD 流程的细节，团队可以在资源分配、流程变更和工具采用方面做出更明智的决策。 建立信心。通过对 CI/CD 管道的清晰洞察，开发人员、测试人员和运营团队可以对他们发布的软件更有信心。它减少了“对部署的恐惧”并培育了持续改进的文化。 问责制和透明度。可观察性确保 CI/CD 流程的每一步都是可追溯的。这意味着，如果出现问题，可以追溯到其源头，促进问责并帮助解决根本原因，而不仅仅是解决症状。 问题 CI/CD 系统并非没有自身的挑战。破坏 CI/CD 管道平稳运行的常见问题是不稳定、性能下降和配置错误。
Flakiness 片状 片状测试是 CI/CD 方程中不可预测的变量。当测试在代码没有任何更改的情况下产生不同的结果（通过或失败）时，该测试被认为是“不稳定的”。出现片状现象通常有以下几个原因：
外部依赖和环境问题。如果这些依赖项不能始终可用，则依赖于外部服务、数据库或特定环境设置的测试可能会产生不可预测的结果。如果环境设置不正确或意外拆除，也可能会发生这种情况。从本质上讲，先前测试的残留或外部服务的不可用可能会扭曲结果，使其不可靠。 比赛条件。当系统的行为依赖于不可控事件的顺序或时间时，就会出现这种情况。特别是在异步操作中，如果管理不当，事件序列的不可预测性可能会导致偶发故障。 Performance regression 性能回归 随着 CI/CD 流程的发展并变得更加复杂，系统性能可能会开始下降。这种回归可能不会立即显现出来，但长期的累积效应可能会阻碍 CI/CD 管道的效率。以下是常见的原因：
测试执行效率低下。某些测试可能会运行比必要的时间更长的时间，这可能是因为冗余操作、设置的等待时间太长或查询效率低下。这在集成和端到端测试中尤其明显。 代码和测试膨胀。当我们添加更多功能和测试而不解决技术债务或进行优化时，我们的构建时间可能会增加。有些测试从添加之日起可能会很慢。如果不解决这些问题，整个构建和测试过程可能会比需要的时间更长。 Misconfigurations 配置错误 即使是最深思熟虑的管道也可能因配置错误而失败。这可能导致：
次优测试计划。 CI/CD 管道遵循一条关键路径，其中每个步骤都依赖于前一个步骤。如果步骤未设置为按正确的顺序执行或正在等待非依赖项，则可能会导致效率低下。 次优容量规划。未配置足够的资源或对所需工作负载规划不当可能会导致管道出现瓶颈。如果 CI/CD 流程在关键阶段没有必要的能力，则可能会减慢整个工作流程或导致中断和故障。 DORA 指标 Deployment frequency 部署频率 (DF)：组织成功发布到生产环境的频率 Mean Lead time for changes 变更平均前置时间 (MLT)：从代码提交到代码在生产中运行所需的时间 Mean time to recover 平均恢复时间 (MTTR)：发生服务事件或缺陷后恢复服务需要多长时间 Change failure rate 变更失败率 (CFR)：导致失败的变更百分比 优化 CI/CD 可观察性 目前GraCIe 是 Grafana 正在使用的应用程序插件，旨在为用户提供一种简单的方法来了解他们的 CI/CD 系统。它非常适合评估构建性能、识别测试结果中的不一致以及分析构建输出。该应用程序简化了这些流程，旨在轻松提供有关管道的见解。</description></item><item><title>Argo cd 安装和部署</title><link>https://www.jobcher.com/argocd/</link><pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/argocd/</guid><description>Argo cd 安装和部署 Argo CD 是一个为 Kubernetes 而生的，遵循声明式 GitOps 理念的持续部署（CD）工具。Argo CD 可在 Git 存储库更改时自动同步和部署应用程序 安装 前提：你已经安装好了 k8s 环境，我们将在国内的k8s环境下部署argocd
1k3s kubectl create namespace argocd 2kubectl apply -n argocd -f https://github.jobcher.com/gh/https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml 检查是否正常部署 1kubectl get po -n argocd 如果没有错误的情况下应该是全部都runnning，但是如果出现argocd-repo-server CrashLoopBackOff错误有以下解决途径：
使用以下补丁修补了部署。删除后，错误消失，repo 服务器可以启动。 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: argocd-repo-server 5spec: 6 template: 7 spec: 8 securityContext: 9 seccompProfile: 10 type: RuntimeDefault 如果出现argocd-dex-server imagepullbackoff错误有以下解决方法：
1docker pull ghcr.io/dexidp/dex:v2.37.0 2docker tag ghcr.io/dexidp/dex:v2.37.0 harbor/dexidp/dex:v2.37.0 3docker push harbor/dexidp/adex:v2.</description></item><item><title>linux服务器进程打开文件过多导致服务异常</title><link>https://www.jobcher.com/system-limit/</link><pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/system-limit/</guid><description>背景 我的logstash是多管道部署结果发现有大量日志丢失的情况查看logstash日志出现了以下报错
[2023-11-07T09:43:38,492][ERROR][logstash.javapipeline ][log] Pipeline worker error, the pipeline will be stopped {:pipeline_id=&amp;gt;&amp;ldquo;log&amp;rdquo;, :error=&amp;gt;&amp;quot;/var/lib/logstash/queue/log/checkpoint.head.tmp (Too many open files)&amp;quot;, :exception=&amp;gt;Java::JavaIo::FileNotFoundException, :backtrace=&amp;gt;[&amp;ldquo;java.base/java.io.FileOutputStream.open0(Native Method)&amp;rdquo;, &amp;ldquo;java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)&amp;rdquo;, &amp;ldquo;java.base/java.io.FileOutputStream.(FileOutputStream.java:237)&amp;rdquo;, &amp;ldquo;java.base/java.io.FileOutputStream.(FileOutputStream.java:187)&amp;rdquo;, &amp;ldquo;org.logstash.ackedqueue.io.FileCheckpointIO.write(FileCheckpointIO.java:105)&amp;rdquo;, &amp;ldquo;org.logstash.ackedqueue.Page.headPageCheckpoint(Page.java:202)&amp;rdquo;,
这个问题是 Logstash Pipeline 在处理数据时报错,原因是打开文件过多导致&amp;quot;Too many open files&amp;quot;
解决方法 1. 检查操作系统的文件打开数量限制,使用ulimit -n查看。如果太低,可以提高这个限制 打开 /etc/profile 增加ulimit 值
1vim /etc/profile 2## 增加，保存并退出 3ulimit -n 10240 4# 重载配置 5source /etc/profile 2. 适当增大Logstash的heap size,如-Xms和-Xmx设置为2g。 1vim /etc/logstash/jvm.option 2# 修改参数 3-Xms 2g 4-Xmx 2g 5# 重启logstash服务</description></item><item><title>使用 ElasticSearch Curator 7天定期删除日志</title><link>https://www.jobcher.com/elasticsearchcurator/</link><pubDate>Mon, 06 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/elasticsearchcurator/</guid><description>使用 ElasticSearch Curator 7天定期删除日志 背景 Curator 是 Elastic 官方发布的一个管理 Elasticsearch 索引的工具，可以完成许多索引生命周期的管理工作。
我使用的 elasticseraech 8.0 以上的版本，所有我直接安装最新版的curator,服务器是centos 7 的
二进制安装 下载 1wget https://packages.elastic.co/curator/5/centos/7/Packages/elasticsearch-curator-5.8.4-1.x86_64.rpm 安装 curator 1rpm -ivh elasticsearch-curator-5.8.4-1.x86_64.rpm 2curator --version 进入安装文件，创建文件 1cd /opt/elasticsearch-curator 2mkdir log 3cd log 4touch run.log 创建config.yml文件在log目录下 config.yml样例如下： 配置说明参考官网说明：config.yml
1# Rmember, leave a key empty if there is no value. None will be a string, 2# not a Python &amp;#34;NoneType&amp;#34; 3client: 4 hosts: 5 - 192.168.10.17 # elasticsearch IP 地址 6 port: 9200 7 url_prefix: 8 use_ssl: False 9 certificate: 10 client_cert: 11 client_key: 12 ssl_no_validate: False 13 http_auth: elastic:password # elastic 密码，没有就不用写 14 timeout: 30 15 master_only: False 16 17logging: 18 loglevel: INFO 19 logfile: /opt/elasticsearch-curator/log/run.</description></item><item><title>sonarqube docker安装和配置</title><link>https://www.jobcher.com/sonarqube/</link><pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/sonarqube/</guid><description>背景 我是在ubuntu服务器安装docker服务，我已经安装好了docker和docker-compose服务，这里我就不写这些服务的安装过程，直接开始安装sonarqube服务
安装 sonarqube服务器 1.执行脚本文件 config.sh 1#!/bin/bash 2sysctl -w vm.max_map_count=262144 3sysctl -w fs.file-max=65536 4ulimit -n 65536 5ulimit -u 4096 6# # 永久改变 7# echo &amp;#34;vm.max_map_count=262144&amp;#34; &amp;gt;&amp;gt; /etc/sysctl.conf 8# sysctl -p 1sh config.sh 2.执行docker-compose文件 1version: &amp;#39;3&amp;#39; 2services: 3 postgres: 4 image: postgres:15 5 container_name: postgres 6 ports: 7 - 5432:5432 8 volumes: 9 - ./sonar/postgres/postgresql:/var/lib/postgresql 10 - ./sonar/postgres/data:/var/lib/postgresql/data 11 environment: 12 TZ: Asia/Shanghai 13 POSTGRES_USER: user #数据库用户 14 POSTGRES_PASSWORD: password #数据库密码 15 POSTGRES_DB: sonar 16 17 sonarqube: 18 depends_on: 19 - postgres 20 image: sonarqube:9.</description></item><item><title>SSH 通过 443 端口连接 GitHub</title><link>https://www.jobcher.com/ssh-git/</link><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ssh-git/</guid><description>背景 GitHub 提供了两种协议供用户使用 Git 连接—— SSH 和 HTTPS。理论上我可以随意选择两者之一连接到我在 GitHub 上的代码仓库，无论是将云端的仓库 clone 到本地，还是将本地的修改 push 到云端。然而，出于一些奇奇怪怪的原因，我所在的办公网络环境禁止了 22 端口，而 22 端口正是 GitHub 提供 SSH 访问的端口号。尽管可以换用 HTTPS 协议，但无论如何将我电脑上的所有代码仓库的上游都从 git@github.com:... 修改称 https://github.com/... 仍然是一个繁重的体力活。
解决 为了让Git也能通过上述端口用 SSH 访问 GitHub，我们为上述 SSH 连接方式设置一个别名。首先找到SSH的配置文件，它的路径一般是~/.ssh/config，如果这个文件不存在的话也可以创建一个。然后，在其中增加以下内容：
1Host github.com 2 HostName ssh.github.com 3 User git 4 Port 443 其中，Host 是别名，HostName 是实际的域名地址，Port 是端口号。因为我希望当我在用 SSH 连接 github.com 时，实际访问的是 ssh.github.com，所以 Host 和 HostName 分别设置成这两个域名（注意不要颠倒顺序）。
测试连接 1ssh -vT git@github.com</description></item><item><title>iOS 17 「待机显示」适配普通 iPhone（非 Pro/Max），屏幕在充电时常亮</title><link>https://www.jobcher.com/ios17-standby/</link><pubDate>Tue, 26 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ios17-standby/</guid><description>让 iOS 17 「待机显示」适配普通 iPhone（非 Pro/Max），屏幕在充电时常亮 背景 让 iPhone 14/15 Pro/Max 以下机型也可以在屏幕激活待机显示功能（充电且横置）时保持常亮，以显示小组件内容。
2023 年新发布的 iOS 17 有一个新功能：待机显示 StandBy，它能在 iPhone 横向放置且充电时，全屏显示小组件，比如时钟、日历等等，但所有的非 Pro/Max 机型，由于没有全天候显示屏（显示屏能够以低至 1 Hz 的刷新率运行），所以并不能持续使用待机显示，会在几秒钟之后熄灭屏幕，当感受到震动（轻轻拍一下桌子），或有新通知时，再次点亮。
原理 如果 iPhone 接入充电器充电 &amp;gt; 等待 19 秒 &amp;gt; 开关一次低电量模式 &amp;gt; 再运行一次脚本 如果没有充电 &amp;gt; 关闭低电量模式 &amp;gt; 停止脚本 之后，使用自动化功能，当 iPhone 接入充电器时，自动运行这个脚本就行了。 教程 获取链接 自带19秒等待间隔，如果遇到熄屏可以修改为15秒。 注意 小组件自动轮换失效 烧屏：请务必小心，长期使用可能会导致的屏幕问题 充电前需要手动熄屏，否则会因为不断的开关低电量模式而无法进入待机显示</description></item><item><title>GNU/Linux 一键更换系统软件源脚本</title><link>https://www.jobcher.com/linux-mirror/</link><pubDate>Thu, 21 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/linux-mirror/</guid><description>背景 有很多小伙伴，在接受公司老项目后，想要更新服务器源时，发现镜像源失效了，手动添加也很不方便，我这里提供了一个脚本供大家使用，轻松切换镜像源。
支持系统：
&amp;nbsp;Debian 8.0 ~ 12 &amp;nbsp;Ubuntu 14.04 ~ 23 &amp;nbsp;Kali Linux 2.0 ~ 2023 &amp;nbsp;Red Hat Enterprise Linux 7.0 ~ 9 &amp;nbsp;Fedora 30 ~ 38 &amp;nbsp;CentOS 7.0 ~ 8.5 / Stream 8 ~ 9 &amp;nbsp;Rocky Linux 8 ~ 9 &amp;nbsp;AlmaLinux 8 ~ 9 &amp;nbsp;OpenCloudOS 8.6 / 9.0 &amp;nbsp;openEuler 21.03 ~ 23 &amp;nbsp;openSUSE Leep 15 / Tumbleweed &amp;nbsp;Arch Linux all 执行命令 国内使用 1bash &amp;lt;(curl -sSL https://www.jobcher.com/ChangeMirrors.sh) 教育网使用 1bash &amp;lt;(curl -sSL https://www.</description></item><item><title>解决Elasticsearch索引只读（read-only）</title><link>https://www.jobcher.com/elasticsearch-error/</link><pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/elasticsearch-error/</guid><description>背景 这两天有开发向我反馈说elasticsearch有报错，嘿，我定睛一看，这不是进入只读状态了，看来是存储达到额度，我马上加个新的数据节点，平衡一下存储压力
报错信息：
1Elasticsearch Error {type:cluster_block_exception,reason:”blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];} 新建服务器，安装elasticsearch 为了和之前的服务器一样，我简单写一下我elasticsearch版本和服务器系统版本
软件 版本 centos 7.9 elasticsearch 6.7.2 JDK 1.8.61 内存 32G 安装和配置elasticsearch 使用rpm 安装
1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.7.2.rpm 1rpm --install elasticsearch-6.7.2.rpm 配置参数，进入/etc/elasticsearch目录
修改配置vim elasticsearch.yml
1# ======================== Elasticsearch Configuration ========================= 2 3cluster.name: cluster-prod-es # 集群名称 4 5node.name: node-x # 节点名称 6 7path.data: /var/lib/elasticsearch # 数据存储 8 9path.logs: /var/log/elasticsearch # 日志存储 10 11network.host: 192.168.0.170 # 主机IP地址 12 13http.port: 9200 # 端口号 14 15discovery.</description></item><item><title>【福利】埃隆·马斯克传 [沃尔特·艾萨克森] 在线下载</title><link>https://www.jobcher.com/elon-musk/</link><pubDate>Tue, 19 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/elon-musk/</guid><description>介绍 著名传记作家艾萨克森以近距离的观察视角，揭开了如今全球引人注目、富有争议性的创新企业家的神秘面纱：他善于突破常规，引领全球进入电动汽车时代、私人太空探索时代和人工智能时代，还将推特收入囊中。 埃隆·马斯克小时候在南非生活，那时他经常遭受校园欺凌，但同父亲给他造成的情感创伤相比，这些伤痛都微不足道。他的童年浸透了人性，这将他塑造为一个坚强而又脆弱的男孩，他对风险的容忍度极高，渴望营造出富有戏剧性的生活，让人类文明成为星际文明是他的宏大目标。 2008年，SpaceX的火箭在前三次发射过程中接连爆炸，特斯拉也即将破产，这是他生命中地狱般的至暗时期。在飓风来临时，他是最兴奋的人之一。动荡的环境和剧烈的冲突对他有着莫大的吸引力，有时他甚至渴望这些东西，无论是在工作中，还是在他努力维持却未能持久的恋爱关系中。每当面临艰巨的挑战，紧张感常常让他夜不能寐，甚至呕吐不止，但这些都是他赖以为生的养分。 2022年年初，也就是在SpaceX成功发射了31颗卫星、特斯拉卖出了近100万辆汽车、埃隆成为地球上最富有的人一年后，对于自己一再挑起戏剧性冲突的背后动机，他略带感伤地谈起了他的反思。 他说：“我需要改变我的思维模式，不能一直处于危机战备状态，我这种状态已经持续了大概14年，或者说我人生的大部分时间。”这更像是一个自怨自艾的评价，而不是在表达新年新气象的决心。他一边做出了这些反思和保证，一边还在秘密买入推特的股票。 两年来，艾萨克森形影不离地跟访马斯克，参加他大大小小的会议，与他一起走访工厂，深度采访了他本人，以及他的家人、朋友、同事、前妻和对手。艾萨克森揭开了马斯克内幕故事的面纱，其中有荡气回肠的胜利，也有跌宕起伏的乱局，令人拍案称奇。这些故事回答了这样一个问题：那个在马斯克心底驱使着他的恶魔，是不是也是推动创新与进步所必需的呢？
下载链接 埃隆·马斯克传 [沃尔特·艾萨克森].pdf
埃隆·马斯克传 [沃尔特·艾萨克森].epub</description></item><item><title>【破解】小鹏P5和小鹏G9开启adb和网络adb</title><link>https://www.jobcher.com/hackp5g9/</link><pubDate>Thu, 14 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/hackp5g9/</guid><description>LET&amp;rsquo;S HACK NOW! 本文章可以帮助当前正式版本的小鹏P5和小鹏G9开启adb和网络adb
重要提示 如果你对第三方软件的需求高于OTA需求，请关闭OTA功能，P5和G9的下一个版本大概率或已经启用了更高级的加密方式，无法获取解锁码，需要等待其他方式破解 开启adb步骤 首先确认您的爱车是小鹏P5（OTA3.5.0及之前）或小鹏G9（OTA4.3.1及之前）或小鹏G6（未测试）或小鹏P7（OTA2.10及之前）或小鹏G3（版本不确定，最新版不行）
将您的笔记本电脑（已安装adb组件）或安卓手机（已安装甲壳虫adb软件）和您的车机连接到同一无线局域网中（此处可使用另一台手机打开热点），以下使用笔记本电脑举例
打开车机的拨号界面，输入*#9925*111#*
此时车机会显示一个页面，其中包含一个二维码
使用微信扫描您的车机的二维码，并将内容保存备用
在任意输入框中输入内容https://hackxpeng.bgcpdd.eu.org/xpeng?m=hackxpeng&amp;amp;id=，然后将您获取到的二维码内容复制到最后面，注意此处不要有任何的空格
使用浏览器打开您输入框中的所有内容（网址拼接，如：https://hackxpeng.bgcpdd.eu.org/xpeng?m=hackxpeng&amp;amp;id=XPENGD55xxxxxxxxxxxxxx）
浏览器返回一个解锁码（如：*#03*12345678*#）
将该解锁码输入车机的拨号界面，此时解锁码会自动消失，如果没有消失请手动删除所有内容
使用拨号界面输入*#9387*141#*
打开调试和网络调试（一般是前两个选项）
笔记本电脑使用win+r，输入cmd回车，输入adb connect 车机页面中的ip:5050（如adb connect 172.20.10.2:5050）
cmd显示连接成功
下载你需要安装的apk
使用adb install安装软件（如：adb install C:\abc\a.apk）
安装成功
adb还有更多好玩有趣的玩法等你发现
笔记本电脑安装adb套件 打开https://developer.android.google.cn/studio/releases/platform-tools?hl=zh-cn
下载windows版本 并解压
将所有文件放入c盘windows目录下的system32和syswow64 注意两个都要放
致小鹏汽车：以下是关闭获取解锁码api的步骤 将P7 P5的地图更新到高德地图最新版本（包括红绿灯倒计时，最新版高精地图，组队功能，普通道路沉浸导航，语音包等）
将P7 P5的QQ音乐更新到最新版本
承诺定期公布OTA进度（最低界限为每月公布）
将P5 p版sr下放到e版车型（显示车辆运动轨迹）
优化P7 P5 G3/i自动泊车
优化NGP并将速度上限设置为130
将P7 P5的夜晚/白天切换逻辑修改为根据光线传感器，而非日出日落时间
上线P5的智慧场景或私人定制2.0
重新评估P7 P5适配新版UI的可行性
重新评估P7更换8155车机的可行性
全部完成后使用小鹏汽车官方Github账号在本仓库发送issue
文章转载于网络，侵权即删 原文连接</description></item><item><title>Kubernetes — kubecost 分析 Kubernetes 成本</title><link>https://www.jobcher.com/k8s17/</link><pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s17/</guid><description>简介 企业在上云之后，云计算基础设施支出不断创造新高，但 IT 团队却难以找到成本失控的源头，跟每一个业务沟通，所需要的资源都是必须的，降本增效无从谈起。
引入FinOps 的目标是在云上创造一种财务问责制度，每个业务团队需要根据 FinOps 团队的数据做出更加合理的配置、规划，从而在财务成本、业务稳定之间找到一种平衡。FinOps 并不是一次性、短暂的任务，而是在规划实施之后依旧需要进行持续管理，这要求企业必须设定明确的、持续的角色和责任，以保持对成本长期控制。
概念 建立对云成本的共识：企业中各个相关角色应该意识到云成本的重要性，并将成本管理纳入到决策过程中。通过提高成本意识，可以更好地控制和优化云资源的使用。 明确云成本管理的责任和角色：确定负责 FinOps 团队成员，建立相应责任制度。这样确保有专门人员负责云成本的监控、分析和优化，从而提高整体的财务管理效果。 提供培训和教育资源：培训企业成员了解成本管理的基本概念、工具和技术。这有助于增强团队的能力，使他们能够更好地理解和应对云成本挑战。 促进不同团队之间的合作：财务团队、开发团队和运维团队应该紧密合作，共同制定和实施成本管理策略。通过协作，可以更好地理解业务需求、优化资源配置，并确保成本管理策略与业务目标相一致。 利用自动化技术提高效率和准确性：通过采用自动化工具收集、分析和报告云成本数据。自动化还可以帮助实现实时监控和警报，以及自动化资源管理，从而提高成本管理的效率和准确性。 使用 kubecost 分析 Kubernetes 成本 接下来我们展开今天的具体内容，如何使用 kubecost 分析 Kubernetes 成本。
kubecost 是目前较优秀的开源 Kubernetes 成本分析工具，它提供了丰富的功能和仪表板，帮助用户更好地理解和控制其容器化工作负载的成本。
kubecost 目前支持 阿里云、AWS 等云厂商对接，它能够提供集群中命名空间、应用等各类资源成本分配，用户还可以基于这些信息在 Kubecost 中设置预算和警报，帮助运维和财务管理人员进一步实现成本管理。
安装 Kubecost 安装 Kubecost 建议使用 Helm 进行安装，使用以下命令：
1helm repo add kubecost https://kubecost.github.io/cost-analyzer/ 2helm repo update 3helm upgrade --install kubecost kubecost/cost-analyzer --namespace kubecost --create-namespace 几分钟后，检查以确保 Kubecost 已启动并运行：
1kubectl get pods -n kubecost 2# Connect to the Kubecost dashboard UI 3kubectl port-forward -n kubecost svc/kubecost-cost-analyzer 9090:9090 现在可以打开浏览器并指向 http://127.</description></item><item><title>3D Gaussian Splatting：3D模型渲染</title><link>https://www.jobcher.com/3dgaussiansplatting/</link><pubDate>Wed, 30 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/3dgaussiansplatting/</guid><description>简介 只需要一组照片或者一个视频，就能快速地生成一个3D模型。
它使了用一种叫做“3D高斯函数”的数学工具来表示这个3D模型，并找到了一种更快的算法来渲染（即生成）3D模型。
介绍 想象一下，你有一堆照片或视频，你想从一个全新的角度看这些场景。3D Gaussian Splatting 就是一个能让你做到这一点的高级工具。它用一种特别快和高质量的方式来“重建”这些场景，让你能够从任何角度观看它们，就像你实际站在那里一样。
这个工具的“大脑”使用了一种叫做3D高斯的数学模型，这个模型能够非常精确地描述场景的每一个细节。更酷的是，这个工具还能实时地显示这些新角度的场景，这意味着你不必等待很长时间就能看到结果。
简而言之，这是一个能让你以全新、快速和高质量的方式探索照片和视频场景的工具。
使用 硬件要求 具有计算能力 7.0+ 的 CUDA 就绪 GPU 24 GB VRAM（用于训练论文评估质量） 软件要求 Conda（推荐使用，以便于设置） 用于 PyTorch 扩展的 C++ 编译器（我们使用 Visual Studio 2019 for Windows） 用于 PyTorch 扩展的 CUDA SDK 11，在 Visual Studio 之后安装（我们使用 11.8，11.6 存在已知问题） C++编译器和CUDA SDK必须兼容 设置 1SET DISTUTILS_USE_SDK=1 # Windows only 2conda env create --file environment.yml 3conda activate gaussian_splatting 请注意，此过程假设您安装了 CUDA SDK 11，而不是 12。有关修改，请参阅下文。
1conda config --add pkgs_dirs &amp;lt;Drive&amp;gt;/&amp;lt;pkg_path&amp;gt; 2conda env create --file environment.</description></item><item><title>Linux 系统收包流程以及内核参数优化</title><link>https://www.jobcher.com/networkinglinux/</link><pubDate>Wed, 30 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/networkinglinux/</guid><description>简介 高并发的系统架构中，任何细微调整，稍有不注意便会引起连锁反应，只有系统地了解整个网络栈，在处理疑难杂症或者系统优化工作中，才能做到手中有粮心中不慌。在本节，我们概览一个 Linux 系统收包的流程，以便了解高并发系统所面临的性能瓶颈问题以及相关的优化策略。
收包过程 网卡 eth0 收到数据包。 网卡通过 DMA 将数据包拷贝到内存的环形缓冲区(Ring Buffer，在网卡中有 RX Ring 和 TX Ring 两种缓冲)。 数据从网卡拷贝到内存后, 网卡产生 IRQ（Interupt ReQuest，硬件中断）告知内核有新的数据包达到。 内核收到中断后, 调用相应中断处理函数，开始唤醒 ksoftirqd 内核线程处理软中断。 内核进行软中断处理，调用 NAPI poll 接口来获取内存环形缓冲区(ring buffer)的数据包，送至更上层处理。 内核中网络协议栈：L2 处理。 内核中网络协议栈：L3 处理。 内核中网络协议栈：L4 处理。 网络协议栈处理数据后，并将其发送到对应应用的 socket 接收缓冲区。 高并发瓶颈 用户进程调用系统调用陷入内核态的开销。 CPU 响应包的硬中断 CPU 开销 ksoftirqd 内核线程的软中断上下文开销。 RX/TX Ring 优化 处理一个数据包会有各类的中断、softirq 等处理，因为分配给 Ring Buffer 的空间是有限的，当收到的数据包速率大于单个 CPU 处理速度的时，Ring Buffer 可能被占满并导致新数据包被自动丢弃。一个 CPU 去处理 Ring Buffer 数据会很低效，这个时候就产生 RSS、RPS 等多核并发机制来提升内核网络包的处理能力。
但是注意，开启多核并发特性，会挤压业务代码的执行时间，如果业务属于 CPU 密集型，会导致业务性能下降。是否开启多核处理，需要根据业务场景考虑，根据笔者的经验来看，例如此类负载均衡服务器、网关、集群核心转发节点等网络I/O 密集型场景可以尝试优化 RSS、RPS 等配置。</description></item><item><title>2023亚运会电竞门票民购买指南（报名+抽签）</title><link>https://www.jobcher.com/2023yayunhui/</link><pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023yayunhui/</guid><description>2023亚运会电竞门票民购买指南（报名+抽签） 杭州亚运会电子竞技项目门票于8月14日陆续启动销售，门票实名登记。杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售
杭州亚运会电子竞技项目以报名抽签，中签支付的形式对公众销售，包括梦三国2、DOTA2、王者荣耀亚运版本、FIFAOnline4、和平精英亚运版本、街霸V、英雄联盟7个小项全部可售场次。
根据竞赛日程安排，上述7个项目将分4批次启动报名，每个批次的报名、抽签、支付时间不同，具体安排如下：
电子竞技项目报名抽签工作在杭州市国立公证处监督下，通过系统随机抽签、订单中签的方式进行，系统不设任何加权抽签系数。
报名阶段 报名渠道:杭州亚运会公众售票官方网站PC端或H5页面、智能亚运一站通·票务通（点击进入选择项目进行报名）。 用户报名申请单需如实提交以下内容:姓名、证件类型、证件号。 报名规则:在有效报名时间内，注册用户仅可成功提交同一场次1个报名申请单，且报名时间内可随时取消报名申请单，最多可取消同一场次报名申请单10次。每个申请单最多包含2名观赛人，每一名观赛人每一场次只允许成功报名一次。单场次报名申请单如达到200万个则将提前截止报名，截止后不可再提交报名申请单。 调剂规则:用户可选择是否接受调剂。如未能中签首选票档，在调剂票档有库存时系统将自动调剂至调剂票档进行抽签。 通知结果阶段 抽签结果告知方式 :用户可在“用户中心-我的报名”中查看抽签结果。
支付阶段 用户在“用户中心-我的报名”确认支付后，已完成支付报名单可在“我的订单”查询门票订单信息。用户在报名单支付有效期内如需放弃门票可随时点击“放弃购买资格，或在支付阶段支付截止时间前未支付也视为放弃门票。
出票及配送阶段 配座规则:根据订单支付时间先后顺序进行配座出票，含多张门票的订单尽量满足连座。 出票方式:电子竞技项目门票配座完成出票后，选择电子票的用户可在票夹中查看具体门票信息，选择纸质票的用户可在“我的订单”页查看门票信息。 门票购票规则 购票要求:购票人需年满18周岁，18周岁以下应在法定代理人陪同下购票。购票时需填写与门票数量一一对应的实名制信息。 实名制购票及入场:用户需携带门票(纸质票或电子票) 及购票时填写的有效身份证件入场。 不支持转售及转送:电子竞技项目门票为报名抽签项目，电子票与纸质票订单和门票均不支持转售及转送。 门票退票规则 所购门票一旦售出，除杭州亚组委另有规定或者比赛取消外一律不予退换。如比赛取消，持票观众无需在线提交退票申请，杭州亚组委统一安排退票事宜，纸质票无需寄回，电子票在线作废。不能要求更换其他比赛场次的门票。</description></item><item><title>Vue3 + vite + nginx项目部署后404问题</title><link>https://www.jobcher.com/nginx-error/</link><pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx-error/</guid><description>Vue3 + vite + nginx项目部署后404问题 vue3 + vite + nginx
在服务器上部署后打开首页都没问题，打开其他路径全部 404。
nginx 报错日志：No such file or directory
其实查看 build 后的dist文件夹可以发现，只有一个index.html，当你访问别的路径时nignx查找不到所以就报错了
解决方案 在 nginx.conf 中添加: try_files $uri $uri/ /index.html;
server { listen 80; server_name localhost; location / { root /dist; index index.html index.htm; # 在配置文件的此处加上这句话 try_files $uri $uri/ /index.html; } } 总结 其实上述改动就是告诉 nignx 找不到文件的时候就访问 index.html 就可以了。
究其原因其实就是是 vue3 的 router 使用了history模式，该模式与之前hash模式的具体区别可以自行百度一下，不在此赘述。</description></item><item><title>大麦抢票辅助软件(福利 TFBOYS十年之约演唱会 2023 全机位 视频)</title><link>https://www.jobcher.com/damaihelp/</link><pubDate>Tue, 08 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/damaihelp/</guid><description>大麦抢票辅助软件(福利 TFBOYS十年之约演唱会 2023 全机位 视频) 只限android手机！IOS手机不支持！
DaMaiHelper是一款大麦抢票辅助软件（只抢待开抢中的），软件原理是抓取页面ui控件id，通过模拟点击实现的大麦辅助抢票，软件需要开启相应的权限，如果页面渲染太慢，就会抓取失败导致点击超时无效，所以可以手动辅助点击，该软件只能起到辅助效果，帮忙快速点击，一定要提前选好场次、价格还有观影人，收藏到想看。
项目地址
软件下载
使用教程 先去演唱会主页预选好场次、价格还有观演人，点击想看 （可选）手机后台杀掉大麦app任务 打开辅助app，给于对应权限 （可选）输入歌手名字，默认五月天 点击开抢按钮即可 如果点击开抢后，页面未开始自动跳转，可手动杀死大麦，再次切到辅助app点击开抢 如果想终止辅助app，点击右上角悬浮窗&amp;lt;点击停止&amp;gt;即可 福利 TFBOYS十年之约演唱会 2023 全机位
百度网盘下载 链接: https://pan.baidu.com/s/1mry1Mib5TSAuTJWpasoG-g
提取码: icep</description></item><item><title>黑群晖最新安装教程</title><link>https://www.jobcher.com/black_nas/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/black_nas/</guid><description>黑群晖最新安装教程 我这里拿蜗牛星际举例讲解，如何安装群晖最新引导文件，如何正常使用黑群晖。
准备 黑群晖设备一台 电源线 hdmi 或者其他视频线 有线鼠标 有线键盘 显示器 8g 以上U盘 一块1T以上硬盘 开始安装 1. 制作U盘启动器 下载 大白菜U盘制作器 https://www.dabaicai.com/
1、打开大白菜超级U盘装机工具，点击主界面的【U盘启动】模块，然后选择【默认模式】。
2、在【请选择】后面选择需要制作启动的设备（插入的USB设备，一般会默认读取该设备）。
3、模式选择【USB-HDD】，格式选择【NTFS】，然后点击【一键制作USB启动盘】。
4、在点击一键制作后会弹出一个关于【U盘数据删除且不可恢复】的窗口，选择【是】。
2. 引导文件复制 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。
1、载写盘软件和群晖引导文件，然后二个文件复制到U盘上
引导文件下载链接: https://pan.baidu.com/s/1F-Mva0AuEehUNk4q19QyxA
提取码: amf3
复制到U盘!
3. U盘启动黑群晖，写入文件 开始前先拔掉前面4个盘位的硬盘，以防写错盘导致数据丢失。
1、大白菜U盘启动,插上U盘开机自检页面 按F11或F7（根据机型不同快捷按键不同），选U盘启动
2、桌面找到 分区工具DiskGenius
3、点选 第一个硬盘 即便是内置的16G硬盘，右键选删除所有分区
4、保存更改
5、删除分区完毕后 打开此电脑 找 默认的第一个分区里面的写盘工具
6、选择写盘工具软件 打开
7、全部保存默认参数，只需要找到群晖引导文件 打开
8、找到U盘上的群晖引导文件IMG，然后点 右下角的Start 按钮开始写入
写入完毕的 提示，此时就写入完成了，拔掉U盘重启系统即可。
4. 重启设备后安装DSM系统 这里为了保证系统稳定性，使用DSM6.2.3系统，我们这边使用DS918+4盘符
1、下载群晖助手软件和系统文件
Synology Assistant: https://cndl.synology.cn/download/Utility/Assistant/7.0.4-50051/Windows/synology-assistant-7.0.4-50051.exe?model=DS918%2B&amp;amp;bays=4&amp;amp;dsm_version=6.2.4&amp;amp;build_number=25556
2、DSM6.2.3系统：https://pan.baidu.com/s/15CYI12-P1GcdLOa-FqNWrA
提取码: riub
2、安装群晖助手软件：在同一网段内的电脑上安装群晖助手软件
3、打开群晖助手搜索到IP,如果要在线安装系统 就选联机 如果本地安装系统就选 安装</description></item><item><title>CocoaPods 安装及碰到问题</title><link>https://www.jobcher.com/cocoapods/</link><pubDate>Mon, 31 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/cocoapods/</guid><description>背景 CocoaPods 是OS X和IOS 下的第三类库管理工具，通过CocoaPods工具我们可以为项目添加被称为Pods的依赖库
检查环境 ruby -v gem -v 出现异常问题 /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/universal-darwin22/rbconfig.rb:21: warning: Insecure world writable dir /opt/homebrew/bin in PATH, mode 040777
该警告信息表明在你的PATH环境变量中包含了一个“不安全可写”（Insecure world writable）的目录/opt/homebrew/bin。这可能会导致潜在的安全问题。
为了解决这个警告，你需要修复/opt/homebrew/bin目录的权限，以使其不再被标记为“不安全可写”。
解决问题 chmod 755 /opt/homebrew/bin chmod 755 /opt/homebrew chmod 755 /opt/homebrew/sbin 安装cocoapods 输入安装命令
1sudo gem install cocoapods 出现异常问题 ERROR: While executing gem &amp;hellip; (Gem::FilePermissionError) You don&amp;rsquo;t have write permissions for the /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0 directory. /Library/Ruby/Site/2.6.0/rubygems/installer.rb:714:in verify_gem_home' /Library/Ruby/Site/2.6.0/rubygems/installer.rb:904:in pre_install_checks' ……
在 macOS 系统中，系统的Ruby目录通常是受保护的，并且普通用户没有对这些目录进行写操作的权限。为了解决这个问题，你应该避免在系统级别的Ruby目录中进行Gem的安装。相反，你应该使用用户级别的Gem安装目录。
解决方案 1mkdir -p ~/.gem/ruby/2.6.0 2export PATH=&amp;#34;$HOME/.</description></item><item><title>Ansible部署ceph集群</title><link>https://www.jobcher.com/ansible-ceph/</link><pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ansible-ceph/</guid><description>基础配置 三台环境为centos7.9，以下配置需要在每台机器上执行
配置hosts解析 1cat &amp;gt;&amp;gt; /etc/hosts &amp;lt;&amp;lt;EOF 2192.168.2.23 node1 3192.168.2.24 node2 4192.168.2.25 node3 5EOF 关闭防火墙和selinux 1systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld 2setenforce 0 &amp;amp;&amp;amp; sed -i &amp;#39;s/SELINUX=enforcing/SELINUX=disabled/g&amp;#39; /etc/selinux/config 分别在三个节点设置主机名 1hostnamectl set-hostname node1 2hostnamectl set-hostname node2 3hostnamectl set-hostname node3 配置主机时间同步 1systemctl restart chronyd.service &amp;amp;&amp;amp; systemctl enable chronyd.service 配置免密登录 1ssh-keygen 2ssh-copy-id -i .ssh/id_rsa.pub node1 3ssh-copy-id -i .ssh/id_rsa.pub node2 4ssh-copy-id -i .ssh/id_rsa.pub node3 安装pip和ansible、git 1yum install python-pip ansible git -y 部署ceph集群 克隆存储库 这里我选择安装的是ceph nautilus版本</description></item><item><title>最好的微信朋友圈集赞神器-福利推荐</title><link>https://www.jobcher.com/fuli-1/</link><pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/fuli-1/</guid><description>最好的微信朋友圈集赞神器-集赞2.0 奶茶店活动，朋友圈集满50个赞，送一杯奶茶。 饭店新开张，朋友圈集满98个赞，全场7折优惠。 旅游景点拉人气，朋友圈集满60个赞，送门票。
还在为这些恼人的朋友圈集赞发愁吗？ 还在为拿着其他地方生成的集赞图片，怕被发现而胆战心惊吗？ 翻遍通讯录，求着好友帮忙点赞。还是不够数？
现在“集赞”发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量，大大方方展示，不惧查验，轻松薅羊毛。 应付生活中各种需要转发点赞场景，体验效果绝非是那种仅仅生成一张点赞图片能比的。
如果你有这样的烦恼，我推荐你试试这款免费的微信朋友圈集赞神器，简单体验了一下，发现这款工具高度还原了一个整个微信界面ui，现在“集赞2.0 ”发布，逻辑重构，去除一天只能发布一条朋友圈的限制，删除“三连”功能，现在可以无限制的发布，1比1还原微信，轻松设置点赞数，再也不用担心点赞数量。
集赞神器使用帮助页面：https://blog.itakeo.com/help</description></item><item><title>探索midjourney(二)：midjourney prompt初体验</title><link>https://www.jobcher.com/midjourney-prompt-2/</link><pubDate>Sun, 09 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/midjourney-prompt-2/</guid><description>紧接上文，我们继续探索midjourney prompt，这次我们来看看midjourney prompt的基础用法。
midjourney 参数使用 参数是添加到提示中的选项，用于更改图像的生成方式。参数可以更改图像的长宽比、在中途模型版本之间切换、更改使用的 Upscaler 等等。参数始终添加到提示的末尾。您可以向每个提示添加多个参数
许多 Apple 设备会自动将双连字符 (&amp;ndash;) 更改为长破折号 (—)。midjourney接受两者！
基础参数列表 参数 描述 &amp;ndash;aspect, &amp;ndash;ar 更改生成图像的长宽比。 &amp;ndash;chaos &amp;lt;nummber 8-100&amp;gt; 更改生成图像的混乱程度。 &amp;ndash;fast 使用快速模式运行单个作业 &amp;ndash;iw &amp;lt;0-2&amp;gt; 设置相对于文本粗细的图像提示粗细。默认值为 1。 &amp;ndash;no 负面提示, --no plant 将生成没有植物的图像。 &amp;ndash;quality &amp;lt;.25, .5 ,1&amp;gt;, &amp;ndash;q &amp;lt;.25, .5, 1&amp;gt; 您想要花费多少渲染质量时间。默认值为 1。值越高，使用的 GPU 分钟数越多；较低的值使用较少 &amp;ndash;repeat &amp;lt;1-40&amp;gt;, &amp;ndash;r &amp;lt;1-40&amp;gt; 从单个提示创建多个作业。 --repeat 对于快速重新运行作业多次很有用。 &amp;ndash;seed &amp;lt;integer between 0–4294967295&amp;gt; Midjourney 机器人使用种子号来创建视觉噪声场（如电视静态），作为生成初始图像网格的起点。种子数是为每个图像随机生成的，但可以使用 --seed 或 --sameseed 参数指定。使用相同的种子编号和提示将产生相似的结局图像。 &amp;ndash;stop &amp;lt;integer between 10–100&amp;gt; 使用 &amp;ndash;stop 参数在流程中途完成作业。以较早的百分比停止作业可能会产生更模糊、不太详细的结果。 &amp;ndash;tile 参数生成可用作重复图块以创建无缝图案的图像。 &amp;ndash;Turbo 使用 Turbo 模式运行单个作业。 &amp;ndash;Weird &amp;lt;number 0-3000&amp;gt; 使用实验性 &amp;ndash;weird 参数探索不寻常的美学。 参数示例 我了解那么多的参数变化，但是我不知道如何使用它们。让我们看看一些示例，以便您可以开始使用它们。</description></item><item><title>探索midjourney(一)：人工智能生成图像软件的惊人之旅</title><link>https://www.jobcher.com/midjourney-prompt-1/</link><pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/midjourney-prompt-1/</guid><description>人工智能（AI）的快速发展为我们带来了许多令人兴奋的技术创新。其中一项令人瞩目的成果是人工智能生成图像软件，它通过机器学习和深度学习算法，能够创造出惊人逼真的图像。在本文中，我将分享我的旅程，探索这项令人着迷的技术，并展示它的潜力与魅力。这个系列我会长期更新下去
midjourney是什么？ midjourney是一个人工智能生成图像软件，它可以生成惊人逼真的图像。它的工作原理是：它通过机器学习和深度学习算法，学习了大量的图像数据，然后通过这些数据，生成惊人逼真的图像。
midjourney的使用 midjourney的使用非常简单，你只需要在这里注册并订阅输入你想要生成的图像的描述，然后点击生成按钮，midjourney就会生成一个惊人逼真的图像。
需要付费订阅，偶尔有放开免费体验的时候，可以去试试
midjourney的demo 下面是我使用midjourney生成的一些惊人逼真的图像。我会为大家推荐一下我最喜欢的几张图像。
1. 数字墙纸，抽象艺术，曲线流畅，紫色，粉色和蓝色，32k超高清，微妙的渐变，充满活力的，夸张的场景，Dariusz Klimczak，新地形，红移，深弯曲，超细节 1digital wallpaper, abstract art, in the style of smooth curves, purple and pink and blue, 32k uhd, subtle gradients, vibrant, exaggerated scenes, dariusz klimczak, new topographics, redshift, deep curving, hyper-detailed 2. 白色背景线条灰色卡通贴纸，一名宇航员坐在漂浮在太空中的沙发上看电视。背景中有星星和月亮。 1white background linework greyscale cartoon sticker of an astronaut watching Television while sitting on a couch that is floating in space. Stars and moon in the background. 3.</description></item><item><title>推荐一下 容器云资源</title><link>https://www.jobcher.com/20230621/</link><pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/20230621/</guid><description>背景 很多同学在开发软件和测试软件的早期，都会遇到一个问题：如何快速的搭建一个测试环境。这个问题在开发软件的早期是非常棘手的，因为开发软件的早期，往往是没有任何的资源的。这个时候，我们就需要借助一些云资源来帮助我们快速的搭建一个测试环境。接下我会推荐一些云资源，希望能够帮助到大家。
推荐 1.vercel vercel是一个提供托管服务的网站，它可以帮助我们快速的部署一个静态网站。它的优点是：免费、快速、简单。它的缺点是：只能部署静态网站。如果你的项目是一个静态网站，那么我强烈推荐你使用vercel。
2。zeabur zeabur是一个帮助开发者一键部署自己的服务的平台，免费方案限制1个项目数量，1vCPU,内存512M，存储1GB 适合做文档和个人博客
3.腾讯云 国内的良心云，但是现在也不太良心了，不太推荐了，毕竟没什么福利了，如果你是学生的话可以考虑买他们的轻量云来部署他们的服务
总结 我随便推荐一下，建议大家可以先试用一下1和2的方案，希望能够帮助到大家，如果你有更好的推荐，欢迎在评论区留言。</description></item><item><title>2010年的天涯神贴聊房价</title><link>https://www.jobcher.com/housetianya/</link><pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/housetianya/</guid><description>天涯神贴（持续更新中&amp;hellip;） 调控降房价是刚需的一厢情愿 1、人人都有居住权。房子是用来住的，不是用来炒的。 2、房子太贵了，租售比严重不合理，空置率太高，人均收入太低，早晚要崩盘。 3、房价上涨造成物价上涨，人民生活变得困难 调控的真正目的：防范金融风险 &amp;amp; 通过垄断实现gj利益最大化 官方公布的统计数据，只要关系到某个群体的利益，就一定会被修饰导致失真 税收从来都是向下游转嫁的 &amp;amp; 房产税迟迟不出台的真正原因 房地产的现状 房价持续上涨的本质是稀缺性让好房子成为资金最好的去处 关于垄断 1、垄断的好处是没有风险 2、垄断可以解决社会稳定 3、房屋垄断只会愈演愈烈，底层人民想要拥有一套房子的难度只会越来越难 民生问题 房产税的制定原则 维稳的本质是人民能吃饱饭 公租房是为体制内服务的 房产税一定会转嫁给租房人 巨大的税收消耗也决定了GDP必须快速增长 调控的好处是让zf利益最大化&amp;amp;防范金融风险 垄断可以控制价格，维持稳定 体制内的住房问题有国家保驾护航 依靠但又不能完全依靠开发商建公租房 体制内的住房问题不难解决 解决体制外的住房问题：国家垄断，细水长流收租 普通人买得起「优质商品房」就尽早买把 商品房和公租房的区别 提议通过征普税调节贫富差距，不是傻，就是坏（制定政策的人不会让政策针对自己，那么政策都是谁制定的呢） 调控带来的影响 农产品的价格关系到影响稳定的吃饭问题 农产品价格的抬头会导致物价全面上涨，但国家不会坐视不管且有能力管 资金会在优质资产之间流动，而决定优质资产价格的是精英阶层的购买力 资金流向规律决定了农产品和资产价格总有一个要涨，人为压制，一定会按下葫芦浮起瓢 资金流向规律决定了洼地不会一直是洼地 大城市对近距离的小城市有虹吸效应 决定房价的因素有很多，具体情况具体分析 房价暴涨是相对于钱而言的，不是相对于实际购买力而言的 土地不稀缺，优质土地稀缺 集中发展大城市是导致优质土地稀缺的原因 为人民服务是说给人民听的 历史是一面镜子，不同的国情决定了采取同样的政策结果可能是南辕北辙 zf限制政策房的利润，那kfs就一定会偷工减料 屁股决定脑袋，人民不知厉害关系选房子，zf选农产品 各个阶层的住房问题都安排的妥妥的 顶层的岁月静好来自于底层的负重前行 底层指的是体制外底薪白领 资金终会流向具有稀缺性的资产 土地的稀缺决定了大多数人永远买不起想买的房子 不同阶层的人对收入高低有不同的理解 一二线买房只会越来越难，最终租房会成为主流 人需要一个安身之所，能买早买比晚买好 股市 如果房价不涨，那其他产品会怎么涨 zf如何利用公租房控制租房市场 城中村不会长期存在 三四线城市的未来 房租价格涨不上去，本质是买房还看起来有希望 稀缺房的价格永远涨 粮食和房子的不同是，房子无法和土地剥离 购买房价基数低的省会城市，怎么都不会亏的 房地产是资本市场还是实体经济？ 什么是傻空 什么是真买不起房 具体情况具体分析，如果看不懂，一定是没有抓住问题本质 桂林 vs 南宁 公租房的量级不会冲击到商品房市场 贵阳，资源的稀缺导致权贵更容易垄断，通过低收入高物价的方式剥削底层群体 重庆：高层和别墅怎么选？ 货币贬值 为什么美国人工高于中国，但大多数商品的物价却低于中国 还能上车的赶紧上车 武汉：城市发展空间的大小，往往和房价的升值空间成正比 权利让革族成为苗族的一支 房价是否会跌，如果会，会怎么跌 通货膨胀是减缓灭亡最好的良药 货币供应不足是明朝的真正原因 经济问题是导致清朝灭亡 房产投资的几点建议 人民币对外升值，对内贬值 南宁买房建议 经济适用房都是内部分配的 普通人怎么办：尽早买房，努力挣钱抵御通胀 房价会出现很多上下波动 买房时机的选择（真TM厉害，这竟然是2010年的建议，可恨的是2020年才看到） 收入分配改革跟体制外的人没关系 体制外的人要早早考虑养老问题 永远不要和白痴争辩，因为他会把你的智商拉到和他同一水平，然后用丰富的经验打败你 当个农民也要懂政策，要顺政策而为 存钱不如存资产，钱会贬值，资产会升值 房子越早买越好，zf想钱想疯了 利益才是zf行为的指挥棒 建议一定是建立在严肃考察的基础上 石家庄 投资最重要的是稀缺性，买房首选公务员小区 远离垃圾人 高房价或许有天会崩盘，但你等不到那一天 房子不仅要早买，而且有能力的话不要怕压力，争取一步到位 金融杠杆是炒房赚钱的放大器 要用发展的眼光看问题，只要努力，只会越来越好，越来越轻松 性格决定命运 2012年不取消调控，还有房价维稳顺利换届考虑 洼地最终都会被填平，多数城市是早买胜于晚买 西部 短期波动属于正常现象，需要关注的是长期趋势 领导人的智慧和才干决定了国家的命运，统帅的智慧和才干决定了军队的命运，而个人的智慧和才干决定了个人的命运 对于具备投资属性的商品，供求关系是指货币与商品之间的关系 早买的风险小于晚买 小开发商的房子能不能买？ 大兴土木搞建设的城市，房价都底不了 北京老式砖混板楼的最终命运？ 把房买在zf边，差不了 天子脚下：二手老房买得好，拆迁补偿少不了 3万入手北京四环，你也是幸运的 君为贵，商人、技工次之，农民为轻，打工人为底 10年的调控和08年调控的区别、带来的影响、机会 历史总是惊人的相似 关于房贷 买卖商品房会逐渐变成富人的游戏 zf还是更在意农民问题 治国需要用贪官、反贪官 二线城市典型代表 关于商铺和住宅投资 关于房产调控 关于房产税 老公房的拆迁问题 投资新房还是老公房 高端盘有房价带动作用 买房和没买房的差距 房产交易历史 契税的历史 廉租房的历史 历史上买房最好的朝代 未来房地产市场的发展 房产到期 买学区房问题 历史的结局 人口普查 昆山房价分析与买房 为什么现在租售比这么低 &amp;amp; 同小区买一套大还是两套小 买房难之回不去的乡 &amp;amp; 拉美人过得比你想象的好 租房的苦 北京西三旗 买房争取一步到位 收入稳定的家庭如何买房 北京回龙观 贷款还是全款 00后的买房需求从何而来 意大利的住房模式 中国的学术 北京远洋山水 精英的资产 北京三环塔楼 普通人买房的未来 北京房价超香港 中国的新闻不可信，精英的有钱是你想象不到的 40年的商住房没有70年的住宅有投资价值 限贷对精英没用 外汇管制决定了大部分有钱人只能在国内投资 外国国籍在中国生活是更好的选择 分期付款买房，如果房价上涨，很容易毁约 &amp;amp; 自住要选大品牌开发商 通货膨胀和房价的关系 南京买房分析 &amp;amp; 买房要做好调查分析工作 北京华清嘉园 中国的朝代更替 中国可以无限印钞吗 读史读的不是故事，还是找历史规律，以古鉴今 毛太阳往事 北京大兴 贵阳 富人越富、穷人越穷 通货膨胀的形成原因 深圳 &amp;amp; 昆明仇书记 &amp;amp; 通货膨胀体制内高枕无忧、体制外自求多福 长春 佛山 首付提高的逻辑 四线城市 苏州工业园 住房公积金利率 济南 &amp;amp; 大规律拆迁的城市房价不会下降 公务员小区牛逼 房屋朝向只要不是纯北西就行 &amp;amp; 买房首选市中心、公园地产 zf搬迁 俄罗斯 珠海 &amp;amp; 唯一自住房不只是投资 &amp;amp; 调控是最佳的选房时机 经济崩溃，最后接盘的是老百姓 命运之矛 除非外族入侵或全国大饥荒，否则双轨制决定了房价不会崩盘 kkndme聊北宋、唐朝 宋代房奴 ZG民主 王安石的青苗法之国家出政策的动机 什么是社会公平 还是有很多有钱人 双轨制之体制内的福利 开发商思维 农民政权的缺点 郑州有前景 公园地产是稀缺资源 张献忠屠川 洪秀全、黄巢、李自成 朱元璋 曹参治国 晁错 民营小企业的老板和打工者 郭解 2010年的中国房地产 房奴算不上不幸，相当当不了才算 精英人群的平均收入决定房价 内地不是香港、海南 历史是一面镜子 买房一次性到位比较好 外汇管制 一线和二线 吕后篡权 小产权房 商铺和住宅 体制内外 2010年的上海 买房：物业与房贷 收紧住房贷款 买房：物业与房贷 奸臣蔡京 体制内的28原则 贾谊 kkndme 推荐的历史书 年轻人要早买房 不要低估通货膨胀 二三线城市与重庆 城区和郊区 守着金碗要饭吃 人制的社会，人就是制度 准公务员的好处 小城市房价会因为人民币贬值涨价，但依然难变现 一线杭州 二三线城市的发展靠拆迁 转篇文章：一个忽悠了几亿中国人的伪概念：所谓“中国房地产泡沫” 拆迁补偿 城市底层 垄断企业 农村自来水 袁盎 二三线城市，选新城还是老城 在中国，普通人手上闲钱不多的人被剥削 三分天注定七分靠打拼 人的前程有的时候不掌握在自己手里 河南郑州与洛阳 杭州 西安与重庆 谢国中「空置率」 打工不如有一技之长的小老板 一线、二线的生活 讲故事含沙射影ZG之房子不属于市场经济 什么是好的政策 李商隐「渣男」祖师爷 西五环内的别墅，是相当稀缺的资源 调控降房价是刚需的一厢情愿 2010年的房地产调控，让很多人看到了希望：让房价降得再猛烈些吧。还有人更是幸灾乐祸似的呼喊：让房地产赶紧崩盘吧。让没房子的好好看看有房子的笑话，是人生的一大快事。</description></item><item><title>NVIDIA GPU 的 docker 安装和部署</title><link>https://www.jobcher.com/nvidia-docker/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nvidia-docker/</guid><description>背景 在人工智能领域，GPU 是必不可少的。在本文中，我们将介绍如何在服务器上安装和部署 NVIDIA GPU 的 docker
升级你的CUDA 官网链接
选择你的系统对应版本进行安装
安装 确保你的系统已经安装了NVIDIA驱动和Docker引擎。确保驱动版本与Docker引擎兼容。你还需要安装nvidia-docker2软件包，它是NVIDIA Docker的一个插件。可以在https://github.com/NVIDIA/nvidia-docker上找到安装说明
1.1 卸载旧版本的nvidia-docker(如果已安装) 1sudo apt-get remove nvidia-docker 1.2 添加nvidia-docker2仓库
1distribution=$(. /etc/os-release;echo $ID$VERSION_ID) 2curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - 3curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list 1.3 更新软件包列表和安装nvidia-docker2
1sudo apt-get update 2sudo apt-get install nvidia-docker2 1.4 重启Docker守护进程
1sudo systemctl restart docker 通过以下命令测试是否安装成功 1docker run --gpus all nvidia/cuda:10.0-base nvidia-smi 如果安装成功，你将看到类似下面的输出 1+-----------------------------------------------------------------------------+ 2| NVIDIA-SMI 440.33.01 Driver Version: 440.</description></item><item><title>skywalking python agent 安装和配置</title><link>https://www.jobcher.com/skywalking-python/</link><pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/skywalking-python/</guid><description>背景 skywalking 是一个APM监控，在java和微服务领域非常流行。但是在python领域，skywalking的使用率并不高。本文将介绍如何安装和配置skywalking python agent。
SkyWalking Python 代理实现了一个命令行界面，可用于在部署期间将代理附加到出色的应用程序，而无需更改任何应用程序代码，就像 SkyWalking Java 代理一样。
安装skywalking python agent 1pip install apache-skywalking 运行 sw-python 以查看它是否可用，您需要按环境变量传递配置。
配置skywalking python agent 1export SW_AGENT_NAME=服务名称 2# 服务器地址 3export SW_AGENT_COLLECTOR_BACKEND_SERVICES=127.0.0.1:11800 执行python程序 1sw-python run -p python app.py 启用 CLI 调试模式，以便在启动应用程序时查看代理日志： 1sw-python -d run python app.py</description></item><item><title>调教Chat GPT生成Midjourney提示词</title><link>https://www.jobcher.com/midjourney/</link><pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/midjourney/</guid><description>实现功能 Priming GPT4 for Midjourney V5 将每一步直接输入给chatgpt即可，记住要一步步输入
第一步： Hello ，Today we are gonna create Images with a Diffusion model. I am gonna feed you some information about it. okey?
第二步： This is how Midjourney work: Midjourney is another AI-powered tool that generates images from user prompts. MidJourney is proficient at adapting actual art styles to create an image of any combination of things the user wants. It excels at creating environments, especially fantasy and sci-fi scenes, with dramatic lighting that looks like rendered concept art from a video game.</description></item><item><title>如何礼貌回绝不合理的需求</title><link>https://www.jobcher.com/20230524/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/20230524/</guid><description>背景 最近在做一个项目，项目的需求是这样的： spring-cloud有一个服务A，服务A有一个接口，接口的功能是根据传入的参数，返回一个字符串。但是服务响应非常的慢，大概需要4秒左右。这个响应速度是不能忍受的！但是这个服务的开发强行说要上线。我们有几个选项：
1.不上线，但是这个服务的开发无法按期交付 2.上线，但是这个服务的响应速度太慢了，运维背锅 3.劝说服务的开发，让他们优化接口的响应速度
相信大家都会选择第3个选择，那我们站在运维的角度如何劝说服务的开发呢？ 劝说 故障级联（Cascading Failures）：连接超时的服务可能会导致其他服务出现故障级联效应。这是因为微服务系统中的服务通常会相互调用和依赖。当一个服务连接超时时，其他依赖该服务的服务可能无法及时获取所需的数据或执行必要的操作，从而导致它们自身出现故障。
响应时间延迟（Increased Response Time）：如果一个服务连接超时，它的调用方可能需要等待更长的时间来获取响应或超时处理。这会增加整个系统的响应时间，因为其他服务的请求也需要等待超时的服务返回结果。这可能会导致用户体验下降，甚至可能导致其他服务的性能问题。
资源耗尽（Resource Exhaustion）：连接超时可能会导致调用方服务的资源耗尽。当一个服务长时间等待连接超时的服务时，它可能会保持与该服务的连接打开，消耗额外的内存和网络资源。这可能导致调用方服务的资源不足，无法为其他请求提供充足的资源，进而影响整个系统的性能。
重试和失败处理（Retry and Failure Handling）：当一个服务连接超时时，调用方服务通常会尝试重新连接或执行其他失败处理机制。这可能导致调用方服务增加额外的负载，因为它需要多次尝试连接超时的服务。同时，如果没有适当的失败处理机制，连接超时的服务可能无法正确处理重试请求，导致进一步的问题。
结论 综上所述，连接超时的服务对Spring Cloud微服务系统可能会带来级联故障、响应时间延迟、资源耗尽、重试和失败处理的问题，并增加监控和故障排除的成本。因此，及时发现和解决连接超时问题对于确保系统的稳定性和性能至关重要。希望领导能够听取意见，不要让运维背锅。</description></item><item><title>在windows上安装appium</title><link>https://www.jobcher.com/appium/</link><pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/appium/</guid><description>在windows上安装appium Appium 主要用于软件测试自动化领域，以帮助确定给定应用程序的功能是否按预期工作。与其他类型的软件测试相比，UI 自动化允许测试人员编写代码，在应用程序的实际 UI 中演练用户方案，尽可能模拟现实世界中发生的情况，同时实现自动化的各种好处，包括速度、规模和一致性。
安装nodejs Appium是基于Node.js构建的,所以首先需要安装Node.js
下载地址：https://nodejs.org/en/download/
下载并安装，验证是否安装成功
1node -v 安装appium 安装Appium。在命令提示符下运行:
1npm install -g appium 安装appium-doctor 安装appium-doctor。在命令提示符下运行:
1npm install -g appium-doctor 安装appium-desktop 安装appium-desktop。在命令提示符下运行:
1npm install -g appium-desktop 安装jdk 下载地址：https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html 下载并安装，验证是否安装成功
1java -version 安装android-sdk 下载地址：https://developer.android.com/studio 下载并安装，验证是否安装成功
1adb version 配置环境变量 在系统环境变量中添加以下变量
1ANDROID_HOME = D:\Android\sdk 2JAVA_HOME = C:\Program Files\Java\jdk1.8.0_311 3Path = %ANDROID_HOME%\platform-tools;%ANDROID_HOME%\tools;%JAVA_HOME%\bin 验证是否配置成功
1appium-doctor 启动appium 1appium 启动appium-desktop 1appium-desktop 测试脚本 创建测试脚本test.py
1from appium import webdriver 2import time 3 4desired_caps = {} 5 6desired_caps[&amp;#39;platformName&amp;#39;] = &amp;#39;Android&amp;#39; 7desired_caps[&amp;#39;platformVersion&amp;#39;] = &amp;#39;10&amp;#39; 8desired_caps[&amp;#39;deviceName&amp;#39;] = &amp;#39;Android Emulator&amp;#39; 9desired_caps[&amp;#39;appPackage&amp;#39;] = &amp;#39;com.</description></item><item><title>nginx 配置和编译</title><link>https://www.jobcher.com/nginx06/</link><pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx06/</guid><description>nginx 自编译 nginx官网
下载nginx-&amp;gt;Configure-&amp;gt;编译-&amp;gt;安装
下载nginx 1wget https://nginx.org/download/nginx-1.24.0.tar.gz 解压目录
1tar -zxvf nginx-1.24.0.tar.gz 编译最新的 nginx,并备份旧的二进制文件 1cd nginx-1.24.0 2./configure &amp;amp;&amp;amp; make 3mv /path/to/nginx /path/to/nginx.bak 覆盖旧的二进制文件 1cp /path/to/nginx /path/to/nginx 执行平滑重启 1nginx -s reopen 观察nginx服务是否有中断,如果正常则删除备份文件 1rm /path/to/nginx.bak</description></item><item><title>github 国内代理访问下载</title><link>https://www.jobcher.com/github-proxy/</link><pubDate>Tue, 11 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/github-proxy/</guid><description>演示代理 前缀 https://github.jobcher.com/gh/
下载仓库 git clone https://github.jobcher.com/gh/&amp;lt;你要下载的GitHub地址&amp;gt;
1#例子 2git clone https://github.jobcher.com/gh/https://github.com/jobcher/blog.git 部署 复制js到cloudflare worker
1&amp;#39;use strict&amp;#39; 2 3/** 4 * static files (404.html, sw.js, conf.js) 5 */ 6const ASSET_URL = &amp;#39;https://jobcher.github.io/&amp;#39; 7// 前缀，如果自定义路由为example.com/gh/*，将PREFIX改为 &amp;#39;/gh/&amp;#39;，注意，少一个杠都会错！ 8const PREFIX = &amp;#39;/gh/&amp;#39; 9// 分支文件使用jsDelivr镜像的开关，0为关闭，默认关闭 10const Config = { 11 jsdelivr: 0 12} 13 14const whiteList = [] // 白名单，路径里面有包含字符的才会通过，e.g. [&amp;#39;/username/&amp;#39;] 15 16/** @type {RequestInit} */ 17const PREFLIGHT_INIT = { 18 status: 204, 19 headers: new Headers({ 20 &amp;#39;access-control-allow-origin&amp;#39;: &amp;#39;*&amp;#39;, 21 &amp;#39;access-control-allow-methods&amp;#39;: &amp;#39;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS&amp;#39;, 22 &amp;#39;access-control-max-age&amp;#39;: &amp;#39;1728000&amp;#39;, 23 }), 24} 25 26 27const exp1 = /^(?</description></item><item><title>使用scrapy-redis实现增量爬取</title><link>https://www.jobcher.com/scrapyredis/</link><pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/scrapyredis/</guid><description>使用scrapy-redis实现增量爬取 Scrapy-Redis是Scrapy框架的一个插件，可以使用Redis实现Scrapy的分布式爬虫。它使用Redis作为分布式队列，可以轻松地将爬虫分布在多个机器上。同时，它还提供了一些功能，如去重、持久化、增量爬取等。
要使用Scrapy-Redis实现增量爬取，可以采取以下步骤： 在Scrapy项目中安装Scrapy-Redis插件。可以使用pip安装：pip install scrapy-redis 在Scrapy的settings.py中添加如下配置： 1# 使用Redis调度器 2SCHEDULER = &amp;#34;scrapy_redis.scheduler.Scheduler&amp;#34; 3# 使用Redis去重过滤器 4DUPEFILTER_CLASS = &amp;#34;scrapy_redis.dupefilter.RFPDupeFilter&amp;#34; 5# 允许暂停、恢复爬取 6SCHEDULER_PERSIST = True 将Spider的爬取链接放入Redis队列中。可以在Spider中重载start_requests()方法，从Redis队列中获取链接开始爬取。 1import scrapy 2from scrapy_redis.spiders import RedisSpider 3 4class MySpider(RedisSpider): 5 name = &amp;#39;myspider&amp;#39; 6 redis_key = &amp;#39;myspider:start_urls&amp;#39; 7 8 def parse(self, response): 9 # 处理响应 10 pass 在Spider中实现增量爬取。可以通过重载Spider中的start_requests()方法或者使用SpiderMiddleware来实现增量爬取。这里提供一种通过修改Redis队列来实现增量爬取的方法。 1import scrapy 2import redis 3from scrapy_redis.spiders import RedisSpider 4from scrapy.utils.project import get_project_settings 5 6class MySpider(RedisSpider): 7 name = &amp;#39;myspider&amp;#39; 8 redis_key = &amp;#39;myspider:start_urls&amp;#39; 9 redis_conn = None 10 11 def __init__(self, *args, **kwargs): 12 super(MySpider, self).</description></item><item><title>打工人周报（第八期）</title><link>https://www.jobcher.com/2023-03-16/</link><pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-03-16/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第八期`欢迎关注。 资讯动态 1. OpenAI公布最新版本GPT-4 称其能在SAT考试中击败90%考生 3月14日，人工智能研究公司OpenAI公布了其大型语言模型的最新版本——GPT-4，并表示模型在许多专业测试中表现出“人类水平的性能”。
据悉，OpenAI于2020年发布了GPT-3（生成型预训练变换模型3），并将其与GPT-3.5分别用于创建Dall-E和聊天机器人ChatGPT，这两款产品极大地吸引了公众的关注，并刺激其他科技公司更积极地追求人工智能（AI）。
OpenAI周二表示，在内部评估中，GPT-4产生正确回应的可能性要比GPT-3.5高出40%。而且GPT-4是多模态的，同时支持文本和图像输入功能。OpenAI称，GPT-4在模拟律师资格考试的成绩在考生中排名前10%左右，在SAT阅读考试中排名前7%左右，在SAT数学考试中排名前11%左右。据合作方爆料，新版必应搜索引擎也将使用GPT-4。（财联社）
2. 戴尔PC将离开中国 完整时间表曝光 3月14日，有媒体曝光了戴尔所谓“去中化”的全套剧本和时间表，从上游IC采购到中下游周边再到整机组装，都有明确的安排。根据计划，戴尔预计从2025年开始，首先在中下游供应链中排除中国内地制造，并优先在美国内需市场上进行转变。比如笔记本，戴尔计划到2025年，在美国市场上销售的产品，60％必须在中国内地之外的地区生产，2027年则达到100％。IC零组件采购方面，戴尔计划从2026年开始，分阶段离开中国。（快科技）
3. 腾讯会议再次调整：将取消免费300人不限时会议 3月14日，腾讯会议发布调整说明：4月4日起逐步取消免费用户“300人不限时会议”使用权限，单场会议最高人数和时长调整为100人/60分钟。与此同时，会员服务也有部分调整。
4. 华为手表将率先支持卫星通信 3月14日，据华为发布的海报猜测，新系列华为手表将支持卫星通信。短时间内卫星通信技术不仅实现了从实验室到商用的演进，还将实现手机到手表的技术攻坚突破，卫星通信技术或将成为智能穿戴行业的技术新趋势。据了解，即将发布的华为WATCH Ultimate还将支持“上山下海”的全新体验。
5. 谷歌在Gmail等办公应用中引入AI技术：可自动生成所需内容 谷歌宣布，将进一步在其产品中引入人工智能（AI）技术，这一次将把它整合到Gmail电子邮件和Google Docs文档等办公应用中。谷歌还表示，计划在今年晚些时候将更多人工智能功能引入Google Workspace，包括在工作表中生成公式，在幻灯片中自动生成图像，以及在Google Meet中做笔记等。
6. Meta减少数字藏品，发力Meta Pay等金融科技工具 据报道，Meta在推出数字收藏品功能不到一年的时间切断了对其平台上数字藏品或不可替代代币（NFTs）的支持。Meta金融科技主管Stephane Kasriel周一（13日）在推特上发文，“我们目前正在逐步减少数字藏品业务，转而专注其他方式来支持创作者、个人和企业。”还指出，“我们将继续投资于人们和企业未来需要的金融科技工具。我们正在通过Meta Pay简化支付，让结账和付款变得更容易，并投资于Meta的消息支付功能。”
7. 马斯克“减肥神药”遭疯抢！欧洲药管局就短缺问题发出警告 3月14日消息，欧洲药品管理局（EMA）发布官方声明表示，诺和诺德（Novo Nordisk）生产的索马鲁肽降糖针诺和泰（Ozempic） 将面临较长时间的短缺，预计这种短缺将持续整个2023年。药管局补充称，虽然这一药品的供应仍将继续增加，但不确定何时才能到满足市场需求的地步。该机构还要求医生优先为糖尿病患者注射诺和泰，而不是将其作为减肥药物出售。值得一提的是，去年10月，特斯拉CEO埃隆·马斯克在社交媒体回复网友时表示，除了禁食，Wegovy也是他减肥的秘诀之一。
互联网环境 1. 知乎市场负责人离职，教育业务或将分拆 有媒体报道，知乎市场负责人宋晓曦已离职两周，她在知乎的任职时间还不到两个月。2022年4月，原市场负责人、老知乎人来原离职后，市场中心由知乎公关负责人张欢接手。当时，内部人士认为这是一个过渡方案。2023年初，张欢也从知乎离开。知情人士认为，过去一年，市场部门表现可能未获得高层认可。现在，知乎副总裁张宁暂时代管市场部。（市界）
2. 蔚来：不会减配降价，价格内卷不可持续 针对近期宝马、奔驰、奥迪等汽车品牌对旗下主销车型大幅降价，蔚来销售运营助理副总裁浦洋表示：“蔚来不会通过ET5各种类型的减配或者减权益来参与降价。我们相信这波降价潮来得凶猛，退却也快。蔚来会按照自己的策略去争取更大的市场份额，通过直营的手段、更高效的运营，以更精细化毛利的运营方式，为用户提供一个极具高端性价比、极具竞争力的产品。” （中证网）
3. 腾讯T13技术大佬黄希彤被曝遭裁员：曾两次“惊动”马化腾，现年47厂龄15年 3月13日消息，近日，腾讯T13技术专家黄希彤遭腾讯裁员的消息引起网络热议，有人感慨道：“这么资深的大佬竟然都被裁员了”。据悉，黄希彤05年入职腾讯，腾讯首个Web前端专家，职级T13，到今年1月还是腾讯前端级别最高专家。黄希彤夫人在“鹅厂前端No.1”这一账号中透露：（黄希彤）在鹅厂打工15年，年前收到裁员通知。并且强调确实“是裁员不是退休”。而被裁以及不再尝试内部转岗的原因则是：没有坐上管理岗位，不会向上管理，不愿意被PUA。
针对网友“T13都能被裁”的疑问，黄希彤回应表示，大厂当然任何时候都会给最高级的专家留足够的空间，只是留多少，留哪些方向放弃哪些方向、线划到哪里的问题。不管是大厂还是专家，都不需要我们去担忧，实在非要担忧的话，就去担忧自己何时能成为Java之父这样的人好了。（快科技）
4. 董明珠谈“35岁职场危机”：不理解，人们要到60岁才退休 日前，全国人大代表、格力电器董事长兼总裁董明珠接受媒体采访，对于“35岁+职场危机”话题，董明珠称，企业根据专业、需求来选择人才，而不是根据年龄。所谓35岁危机，现在很多人要到60多岁才退休，他们其实还有30年时间要工作。我觉得企业能提供适应的岗位最重要。企业当然希望招进来的人对企业忠诚、有奋斗精神，这个和学历、年龄关系不大，重要的是和岗位匹配。对于一些企业觉得超过35岁的员工 &amp;quot; 狼性 &amp;quot; 不够，同时薪资要求比应届毕业生还高，所以不愿意招收35岁以上的员工的问题。董明珠认为这种说法本身不太成立。35岁的年纪在职场上是有一定经验的，如果企业不需要这样的人，那只能说这个企业的生产力不够，不需要更有经验的人。
5. 理想推用户购车价格保护权益 李想曾称不会降价 据网络上曝光的图片显示，理想汽车推出了用户购车价格保护权益。3月11日起，通过理想汽车官方渠道定购理想L系列车型 (理想L7、理想L8、理想L9)，自定购日 (含) 起90天内，如果所购车型的官方售价发生降价情形，理想汽车承诺将主动返还差价。此前媒体曾报道，理想汽车CEO李想本月初发布微博称，碳酸锂无论如何都要大幅降价了，因为需求远远不如预期。李想同时表示，理想汽车不会降价。（IT之家）
6. 小红书回应后台删照片：系清理用户使用App时生成的临时缓存 近日，有用户反馈自己在使用手机时发现系统提示小红书正在试图删除手机内部图片，引发用户对个人隐私安全的担忧。针对这一事件，小红书今日回应称：小红书 App 并未删除用户手机中的原图片，而是清理了用户在使用 App 时生成的临时缓存。用户在使用某些版本小红书 App 的部分功能时，系统可能会生成临时缓存文件以便于使用。用户完成相应操作后，系统会自动清除，以避免占用用户手机存储空间。</description></item><item><title>🧠ChatGPT 中文使用指南</title><link>https://www.jobcher.com/chatgpt-use/</link><pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/chatgpt-use/</guid><description>🧠ChatGPT 中文使用指南 ChatGPT是由OpenAI训练的一款大型语言模型，能够生成类人文本。
国内中文版 它能够生成类似于人类写作的文本。您只需要给出提示或提出问题，它就可以生成你想要的东西。
在此页面中，您将找到可与 ChatGPT 一起使用的各种提示。
它能干什么? 包括但不限于：
类别 描述 学术论文 它可以写各种类型的学术论文，包括科技论文、文学论文、社科论文等。它可以帮助你进行研究、分析、组织思路并编写出符合学术标准的论文。 创意写作 它可以写小说、故事、剧本、诗歌等创意性的文学作品，能够在描述情节和角色方面提供帮助。 内容创作 它可以写SEO文章、博客文章、社交媒体帖子、产品描述等各种类型的内容创作。它能够为你提供有趣、独特、易读的内容，帮助你吸引读者和提升品牌知名度。 商业写作 它可以帮助你编写商业计划书、市场调研报告、营销策略、商业简报、销售信件等。它可以用清晰、精炼的语言向你的潜在客户或投资者传达你的信息。 学术编辑 它可以帮助你进行学术论文、研究报告、学位论文等的编辑和校对工作，确保文本的正确性、一致性和完整性，并提供改进建议。 翻译 它可以进行英语和中文之间的翻译工作，包括但不限于学术文献、商业文档、网站内容、软件界面等。它可以保证翻译的准确性和专业性。 数据分析 它可以帮助你进行各种类型的数据分析，包括统计分析、文本分析、数据可视化等。它可以使用Python、R等工具来分析你的数据，并提供数据报告和可视化结果。 技术文档 它可以编写各种类型的技术文档，包括用户手册、技术规范、API文档、代码注释等。它可以使用清晰、准确、易懂的语言描述你的技术产品和流程。 教育培训 它可以编写各种类型的教育培训材料，包括课程大纲、课件、教学指南、教育评估等。它可以帮助你设计课程内容和教学方法，并为你制定适合你目标受众的培训计划。 网站内容 它可以编写网站的各种类型内容，包括首页、关于我们、服务介绍、博客文章等。它可以根据你的品牌和目标读者为你提供优质、富有吸引力的内容。 研究咨询 它可以帮助你进行研究、提供咨询意见和建议。它可以进行文献综述、研究设计、数据分析等工作，为你提供高质量、可靠的研究结果和建议。 演讲稿 它可以帮助你编写演讲稿、PPT等，包括商业演讲、学术演讲、庆典致辞等。它可以根据你的主题、目标听众和场合为你编写一份有说服力、生动有趣的演讲稿。 个人陈述 它可以帮助你编写个人陈述，包括申请大学、研究生、博士生、奖学金、工作等的个人陈述。它可以帮助你展现你的优势和价值观，并提供专业的写作建议。 简历和求职信 它可以帮助你编写简历和求职信，帮助你突出你的技能和经验，并为你提供吸引雇主和HR的技巧和建议。 广告文案 它可以编写各种类型的广告文案，包括产品广告、服务广告、品牌广告、活动宣传等。它可以为你编写具有吸引力、清晰明了的广告文案，让你的目标受众更容易接受你的产品或服务。 SEO优化 它可以帮助你优化你的网站、文章或其他内容的SEO。它可以使用关键词研究、内容优化等技术，帮助你提高排名、获得更多的流量和转换率。 社交媒体 它可以为你编写社交媒体内容，包括微博、脸书、Instagram等。它可以帮助你设计吸引人的标题、内容和图片，并为你提供有用的社交媒体营销策略。 新闻稿 它可以帮助你编写新闻稿，包括公司新闻、产品发布、重大事件等。它可以为你编写新闻稿、编辑和发布，以吸引媒体关注并提高品牌知名度。 多语言翻译 它可以提供各种语言之间的翻译服务，包括英文、中文、法文、德文、西班牙文、俄文等。它可以翻译各种类型的文件，包括技术文档、商务合同、宣传资料、学术论文等。 电子商务 它可以编写各种类型的电子商务内容，包括产品描述、产品说明书、电子商务博客文章等。它可以帮助你编写吸引人的产品描述，以及建立与客户的信任和忠诚度。 旅游文案 它可以帮助你编写旅游文案，包括旅游目的地介绍、旅游路线规划、旅游攻略、旅游博客等。它可以帮助你为你的读者提供有用的信息和建议，帮助他们计划自己的旅行。 医疗文案 它可以帮助你编写医疗文案，包括医疗产品说明、疾病预防、健康知识、医疗博客等。它可以帮助你使用专业的术语和语言，使你的文案更易于理解和接受。 儿童读物 它可以帮助你编写儿童读物，包括故事书、绘本、启蒙读物、课外阅读等。它可以使用有趣、生动的语言和图片，吸引孩子们的注意力，并帮助他们学习和成长。 小说 它可以帮助你编写小说，包括各种类型的小说，如言情、悬疑、恐怖、科幻等。它可以帮助你创造有趣、引人入胜的情节和角色，并为你提供专业的写作技巧和建议。 充当 Linux 终端 我想让你充当 Linux 终端。我将输入命令，您将回复终端应显示的内容。我希望您只在一个唯一的代码块内回复终端输出，而不是其他任何内容。不要写解释。除非我指示您这样做，否则不要键入命令。当我需要用英语告诉你一些事情时，我会把文字放在中括号内[就像这样]。我的第一个命令是 pwd
充当英语翻译和改进者 替代：语法，谷歌翻译
我希望你能担任英语翻译、拼写校对和修辞改进的角色。我会用任何语言和你交流，你会识别语言，将其翻译并用更为优美和精炼的英语回答我。请将我简单的词汇和句子替换成更为优美和高雅的表达方式，确保意思不变，但使其更具文学性。请仅回答更正和改进的部分，不要写解释。我的第一句话是“how are you ?</description></item><item><title>打工人周报（第七期）</title><link>https://www.jobcher.com/2023-03-09/</link><pubDate>Thu, 09 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-03-09/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第七期`欢迎关注。 资讯动态 1. 特斯拉因石子故障维修需花14万，特斯拉回应：电池价位占总价一半，都是明码标价 江西南昌董女士反映自己开特斯拉出门因碾压到路上小石子，石子弹射到车辆空气管致故障。行驶中发现行驶灯故障并出现无法加速情况。董女士将其送往维修中心。经过检测鉴定为电池故障需更换电池，费用大约需要14万元。高额的维修更换费用让董女士难以接受，目前该车辆正在走流程当中。据特斯拉官方回应称：电池价格占到车辆总价的一半，因为电池相对很重要，它的价格都是官方明码标价。（知未）
2. 中文在线：国内首个科幻主题元宇宙RESTART将于本月进行首期功能模块上线 3月8日，中文在线在互动平台表示，公司目前已上线3款AIGC产品，分别为AI主播、AI绘画和AI文字创作功能。此外，根据公司自有IP打造的国内首个科幻主题元宇宙RESTART（重启宇宙）将于本月进行首期功能模块上线。同时，公司在国内和国外的不同应用产品上进行AIGC技术测试，推动业务合作。（界面新闻）
3. 上海宜家回应禁止在仓库拍照：若影响其他客户体验将制止 近日，有网友发现在宜家大仓库区域不允许拍照。上海某门店客服称“一般的情况下，我们是让每个顾客满意，如果只是拿出手机随意拍两张是无所谓的。但是有的人，一些网店的人他们会拿着自己的箱子，服装来拍，影响到了其他客户的体验，在我们没法判断顾客进来是否会影响到他人的情况下，我们一般是不允许拍照的。”（新闻晨报）
4. 特斯拉在美遭监管机构调查：Model Y方向盘在驾驶过程中脱落 3月8日，美国国家公路交通安全管理局（NHTSA）表示，在接到两起投诉后，已开始对特斯拉Model Y电动汽车的方向盘脱落问题展开调查。NHTSA称，已经接到两起事故投诉，车主在驾驶2023年生产的Model Y SUV电动汽车时，车轮竟然脱离了转向柱，即方向盘脱落。这主要是因为，受影响车辆在没安装固定螺栓（用于固定方向盘）的情况下就交付给了车主。（新浪科技）
5. 美科学家团队重提“室温超导” 美国物理学会网站显示，罗切斯特大学物理学家蓝戈·迪亚兹举办了题为“静态超导实验”的报告会议，报告会现场爆棚，会议摘要显示，迪亚兹团队开发的新材料可以在更宽松的环境条件下表现出超导性。据报道，该团队在最新的实验中研发了一种由氢、氮和镥制成的材料，“它似乎可以在约21摄氏度的温度以及10千帕的压力下进入超导状态。”报道指出，虽然10千帕大约是常压环境的10000倍，但已经远远低于在其他室温超导体通常所需的数百万倍。迪亚兹表示，“这是可用于实际应用的新型材料的开端。
6. 微软将整合ChatGPT：不用写代码就能开发应用 3月6日晚间消息，据报道，微软公司今日将ChatGPT背后的技术整合到其Power Platform平台上，允许用户在几乎不需要编码的情况下，就能开发自己的应用程序。
当前，Alphabet等多家大型科技公司，均争相将“生成式人工智能”整合到他们的产品中。微软今日表示，其Power Platform平台上的一系列商业智能和应用程序开发工具，包括Power虚拟代理（Power Virtual Agent）和AI Builder，均已更新ChatGPT功能。
互联网环境 1. 奇瑞领导回应周六要上班争议邮件：本意是不是压榨，鼓励愿意努力的奋斗 近日，奇瑞汽车高管要求员工规避法律风险想办法加班的内部邮件曝光，引发舆论热议。该邮件发件人为奇瑞汽车股份有限公司执行副总经理、汽车工程技术研发总院院长高新华。在回复研发出勤统计时这位高管称，所有员工应以奋斗者为本，周六是奋斗者的正常工作日，对于行政领导们则必须为正常工作日，并暗示员工想办法规避加班的法律风险。3月8日，高新华回应称，邮件要求的对象并非普通员工，而是希望激发愿意努力工作的员工，鼓励他们奋斗，同时不让他们吃亏，邮件内容本意并非压榨员工。但对于外界关注的「规避法律风险」这一说辞，高新华则并未做出回应。（Tech星球）
2. 科亚医疗自主研发人工智能CT-FFR露锋芒！ACC.23 TARGET研究结果发布 3月5日，中国人民解放军总医院心脏医学中心陈韵岱教授团队在美国心脏病学会/世界心脏病（ACC/WCC）2023大会，发表基于人工智能CT-FFR技术指导稳定性冠心病患者治疗随访的临床研究报告-TARGET试验，该研究结果将同步发表在国际顶级期刊《Circulation》杂志。该研究采用的是我国科亚医疗科技股份有限公司自主研发的CT-FFR模拟计算技术-深脉分数，利用深度学习技术和人工智能技术对冠状动脉造影图像进行FFR评估，能快速、准确地进行无创血流储备分数分析，该技术已成为全球唯一获得中国NMPA、欧盟CE、美国FDA三重认证的CT-FFR产品。该研究发现，对于冠脉狭窄程度在30%~90%的稳定型冠心病患者，使用科亚医疗自主研发的现场人工智能CT-FFR检测可行、安全、有效，能够挑选更适合有创冠脉造影和血运重建的患者。
3. 新加坡科技人才逆势涨薪 经济前景不明朗，全球科技企业相继裁员瘦身，新加坡科技人才却能逆势涨薪。科技行业薪酬调查显示，2022年新加坡软件工程师薪酬平均上涨7.6%，月薪创下新高并居于亚洲之首，不过，相较2021年时22%的涨幅显著收窄。去年，新加坡“首席软件工程师”岗位的中位数月薪为6666美元，印尼的同一岗位的收入中位数为1309美元，而印度相同岗位为1357美元。最受科技从业人员关注的五大企业包括字节跳动、新加坡政府科技局、虾皮、币安和维萨。（第一财经）
4. 国务院机构改革：重组科学技术部，中央国家机关人员编制按照5%比例精减 根据国务院关于提请审议国务院机构改革方案的议案，重新组建科学技术部。保留国家基础研究和应用基础研究、国家实验室建设、国家科技重大专项、国家技术转移体系建设、科技成果转移转化和产学研结合、区域科技创新体系建设等相关职责，仍作为国务院组成部门。议案还提出要组建国家数据局。负责协调推进数据基础制度建设，统筹数据资源整合共享和开发利用，统筹推进数字中国、数字经济、数字社会规划和建设等，由国家发展和改革委员会管理。
5. TikTok将限制青少年每天的屏幕时间为60分钟 TikTok宣布了一批新功能，旨在减少屏幕时间，提高年轻用户的幸福感。在未来几周，每天60分钟的屏幕时间限制将自动适用于每个18岁以下的TikTok用户。达到这一限制的青少年将被要求输入一个密码以继续观看，并且他们可以完全禁用该功能，但如果他们这样做，并且每天在TikTok上花费超过100分钟，他们会被要求设置新的限制。
科技分享 1. ChatGPT 3.5 版本 国内聊天工具 采用最新的gpt-3.5-turbo模型，stream模式，秒回
链接直达 2. 选股工具 比较全面的选股工具，还能查看指数。
链接直达 3. 油猴脚本：我只想好好观影 打开豆瓣，搜索自己想看的电影，点击播放
我只想好好观影 欢迎关注我的博客 [www.jobcher.com](https://www.jobcher.com/)</description></item><item><title>打工人周报（第六期）</title><link>https://www.jobcher.com/2023-03-02/</link><pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-03-02/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第六期`欢迎关注。 资讯动态 1. 知乎推出“一起公考AI课”APP，再加码教育业务 近日，知乎上线了一款名为“一起公考AI课”的APP，是知乎教育旗下的职业教育品牌。据悉，该产品运用了AI教学技术，专门提供公务员考试课程内容。根据体验，“一起公考AI课”APP，当前主要提供“行测”的笔试内容，通过AI教学技术逐节解锁5大模块，覆盖192个知识点，部分课程服务需进行付费。（Tech星球）
2. 苹果：今天起，iPhone等设备电池正式涨价 苹果官网显示，从3月1日起，苹果iPhone、iPad、Mac部分机型的换电池服务将正式涨价。其中，iPhone 14之前的所有iPhone机型保外电池服务费用将增加169元。所有MacBook Air机型的保外电池服务费用也将增加290元，而所有Macbook和MacBook Pro机型的保外电池服务费用将增加480元。此外，以下iPad机型的保外电池服务费用将增加149元。
3. Snap推出ChatGPT驱动的聊天机器人 据报道，照片信息应用Snapchat的母公司Snap在表示，将推出一个由ChatGPT技术驱动的AI聊天机器人。当前，该公司正寻求进入热门的生成式AI领域。Snap表示，新的聊天机器人名为My AI，将提供给Snap的高级订阅Snapchat+的用户使用。Snap表示，在经过训练之后，My AI能够提供一种有趣和轻松的对话方式，并将能够提供创造性的想法，如为朋友的生日提供潜在的礼物，或为某个主题写一首诗。
4. 小米无线AR眼镜探索版正式发布 在2023MWC世界移动通信大会上，小米正式发布小米无线AR眼镜探索版。该眼镜拥有三大创新：采用无线连接，手机与眼镜通信延迟低于3ms，全链路延迟低至50ms；采用自由曲面光学模组，实现了“视网膜级”显示；采用自研微手势交互。具体来说，佩戴小米无线AR眼镜探索版时，在日常使用一个应用的过程中，挑选一个应用并打开、滑动浏览页面、退出应用回到桌面，这些操作都可使用微手势交互，无需借助手机。
5. 苹果RealityPro头显无需iPhone配合使用 在最新一期的Power On通讯中报道，最新测试版本的Reality Pro头显“将不需要iPhone来设置或使用”。这与过去的苹果设备相比是一个很大的变化，如Apple Watch，其最初需要iPhone来初始化设置。相反，Reality Pro头显将支持独立于iPhone进行设置，然后可以直接从iCloud下载用户的数据。不过与其他苹果设备的设置过程类似，用户也可以选择直接从iPhone或iPad向头显传输数据。
6. 世界上首款癌症疫苗即将获批 莫德纳近日宣布，mRNA-4157/V940，该公司正在研究的一种mRNA癌症疫苗，与默沙东的抗PD-1疗法Keytruda联合使用，已被美国食品药品管理局(FDA)授予突破性疗法认定，用于完全切除后的高危黑色素瘤患者的辅助治疗。（每经）
7. 比亚迪今年首次降价：王朝系列降幅超1万，交付周期大幅缩短 从北京、上海等多家比亚迪展厅获悉，比亚迪王朝系列产品已经启动降价，交车周期较去年出现不同程度的缩短。目前比亚迪暂未通过官方渠道公布降价讯息。北京一家比亚迪王朝展厅销售人员向界面新闻表示，刚刚收到官方发布的调价通知，大部分车型均有价格优惠。其中，老款车型的优惠幅度在1万元以上，部分热门现款产品也有上千元的优惠。上海与深圳地区也均有不同程度的降价，但调价力度最高在万元上下。（界面新闻）
互联网环境 1. 华为起诉小米专利侵权，国家知识产权局已受理 据国家知识产权报第 02 版刊发的《重大专利侵权纠纷行政裁决受理公告》显示，华为起诉小米专利侵权。该公告显示，2023年1月17日，国家知识产权局受理了请求人华为提出的被请求人小米侵犯其四项中国专利的案件，四个专利分别为“发送控制信令的方法和装置”，“载波聚合时反馈ACK/NACK信息的方法、基站和用户设备”和“一种获取全景图像的方法及终端”，“一种锁屏方法及移动终端”。
2. “宁德时代”理财骗局曝光：有人损失上百万 涉及多省上千人 近日，有多位投资者向红星资本局爆料称，自己在一款名为“宁德时代”的App中，遭遇了投资理财骗局，被骗金额从几万元到上百万元不等。据投资者介绍，这款“宁德时代”App，可以购买“宁德时代锂电池”“宁德时代专属社会公众股”等理财投资产品，收益颇高，还能每天提现。加入“宁德时代”App投资群的投资者或有上千人，涉及全国多个省份。不过，2月26日，宁德时代相关负责人回应称，上述“宁德时代”App不是公司的，“宁德时代”投资群里自称与宁德时代对接的杨某也不是该公司员工。(红星资本局)
3. 阿里确定淘宝2023年五大战略，价格力在今年会更被重视 阿里近期确定了淘宝今年的五大战略：直播、私域、内容化、本地零售和价格力。目前，这五个战略如何展开在核心管理层已经有了初步方案，但尚未最终确认。多位阿里员工表示，只知道有这五个战役，但他们都不清楚具体策略。此外，淘宝内部已经明确指出，今年相比GMV（网站成交金额）增长，更重要的指标是DAU（日活跃用户数量）增长。（晚点 LatePost）
4. 高通发布全球首个可商用部署的iSIM卡 2月28日，高通和泰雷兹宣布，双方在第二代骁龙8移动平台（骁龙8Gen2）上完成全球首个可商用部署的iSIM卡（集成式SIM卡）认证，使SIM卡功能能够通过智能手机的主处理器实现。据介绍，该iSIM卡完全符合GSMA远程SIM卡配置规范，可通过任何标准平台对iSIM卡功能订阅进行远程管理。（IT之家）
科技分享 今天是AI科技主题！ Arc图片增强
腾讯出品的图像增强器，人像修复效果超赞👍🏻
链接直达
SolidGrids
AI去除背景
链接直达
AI帮个忙
AI文本小工具，用AI生成周报，点评，邮件……
链接直达
Copy.ai
优化从他人拷贝博客或文案，并提高转化率
链接直达
Glasp
Highlight网页，AI生成全文摘要，导入笔记软件，还可以生成Youtube内容概要
链接直达
Runway
用AI塑造先进的视频编辑能力，帮助视频创作者生产更优质的视频内容 链接直达
欢迎关注我的博客 [www.</description></item><item><title>ChatGPT Plus开通教程攻略</title><link>https://www.jobcher.com/chatgpt-plus/</link><pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/chatgpt-plus/</guid><description>ChatGPT Plus开通教程攻略 鉴于免费的ChatGPT账号经常无响应或者响应慢，一些已经顺利注册到ChatGPT的推特用户私信我，问我怎么开通ChatGPT Plus，于是我收集了各大佬们的各种开通ChatGPT Plus的方法，挑一个比较简单的测试了一下，目前顺利开通了ChatGPT Plus，20美金一个月，想要体验的同学可以跟着试试，目前国内大部分的master或者visa信用卡都无法通过验证的，我也是使用网友推荐的Depay信用卡成功开通ChatGPT Plus的。
而且这卡还可以绑定美区的Apple ID作为付款方式，虽然美区Apple ID可以使用支付宝或者购买礼品卡进行充值，况且我已经绑定了Paypal，这卡还可以绑定国内微信支付宝进行消费，挺不错的。ChatGPT Plus开通攻略
1、硬性条件 如果你具有两个条件，那么可以试试这个方法，能够顺利开通到ChatGPT Plus。
ChatGPT账号 纯净可访问ChatGPT的网络（全局美国IP网络） 如果你没有可以在这里跟着注册一个：ChatGPT注册详细步骤攻略 亲测成功
2、注册领取虚拟信用卡 首先，你得注册一个可以绑定ChatGPT付款的信用卡：邀请注册地址
使用手机或者邮箱都可以，注册完下载app
iOS需要外区账号
安卓用户直接下载apk安装即可
下载安装完app，使用账号登录，点击申请卡，然后根据自己的情况进行选择卡片类型
免费开卡需要进行KYC验证 免KYC信息认证的需要支付10USDT 我选择的是免费开卡-标准卡，根据提示提交信息进行认证即可（大佬可以直接充钱免认证，看个人）
3、钱包充值 目前激活该卡片需要充值USDT，而且仅支持USDT-TRC20方式进行充值
我不是高级玩家，可以通过OKX、Bitop等等交易市场进行USDT-TRC20充值即可
或者身边有朋友有的，直接转到你钱包也可，A姐使用的是OKX，
不过发现我是新账号，需要7天才可以提币（不知道是不是针对我的，我也是小白）
于是没有等，喊朋友直接转到我钱包了，身边没有朋友使用的，可以使用OKX试试
开通ChatGPT需要20美元，其中转账或者兑换会有点汇率或者手续费
充值25USDT够了，我充值了30USDT，开通完剩余8USDT多一点
4、激活信用卡 等待到账号，点击充值，然后把收到的USDT充值到卡片进行激活信用卡，然后会提示余额不足，提示你把USDT兑换成USD，按要求操作即可
5、订阅开通ChatGPT Plus 激活完信用卡后，登录你的ChatGPT账号，点击Upgrade to Plus，然后点击Upgrade plan
然后填写卡片信息和账单信息
卡片信息点击信用卡app 旁边的CVV安全码获取
账单地址可以使用 虚拟美国人信息生成器获取，需要是免税州的地址，不然有额外的费用，账单地址不会填的可以抄我的。
填写完信息，点击订阅/Subscribe 等待验证即可成功订阅开通ChatGPT Plus。
欢迎关注我的博客 [www.jobcher.com](https://www.jobcher.com/) 转载自（https://www.ahhhhfs.com/）</description></item><item><title>打工人周报（第五期）</title><link>https://www.jobcher.com/2023-02-23/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-02-23/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第五期`欢迎关注。 资讯动态 1. 星链拟推出“全球漫游”互联网服务 月收费超 1300 元 SpaceX 旗下星链（Starlink）卫星互联网服务部分用户收到的最新消息显示，该公司正在测试名为“全球漫游”的互联网服务，其可以让人们“在世界上的任何地方接入网络”。然而，使用这项服务的费用并不便宜，除了花费 599 美元购买基本的星链套件之外，用户每月还需支付 200 美元（约合 1373 元人民币）费用。
2. 爱奇艺黄金 VIP 恢复 720P 和 1080P 投屏 不再限制登录设备种类 2 月 20 日，爱奇艺做出两项会员服务调整：为 2023 年 2 月 20 日仍处于订阅状态的爱奇艺黄金 VIP 会员，恢复 720P 和 1080P 清晰度的投屏服务，以及爱奇艺黄金、白金、星钻 VIP 会员可在 5 台设备上登录，不再限制登录设备种类。当播放设备数量达上限后，爱奇艺会提示用户选择希望使用的播放设备。如遇 IP 地址异常等安全风险导致账号锁定，用户可通过修改密码解除锁定。
3. 消息称京东拟 3 月初上线百亿补贴频道 2 月 20 日消息，据媒体报道，京东计划在 3 月初上线百亿补贴频道，正式向拼多多开战。报道称，百亿补贴频道将在 3 月 1 日~3 月 3 日前台切量 100%正式上线；3 月 3 日晚 8 点正式开场。今年，京东大商超事业群将重点发力 pop，自年初实施“0 元开店”策略以来，已经邀请了一批商家入驻，并承诺给予入驻商家一定的流量倾斜。至于这次京东的补贴方案，无论是自营还是 pop，都将与拼多多的商品价格进行比较，如果价格高于拼多多，就会进行补贴，同时也会与拼多多拉平抽取费用。报道还称，拼多多方面已采取初步应对措施，比如，拼多多百亿补贴频道已将部分京东员工 IP 屏蔽。（深厂）</description></item><item><title>打工人周报（第四期）</title><link>https://www.jobcher.com/2023-02-16/</link><pubDate>Thu, 16 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-02-16/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第四期`欢迎关注。 上周因为个人原因延了一期，之后会补上。 资讯动态 1. 宝马 i4 车主收到通知：车停在陡坡上无法升级 近日，宝马 i4 车主 Clare Eliza 近日收到通知：“路面太陡无法启动升级程序。请将车辆停到平坦区域再进行更新”。也就是说宝马 i4 车辆停在陡坡上就无法执行更新。宝马发言人表示：“宝马 i4 配备了俯仰、偏航、横向和纵向加速和减速等各种各样的传感器，汽车能够自行检测是否停在平坦路面上。这是一项安全预防措施，防止在糟糕的情况下导致车辆无法正常升级，避免滑坡等情况影响系统的升级”。（IT 之家）
2. 科学家发现阻止新冠病毒感染的受体 悉尼大学的科学家在肺部发现一种蛋白质，可阻止 SARS-CoV-2 感染，在人体内形成天然保护屏障。被称为 LRRC15（leucine-rich repeat-containing protein 15） 的蛋白质能与 SARS-CoV-2 结合但不传播感染。英国牛津以及美国布朗和耶鲁大学的团队都各自独立在 LRRC15 蛋白质中发现了受体。
SARS-CoV-2 病毒主要通过与 ACE2 受体结合感染人体细胞，而肺细胞具有高水平的 ACE2 受体，因此病毒主要通过感染肺部而造成严重问题。LRRC15 和 ACE2 一样都是 SARS-CoV-2 的受体，但不同之处是它不支持感染，通过粘住病毒使其无法移动，防止其它脆弱的细胞被感染。它会形成一道屏障，隔离病毒和最脆弱的肺细胞。（奇客 Solidot）
3. 印度首款太阳能电动汽车 Vayve Eva 亮相，每天不花钱能跑 12 公里 2 月 12 日消息，总部位于印度浦那的电动汽车初创公司 Vayve Mobility 宣布计划于 2024 年推出印度首款太阳能电动汽车 Eva，并于 2024 年年中开始交付。
从图中可以看到，Vayve Eva 是一款超小型的城市通勤车，可容纳两名成人和一名儿童。Eva 在车顶配备了一堆额定功率为 150W 的太阳能电池板，每天可以增加 10~12 公里的续航里程。Vayve Eva 还装有 14kWh 的电池组，总续航达到了 250 公里，并且可以使用家用壁式插座充电器在 4 小时内充满电。（IT 之家）</description></item><item><title>打工人周报（第三期）</title><link>https://www.jobcher.com/2023-02-02/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-02-02/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第三期`欢迎关注。 资讯动态 1. 优酷“首月 1 元”会员引争议：取消续费却被扣 24 元 1 月 30 日消息，近日优酷的“1 元会员”又引发争议。据上观新闻报道，优酷视频于 2022 年年末上线“首月 1 元”会员优惠充值活动，但多名用户反映，其在完成支付后才发现，支付宝相应页面中弹出的实则为“优酷月月省”活动界面，支付 1 元后默认签约 1 年，除首月外，每月将自动扣费 12 元。由于并无长期会员需求，不少用户选择了提前中止参与该活动，不料却立刻收到了扣费 24 元的提示：“未完成任务，扣回已享优惠。”
2. ChatGPT 全球爆火后：百度宣布 3 月将推出类似 AI 服务 1 月 30 日，据报道，一位知情人士透露，百度公司正计划在今年 3 月推出与 OpenAI 的 ChatGPT 类似的人工智能聊天机器人服务，最初版本将嵌入其搜索服务中。这项工具将允许用户获得对话式的搜索结果，但名称尚未确定。百度的一位代表对该消息不予置评。
3. 网易开放暴雪游戏退款申请通道 申请排队人数超 90 万 2 月 1 日，网易暴雪游戏客服团队面向暴雪游戏国服玩家，发布了《网之易关于暴雪游戏产品运营到期开放退款的说明》。网易暴雪游戏客服团队表示，从 2023 年 2 月 1 日 11 时起，针对玩家在“暴雪游戏产品”中已充值但未消耗的虚拟货币或未失效的游戏服务（下称“可退款商品”）开放退款申请通道。
此外，提交退款申请的截止日期为 2023 年 6 月 30 日，未在截止日期前提交退款申请的玩家将被视为主动放弃相关权益。截至 2 月 2 日 0 时 12 分，在暴雪游戏服务中心的退款渠道中，申请退款的排队人数已超 90 万。</description></item><item><title>打工人周报（第二期）</title><link>https://www.jobcher.com/2023-01-19/</link><pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-01-19/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第二期`欢迎关注。 [通知]因春节假期改为周一发布 资讯动态 1. 曝 iPad Pro 未来会砍掉实体按键：梦回 iPhone 7 时代 1 月 12 日消息，据 9to5Mac 报道，苹果今年下半年要发布的 iPhone 15 Pro 将会砍掉实体按键，未来 iPad Pro、Apple Watch 等也将会跟进，它们都将采用类似 iPhone 7、iPhone 8 时代的固态 Home 按键设计。据悉，iPad Pro 将会集成 Taptic Engine 固态按键控制器 IC，它被用来模拟按压物理按键的震动。知名分析师郭明錤表示，苹果之所以想砍掉实体按键，最主要原因是想提高设备耐用性，物理电源和音量按键很容易出故障，砍掉按键一方面提升耐用性，另一方面增强设备防水性。
2. AMD 承认闹乌龙，官方表示尚未确认锐龙 7000 X3D 上市时间 根据 AMD 官网放出的参数页信息，AMD R9 7950X3D、R9 7900X3D、R7 7800X3D 将于 2 月 14 日上市，但有网友怀疑只是占位符，现在 AMD 官方也已经确认这一数字并非真实日期，不过官方并未给出任何进一步的细节。上周，AMD 在 CES 2023 上正式发布了采用 3D 缓存的锐龙 7000X3D 台式机处理器，最高 16 核 32 线程，L2+L3 缓存达到 144MB，共有三个型号。AMD 在 PPT 中声称，在流行的电子竞技游戏中，R7 7800X3D 的游戏性能提升可达 25%。</description></item><item><title>打工人周报（第一期）</title><link>https://www.jobcher.com/2023-01-13/</link><pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/2023-01-13/</guid><description>打工人周报：记录每周值得分享的内容,周四发布,`第一期`欢迎关注。 资讯动态 1. 苹果宣布送 iPhone 或 iPad 新用户 6 个月 iCloud+ 苹果公司宣布，近期购买并激活新 iPhone 或 iPad 的新订阅用户，可免费获取 6 个月 iCloud+服务。简而言之，就是今年 1 月之后购买激活 iPhone 或 iPad 的用户。
停用 iCloud+ 服务三个月以上的原订阅用户也可享受这一优惠”，老用户停用一段时间也可以享受优惠。
2. 苹果推出 Apple Business Connect 工具 据苹果官网消息, Apple 今日推出了 Apple Business Connect。这款免费工具让各种规模的企业都能认领相应地址的地点卡，并自主设计关键信息在 Apple 地图、信息、钱包、Siri 等各种 App 中向超过十亿 Apple 用户展示的方式。
Apple Business Connect 是一款全新的免费工具，让企业可以在地点卡中自定义显示精美图像、关键信息和特别促销活动
3. TikTok 推出限制给成人观众观看的功能 TikTok 宣布扩大其观众控制功能，使创作者能够将他们的视频限制给成人观众观看。在这次扩展之前，仅限成人的观众控制功能仅适用于 TikTok Live。现在，该公司也将该功能引入其短视频。
4. iPhone 16 Pro 或取消灵动岛 近日，据 9to5Mac 报道，有两份报告显示，苹果在明年推出的 iPhone 16 系列（或仅限 iPhone 16 Pro 机型）将配备屏下 Face ID 传感器。这意味着苹果完全可以取消灵动岛（或刘海），仅保留 1 个前摄圆形打孔。</description></item><item><title>基础知识-计算机系统</title><link>https://www.jobcher.com/base-1/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/base-1/</guid><description>计算机硬件 计算机的基本硬件系统由运算器、控制器、存储器、输入设备和输出设备五大部件组成
运算器、控制器等部件被集成在一起统称为中央处理单元（Central Processing Unit，CPU）。 存储器是计算机系统中的记忆设备，分为内部存储器和外部存储器。 内部存储器:速度高、容量小，一般用于临时存放程序、数据及中间结果 外部存储器:者容量大、速度慢，可长期保存程序和数据。 输入设备和输出设备合称为外部设备（简称外设），输入设备用于输入原始数据及各种命令，而输出设备则用于输出处理结果 CPU CPU 主要由运算器、控制器、寄存器组和内部总线等部件组成
功能 程序控制：通过执行指令来控制程序的执行顺序 操作控制：一条指令功能的实现需要若干操作信号配合完成，CPU产生每条指令的操作信号并将操作信号送往不同的部件，控制相应的部件按指令的功能要求进行操作 时间控制：CPU对各种操作进行时间上的控制，即在指令执行过程中操作信号的出现时间、持续时间及出现的时间顺序都需要严格的控制 数据处理：CPU通过对数据进行算术运算及逻辑运算等方式进行加工处理，数据加工处理的结果被人们所利用。所以，对数据的加工处理也是CPU最根本的任务。 运算器 运算器由算术逻辑单元、累加寄存器、数据缓存寄存器、状态条件寄存器组成。功能：1.执行所有算术运算2.执行所有的逻辑运算并进行逻辑测试。如与、或、非、零值测试或两个值的比较等
算术逻辑单元（ALU）：负责处理数据，实现对数据的算术运算和逻辑运算 累加寄存器（AC）：也称为累加器，是一个通用寄存器，功能是当运算器的算术逻辑单元执行算术运算或逻辑运算时，为ALU提供一个工作区 数据缓存寄存器（DR）：在对内存储器进行读/写操作时，用DR暂时存放由内存存储器读/写的一条指令或一个数据字，将不同时间段内的读/写数据隔离。主要作用是作为CPU和内存、外部设备之间数据传送中转站；作为CPU和内存、外围设备之间在操作速度上的缓冲；在单累加器结构的运算器中，数据缓冲寄存器还可兼作为操作数据寄存器。 状态条件寄存器（PSW）：由算数指令和逻辑指令运行或测试的结果建立的各种条件码内容，主要分为状态标志和控制标志 控制器 运算器只能完成运算，而控制器用于控制整个 CPU 的工作，它决定了计算机运行过程的自动化。它不仅要保证程序的正确执行，而且要能够处理异常事件。一般包括指令控制逻辑、时序控制逻辑、总线控制逻辑和中断控制逻辑等几个部分。
指令控制逻辑
指令寄存器（IR）: 当 CPU 执行一条指令时，先把它从内存储器取到缓冲寄存器中，再送入 IR 暂存，指令译码器根据 IR 的内容产生各种微操作指令，控制其他的组成部件工作，完成所需的功能。 程序计数器（PC）: 具有寄存信息和计数两种功能，又称为指令计数器。程序的执行分为两种情况，一是顺序执行，二是转移执行。 地址寄存器（AR）: 保存当前 CPU 所访问的内存单元的地址。 指令译码器（ID）: 指令分为操作码和地址码两个部分，为了执行任何给定的命令，必须对操作码进行分析，以便识别所有完成的操作。 时序控制逻辑
为每条指令按时间顺序提供应有的控制信号
总线逻辑
是为多个功能部件服务的信息通路的控制电路。
中断控制
逻辑用于控制各种中断请求，并根据优先级的高低对中断请求进行排队，逐个交给 CPU 处理。
寄存器组 寄存器组分为专用寄存器和通用寄存器。运算器和控制器中的寄存器是专用寄存器，其作用是固定的。通用寄存器的用途广泛，并且由程序员规定其用途，其数目因处理器的不同有所差异。
机器数 各种数值在计算机中表示的形式称为机器数，特点是采用二进制计数制，数的符号用 0 和 1 表示，小数点则隐含，表示不占位置。机器数对应的实际数值称为数的真值。
原码： 一个数的正常二进制表示，最高位表示符号。+0(00000000),-0(10000000) 反码：正数的反码即原码，负数的反码是在原码的基础上，除符号位外，其他各位按位取反。+0(00000000),-0(11111111) 补码：正数的补码即原码，负数的补码是在原码的基础上，除符号位外，其他各位按位取反，而后末位+1，若有进位则产生进位。+0 = -0 = 0 0000000 移码：用作浮点运算的阶码，无论正数负数，都是将该原码的补码的首位（符号位）取反得到移码 原码最高位表示正负号，且不参与计数，而其他编码最高位虽然也是代表正负号，但是参与计数</description></item><item><title>逆境和成长-2022年终总结</title><link>https://www.jobcher.com/20221230/</link><pubDate>Fri, 30 Dec 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/20221230/</guid><description> 转眼间来到了 2022 年的尾声，2022 年不仅仅对于世界来说，还是对于我个人来说都是意义非凡的一年。
逆境和成长 2022 年初在中国大陆仍然实行着最为严格的清零政策并愈演愈烈，城市居民被限制人身自由，就连农村地区也被大量要求居家隔离，严重损害了中国经济和社会活力。中国失业人口再创新高，大量的毕业生找不到工作。在美国，最为严重的通货膨胀席卷全国，高昂的加息政策，损害了底层人民和工薪阶层。在中东，塔利班武装重新占领阿富汗，重新实行政教合一的暴力统治。在俄罗斯，爆发了乌克兰战争，将俄罗斯真正从苏联的阴影中脱离出来。在世界各地发生了太多的变化，2022 年注定是要被载入史册的一年。
对于我个人来说，2022 年也是成长非常大的一年，我经历了自工作来最大的变化，我从一家工作了多年的企业毕业，再次进入了社会的试炼场中求职，接触了更多的人，碰到了更多的事，也有了更多的感悟。曾经的我会讲工作看的比一切都重要，通过勤奋和努力可以改变一切，但是，社会的规则并不是这样的。决定你的个人价值并不是这些外在的东西，决定你个人价值的是你自己对自己的看法。你认为自己有价值，你就是你能够做到有价值。你觉得自己不重要，别人自然觉得你不重要。
在 🆕 的 2023 年，希望世界和平，人人幸福，愿生活在苦难中的人们，能够早日远离苦难，让幸福来敲门……
欢迎关注我的博客[www.jobcher.com](https://www.jobcher.com/)</description></item><item><title>优雅的使用Conda管理python环境</title><link>https://www.jobcher.com/conda/</link><pubDate>Wed, 14 Dec 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/conda/</guid><description>背景 很多时候,避免不了同时使用 python2 和 python3 的环境,也避免不了不同的工作所需要不同版本的库文件,比如在想用 TensorFlow 较早版本的同时;还想运行 Pytorch 最新版；还想顺便学习 Nao 机器人编程,学习 Django 后台,这个时候,一款非常好用的包管理工具就显得十分重要了,这就是我写这篇博客的原因,这篇博客将会讲解：
如何安装 conda; 如何更换 conda 的下载源; 如何使用 canda; Linux 安装 conda 在 Ubuntu 上安装 Anaconda 的步骤如下：
首先，你需要下载 Anaconda 的安装包。你可以从 Anaconda 的官方网站上下载最新版本的 Anaconda for Linux。选择适合你的系统的版本（Python 3.x）。
访问下载链接：https://www.anaconda.com/products/distribution#download-section
下载完成后，你可以在终端中导航到下载的文件所在的目录。你可以使用 cd 命令来改变目录。例如，如果你的下载文件在 Downloads 文件夹中，你可以输入以下命令：
1cd ~/Downloads 然后，你需要运行 bash 命令来安装 Anaconda。假设你下载的 Anaconda 文件名为 &amp;ldquo;Anaconda3-2020.02-Linux-x86_64.sh&amp;rdquo;，你可以输入以下命令： 1bash Anaconda3-2020.02-Linux-x86_64.sh 请注意，你需要将上述命令中的 &amp;ldquo;Anaconda3-2020.02-Linux-x86_64.sh&amp;rdquo; 替换为你实际下载的文件名。
4. 接下来，你会看到 Anaconda 的许可协议。按 Enter 键滚动到底部，然后输入 &amp;lsquo;yes&amp;rsquo; 来接受许可协议。
5. 然后，你需要确认 Anaconda 的安装位置。你可以选择默认位置或输入新的位置。 6.</description></item><item><title>Chrome浏览器启动参数大全（命令行参数）</title><link>https://www.jobcher.com/chrome/</link><pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/chrome/</guid><description>背景 在开发 Web 项目当中，浏览器必不可少，而浏览器的启动参数可以帮我们实现很多功能。
常用参数 序号 参数 说明 1 &amp;ndash;allow- ted-plugins 不停用过期的插件。 2 &amp;ndash;allow-running-insecure-content 默认情况下，https 页面不允许从 http 链接引用 javascript/css/plug-ins。添加这一参数会放行这些内容。 3 &amp;ndash;allow-scripting-gallery 允许拓展脚本在官方应用中心生效。默认情况下，出于安全因素考虑这些脚本都会被阻止。 4 &amp;ndash;disable-desktop-notifications 禁用桌面通知，在 Windows 中桌面通知默认是启用的。 5 &amp;ndash;disable-file-system 停用 FileSystem API。 6 &amp;ndash;disable-preconnect 停用 TCP/IP 预连接。 7 &amp;ndash;disable-remote-fonts 关闭远程字体支持。SVG 中字体不受此参数影响。 8 &amp;ndash;disable-web-security 不遵守同源策略。 9 &amp;ndash;disk-cache-dir 将缓存设置在给定的路径。 10 &amp;ndash;disk-cache-size 设置缓存大小上限，以字节为单位。 11 &amp;ndash;dns-prefetch-disable 停用 DNS 预读。 12 &amp;ndash;enable-print-preview 启用打印预览。 13 &amp;ndash;extensions-update-frequency 设定拓展自动更新频率，以秒为单位。 14 &amp;ndash;incognito 让浏览器直接以隐身模式启动。 15 &amp;ndash;keep-alive-for-test 最后一个标签关闭后仍保持浏览器进程。（某种意义上可以提高热启动速度，不过你最好得有充足的内存） 16 &amp;ndash;kiosk 启用 kiosk 模式。（一种类似于全屏的浏览模式） 17 &amp;ndash;lang 使用指定的语言。 18 &amp;ndash;no-displaying-insecure-content 默认情况下，https 页面允许从 http 链接引用图片/字体/框架。添加这一参数会阻止这些内容。 19 &amp;ndash;no-referrers 不发送 Http-Referer 头。 20 &amp;ndash;no-startup-window 启动时不建立窗口。 21 &amp;ndash;proxy-server 使用给定的代理服务器，这个参数只对 http 和 https 有效。 22 &amp;ndash;start-maximized 启动时最大化。 23 &amp;ndash;single-process 以单进程模式运行 Chromium。（启动时浏览器会给出不安全警告）。 24 &amp;ndash;user-agent 使用给定的 User-Agent 字符串。 25 &amp;ndash;process-per-tab 每个分页使用单独进程。 26 &amp;ndash;process-per-site 每个站点使用单独进程。 27 &amp;ndash;in-process-plugins 插件不启用单独进程。 28 &amp;ndash;disable-popup-blocking 禁用弹出拦截。 29 &amp;ndash;disable-javascript 禁用 JavaScript。 30 &amp;ndash;disable-java 禁用 Java。 31 &amp;ndash;disable-plugins 禁用插件。 32 –disable-images 禁用图像。 更多参数 由于水平有限，下表为网络翻译，了解跟多可根基参数，查找相关资料。</description></item><item><title>Jenkins 编译Android apk 流水线</title><link>https://www.jobcher.com/gradle-apk/</link><pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/gradle-apk/</guid><description>背景 Jenkins 编译 Android apk，上传 apk 包，生成下载二维码，并推送钉钉
安装 Android 环境 安装 JDK 1# 这里使用的是openjdk 1.8.0版本，有需要的话需要到java官网上进行下载对应的JDK版本。 2$ yum install java -y 3 4# 其他版本JDK的安装方式 5$ mv jdk1.8.0_161 /usr/local/ 6$ ln -s /usr/local/jdk1.8.0_161 /usr/local/jdk 7$ vim /etc/profile #配置JDK的环境变量 8export JAVA_HOME=/usr/local/jdk 9export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH 10export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar 11$ source /etc/profile #重新加载系统环境变量 12$ java -version #查看java版本 Android SDK 安装 1# 下载sdk工具包 2$ wget https://dl.google.com/android/repository/sdk-tools-linux-3859397.zip 3 4# 创建sdk工具文件夹和解压工具包 5$ mkdir -p /opt/android/sdk 6$ unzip sdk-tools-linux-3859397.zip -d /opt/android/sdk 7 8# 使用sdkmanager工具配置构建工具和平台版本 9$ cd /opt/android/sdk/tools/bin/ 10$ .</description></item><item><title>Kubernetes — 更新证书</title><link>https://www.jobcher.com/k8s16/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s16/</guid><description>背景 使用 kubeadm 安装 kubernetes 集群非常方便，但是也有一个比较烦人的问题就是默认的证书有效期只有一年时间，所以需要考虑证书升级的问题
检查证书 由 kubeadm 生成的客户端证书默认只有一年有效期，我们可以通过 check-expiration 命令来检查证书是否过期：
1kubeadm alpha certs check-expiration 该命令显示 /etc/kubernetes/pki 文件夹中的客户端证书以及 kubeadm 使用的 KUBECONFIG 文件中嵌入的客户端证书的到期时间/剩余时间。
手动更新 kubeadm alpha certs renew
这个命令用 CA（或者 front-proxy-CA ）证书和存储在 /etc/kubernetes/pki 中的密钥执行更新。
高可用的集群，这个命令需要在所有控制面板节点上执行
具体执行 接下来我们来更新我们的集群证书，下面的操作都是在 master 节点上进行
备份节点 1$ mkdir /etc/kubernetes.bak 2$ cp -r /etc/kubernetes/pki/ /etc/kubernetes.bak 3$ cp /etc/kubernetes/*.conf /etc/kubernetes.bak 备份 etcd 数据目录 1$ cp -r /var/lib/etcd /var/lib/etcd.bak 执行更新证书的命令 1kubeadm alpha certs renew all --config=kubeadm.yaml 检查更新 1kubeadm alpha certs check-expiration 更新下 kubeconfig 文件 1kubeadm init phase kubeconfig all --config kubeadm.</description></item><item><title>Oracle Instant Client 安装配置实现远程连接oracle</title><link>https://www.jobcher.com/oracle-client/</link><pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/oracle-client/</guid><description>背景 关于 Oracle 数据库一直是许多初学者比较头疼的地方，一方面受限于线上文档比较少，令一方面在企业中不得不接触和使用 Oracle 数据库，这篇文章是教大家如何通过配置 oracle client 来远程访问 Oracle 数据库。本文会通过 python3 和 cx_Oracle 来实现对 Oracle 的访问和增删改查
下载 oracle 客户端 官方地址下载
安装 下载并安装你的 oracle client，因为我连接的 11g oracle，所以下载 11.2 版本
1# 下载 2wget https://download.oracle.com/otn/linux/instantclient/11204/oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm 3# 安装 4rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm 配置环境变量 1# 直接运行 2export ORACLE_HOME=/usr/lib/oracle/11.2/client64 3export ORABIN=/usr/lib/oracle/11.2/client64/bin 1# 编辑环境变量配置文件 2vim /etc/profile 1# 底部增加内容 2export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL 3export ORACLE_HOME=/usr/lib/oracle/11.2/client64 4export TNS_ADMIN=/usr/lib/oracle/11.2/client64 5export LD_LIBRARY_PATH=/usr/lib/oracle/11.2/client64/lib 6export ORABIN=/usr/lib/oracle/11.2/client64/bin 7PATH=$PATH:$ORABIN 8export PATH 9 10export PATH=$ORACLE_HOME:$PATH 11export PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin 1# 刷新环境变量 2source /etc/profile 下载 cx_Oracle 1pip3 install cx_Oracle 创建 Oracle.</description></item><item><title>shell功能脚本集合</title><link>https://www.jobcher.com/shell-test/</link><pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/shell-test/</guid><description>28 合 1 多功能脚本 脚本说明: 多合一脚本，DD 系统，BBR，xray,TG 搭建等等·常用的各种脚本基本都有！ 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 支持安装 BBR，搭建 KCPtun，ssr 多用户版 安装 V2ary，Tg 专用代理（Go 版），安装 Goflyway 小鸡性能测试，回程线路测试，云监控 傻瓜式一键 DD 包 一键开启默认 bbr Netflix 解锁检测 xray 安装 宝塔面板，闲蛋面板，x-ui 面板，WARP 一键配置 脚本特点: 目前网上的各个一键脚本基本都是只有 安装/启动/重启 等基础功能，对于小白来说还是不够简单方便。常用的各种脚本基本都有！
下载安装: 1bash &amp;lt;(curl -s -L https://git.io/JPj82) gfw_push 一键安装 脚本说明: 监测服务器 IP 是否被墙并推送至 Telegram 一键脚本 系统支持: CentOS6+ / Debian6+ / Ubuntu14+ 下载安装: 1bash &amp;lt;(curl -s -L git.io/JPjzm) 服务器测速 脚本说明: 服务器一键测速脚本 系统支持: CentOS7 / Debian7+ / Ubuntu14+ 下载安装: 1bash &amp;lt;(curl -s -L git.</description></item><item><title>zlibary 无法下载 解决方案</title><link>https://www.jobcher.com/zlibary/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/zlibary/</guid><description>zlibary 无法下载 因为 zlib 最近被封，导致现在通过正常方法下载不了电子书，但是不要慌，我们可以通过暗网进行下载~
安装 brave 浏览器 官网下载
下载你需要的版本，这个下载浏览器很简单，我就不多说了
配置 tor 配置 编辑 tor 配置 使用 tor 浏览 zlibary tor 暗网版</description></item><item><title>Logstash 自动重载配置文件</title><link>https://www.jobcher.com/logstash1/</link><pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/logstash1/</guid><description>工作原理 检测到配置文件变化 通过停止所有输入停止当前pipline 用新的配置创建一个新的管道 检查配置文件语法是否正确 检查所有的输入和输出是否可以初始化 检查成功使用新的 pipeline 替换当前的pipeline 检查失败,使用旧的继续工作. 在重载过程中,jvm 没有重启. Logstash 自动重新加载配置 为了可以自动检测配置文件的变动和自动重新加载配置文件,需要在启动的时候使用以下命令:
1./bin/lagstash -f configfile.conf --config.reload.automatic 启动 Logstash 的时候使用--config.reload.automatic或-r选项来开启自动重载配置。
修改检测间隔时间 默认检测配置文件的间隔时间是3秒,可以通过以下命令改变
1--config.reload.interval &amp;lt;second&amp;gt; 如果 Logstash 已经运行并且没有开启自动重载，你可以强制 Logstash 重新载入配置文件并且重启管道通过发送一个 SIGHUP 信号。比如：
1kill -1 &amp;lt;pid&amp;gt; 其中是正在运行的 Logstash 的进程号。
注意！！！ stdin输入插件不支持自动重启.
syslog作为输入源,当重载配置文件时,会崩溃.
解决方法</description></item><item><title>macOS 13 升级 软件失效</title><link>https://www.jobcher.com/macos13/</link><pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/macos13/</guid><description>关于 macOS 13 软件失效 Warning: You are using macOS 13.
We do not provide support for this pre-release version.
You will encounter build failures with some formulae.
Please create pull requests instead of asking for help on Homebrew&amp;rsquo;s GitHub, Twitter or any other official channels. You are responsible for resolving any issues you experience while you are running this pre-release version.
简单来说就是 macOS13 版本 暂时不提供技术支持
解决方法 升级完 macos13 之后发现了比较麻烦的问题，很多软件出现了不兼容，这真的很无奈，对于我们这些做 IT 的人来说，这是致命的。我以 git 软件举例，有以下几个方法。</description></item><item><title>Nexus3 使用和部署</title><link>https://www.jobcher.com/nexus/</link><pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nexus/</guid><description>Nexus3 docker-compose 安装 创建外部存储
1mkdir -p /data/nexus 2chmod +777 -R /data/nexus 运行 docker-compose
1version: &amp;#39;3&amp;#39; 2services: 3 nexus3: 4 image: sonatype/nexus3:3.42.0 5 container_name: nexus3 6 ports: 7 - 8081:8081 8 - 5000:5000 9 volumes: 10 - /data/nexus:/nexus-data 11 environment: 12 - INSTALL4J_ADD_VM_PARAMS=-Xms1024m -Xmx1024m -XX:MaxDirectMemorySize=1024m -Djava.util.prefs.userRoot=/some-other-dir 13 restart: always 14 # 赋予外部root权限 15 privileged: true docker-compose up -d 运行 docker-compose</description></item><item><title>githubAction set-output弃用错误</title><link>https://www.jobcher.com/github-error/</link><pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/github-error/</guid><description>githubAction set-output 弃用错误 The set-output command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/
原因 如果您有一个使用 设置输出的GitHub Actionsecho ::set-output key=value工作流程，您已经开始看到无用的弃用警告。这是修复它的方法。查看官方链接基本上得不到什么帮助！
修复方法 更新其它人的 action 方法 1将 @actions/core 提升到 1.10.0 修改自己的 aciton 方法 1run: echo &amp;#34;::set-output name=KEY::VALUE&amp;#34; 2## 改为 3run: echo &amp;#34;KEY=VALUE&amp;#34; &amp;gt;&amp;gt;$GITHUB_OUTPUT 建议：使用自己的方法
总结 平台经营者非常肆意妄为的修改自己的代码内容弃用功能，无限的权力滋生傲慢……我相信大部分开发这并没有注意到这个告警，知道流水线服务报错之后才会注意到，希望微软可以对能更加包容不同的开发者，尊重开发者社区。</description></item><item><title>打开web 3.0的大门——IPFS使用</title><link>https://www.jobcher.com/ipfs/</link><pubDate>Fri, 21 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ipfs/</guid><description>背景 有很多朋友问我什么是 web3.0，web3.0 似乎离我们非常远。有人会说 web3.0 是未来下一代的技术很有前景！但是举出一个具体的例子，似乎又非常困难。使用 web3.0 是一件非常高科技的事情。本文就是通过各 IPFS 给各位初学者和对 web3.0 感兴趣的人使用介绍，看完本篇文章，你就能进入 web3.0 的世界了~
IPFS 星际文件系统(InterPlanetary File System). IPFS 是一个分布式的 web, 点到点超媒体协议. 可以让我们的互联网速度更快, 更加安全, 并且更加开放. IPFS协议的目标是取代传统的互联网协议HTTP
下载安装 本文不会对技术做更深入探讨，只在应用层面上介绍
下载 官网
下载 windows
下载 MAC
安装 运行 .exe 文件开始安装，选择是要为您自己还是为计算机上的所有用户安装应用程序。点击下一步：
选择应用程序的安装位置。默认位置通常很好。点击下一步：
等待安装完成，然后单击完成：
您现在可以在状态栏中找到 IPFS 图标：
使用 打开软件 可以正常使用了！是不是很简单接下来浏览器直接查看 web3.0 站点 站点 我的 web3.0 blog： ipfs.jobcher.com
对标 youdTube 的视频网站: d.tube
Orbit，QQ 在 IPFS 上的替代者: orbit.chat
Akasha，对标 facebook，微信等社交工具：akasha.world</description></item><item><title>Kubernetes — Rook云存储介绍和部署</title><link>https://www.jobcher.com/k8s14/</link><pubDate>Tue, 11 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s14/</guid><description>Rook 云存储介绍和部署 Rook 将分布式存储软件转变为自我管理，自我缩放和自我修复的存储服务。它通过自动化部署，引导、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。 Rook 使用基础的云原生容器管理、调度和编排平台提供的功能来履行其职责。
Rook 利用扩展点深入融入云原生环境，为调度、生命周期管理、资源管理、安全性、监控和用户体验提供无缝体验。
部署 使用 helm 部署 1helm init -i jimmysong/kubernetes-helm-tiller:v2.8.1 2helm repo add rook-alpha https://charts.rook.io/alpha 3helm install rook-alpha/rook --name rook --namespace rook-system 直接使用 yaml 文件部署 1kubectl apply -f rook-operator.yaml 不论使用那种方式部署的 rook operator，都会在 rook-agent 中看到 rook-agent 用户无法列出集群中某些资源的错误，可以通过为 rook-agent 的分配 cluster-admin 权限临时解决，详见 Issue 1472。
使用如下 yaml 文件创建一个 ClusterRoleBinding 并应用到集群中。
1kind: ClusterRoleBinding 2apiVersion: rbac.authorization.k8s.io/v1beta1 3metadata: 4 name: rookagent-clusterrolebinding 5subjects: 6 - kind: ServiceAccount 7 name: rook-agent 8 namespace: rook-system 9roleRef: 10 kind: ClusterRole 11 name: cluster-admin 12 apiGroup: &amp;#34;&amp;#34; 部署 rook cluster 创建完 rook operator 后，我们再部署 rook cluster。</description></item><item><title>Kubernetes — 基于K8S搭建Ceph分布式存储</title><link>https://www.jobcher.com/k8s15/</link><pubDate>Tue, 11 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s15/</guid><description>基于 K8S 搭建 Ceph 分布式存储 前提 正常运行的多节点 K8S 集群，可以是两个节点也可以是更多。 每一个节点需要一个没有被分区的硬盘，最好大小一致不然会浪费。 没错其实就是一个要求，必须有集群才能进行容器管理，必须有硬盘才能做存储这些都是基础。 添加硬盘 主机 IP 磁盘 master01 10.12.12.51 SATA 20G master02 10.12.12.52 SATA 20G master03 10.12.12.53 SATA 20G worker01 10.12.12.54 SATA 20G worker02 10.12.12.55 SATA 20G 在 5 个节点都加 20g 存储
重启 k8s 节点 1kubectl cordon &amp;lt;节点&amp;gt; 2kubectl drain &amp;lt;节点&amp;gt; --ignore-daemonsets --delete-emptydir-data 3# 虚拟机重启后 4kubectl uncordon &amp;lt;节点&amp;gt; 查看新增存储 1fdisk -l 看到新增 20g 存储,不要格式化分区硬盘！！！
1Disk /dev/sdb: 20 GiB, 21474836480 bytes, 41943040 sectors 2Disk model: QEMU HARDDISK 3Units: sectors of 1 * 512 = 512 bytes 4Sector size (logical/physical): 512 bytes / 512 bytes 5I/O size (minimum/optimal): 512 bytes / 512 bytes ROOK 自动创建 Rook 是一个开源的cloud-native storage编排, 提供平台和框架；为各种存储解决方案提供平台、框架和支持，以便与云原生环境本地集成。 Rook 将存储软件转变为自我管理、自我扩展和自我修复的存储服务，它通过自动化部署、引导、配置、置备、扩展、升级、迁移、灾难恢复、监控和资源管理来实现此目的。 Rook 使用底层云本机容器管理、调度和编排平台提供的工具来实现它自身的功能。 Rook 目前支持Ceph、NFS、Minio Object Store和CockroachDB。 Rook 使用Kubernetes原语使Ceph存储系统能够在Kubernetes上运行。 下载 1git clone https://github.</description></item><item><title>Kubernetes — 探针和生命周期</title><link>https://www.jobcher.com/k8s13/</link><pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s13/</guid><description>Kubernetes — 探针和生命周期 用于判断容器内应用程序是否已经启动。
存活（Liveness）探针 用于探测容器是否运行，如果探测失败，kubelet 会根据配置的重启策略进行相应的处理，若没有配置探针该返回值默认为 success 就绪（Readiness）探针 用于探测容器内的程序是否健康，如果返回值为 success，那么代表这个容器已经完全启动，并且程序已经是可以接受流量的状态 启动（Startup）探针 用于探测容器是否启动，如果配置了 startup 就会先禁止其他探测，直到它成功，成功后将不在运行探测 Pod 检测方式 ExecAction：在容器执行一个命令，返回值为 0，则认为容器健康 TCPSocketAction：通过 TCP 连接检查容器是否联通，通的话，则认为容器正常 HTTPGetAction：通过应用程序暴露的 API 地址来检查程序是否正常的，如果状态码为 200-400 之间，则认为容器健康 gRPCAction：通过 gRPC 的检查机制，判断容器是不是正常 StartupProbe 启动探针 有时候，会有一些现有的应用在启动时需要较长的初始化时间。 要这种情况下，若要不影响对死锁作出快速响应的探测，设置存活探测参数是要技巧的。 技巧就是使用相同的命令来设置启动探测，针对 HTTP 或 TCP 检测，可以通过将 failureThreshold * periodSeconds 参数设置为足够长的时间来应对糟糕情况下的启动时间。
1ports: 2 - name: liveness-port 3 containerPort: 8080 4 hostPort: 8080 5 6livenessProbe: 7 httpGet: 8 path: /healthz 9 port: liveness-port 10 failureThreshold: 1 11 periodSeconds: 10 12 13startupProbe: 14 httpGet: 15 path: /healthz 16 port: liveness-port 17 failureThreshold: 30 18 periodSeconds: 10 幸亏有启动探测，应用程序将会有最多 5 分钟（30 * 10 = 300s）的时间来完成其启动过程。 一旦启动探测成功一次，存活探测任务就会接管对容器的探测，对容器死锁作出快速响应。 如果启动探测一直没有成功，容器会在 300 秒后被杀死，并且根据restartPolicy来执行进一步处置。</description></item><item><title>windows-exporter 监控</title><link>https://www.jobcher.com/windows-exporter/</link><pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/windows-exporter/</guid><description>windows-exporter 监控安装 windows_exporter 下载安装 启动 下载 msi 版本，输入一下命令启动
1msiexec /i C:\Users\Administrator\Downloads\windows_exporter.msi ENABLED_COLLECTORS=&amp;#34;ad,iis,logon,memory,process,tcp,scheduled_task&amp;#34; TEXTFILE_DIR=&amp;#34;C:\custom_metrics\&amp;#34; 卸载
1msiexec /uninstall C:\Users\Administrator\Downloads\windows_exporter.msi 添加 prometheus 监控 prometheus.yaml
1# 新增 windows-exporter 2- job_name: &amp;#34;windows-exporter&amp;#34; 3 file_sd_configs: 4 - files: 5 - &amp;#34;./file_sd/windows-exporter.yaml&amp;#34; ./file_sd/windows-exporter.yaml
1# 新增 windows-exporter 2- targets: [&amp;#34;192.168.0.6:9182&amp;#34;] 3 labels: 4 instance: windows-task 添加 alertmanager 告警 1# 告警信息 2groups: 3 - name: sanjiang windows 任务计划程序告警 4 rules: 5 - alert: windows实例任务告警 6 expr: windows_scheduled_task_state{state=&amp;#34;disabled&amp;#34;,task=~&amp;#34;/ETL_kettle_tasks/.*&amp;#34;}==1 7 for: 30s 8 labels: 9 severity: critical 10 target: &amp;#34;{{$labels.</description></item><item><title>Kubernetes — 开放标准（OCI、CRI、CNI、CSI、SMI、CPI）概述</title><link>https://www.jobcher.com/k8s12/</link><pubDate>Fri, 07 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s12/</guid><description>Kubernetes — 开放标准（OCI、CRI、CNI、CSI、SMI、CPI）概述 什么是 Kubernetes 开放标准？— K8s 开放标准简介
开放标准有助于和补充像 Kubernetes 这样的系统，Kubernetes 是用于编排容器的事实上的标准平台。开放标准定义了实施 Kubernetes 的最佳实践，并在支持此实施方面发挥着至关重要的作用。开放标准由开源 Kubernetes 社区而非某个特定供应商制定，以确保更高的效率、避免供应商锁定以及更轻松地将其他软件集成到技术堆栈中。
OCI 容器开放接口规范，由多家公司共同组成于 2015 年 6 月成立的项目（Docker, Google, CoreOS 等公司），并由 Linux 基金会运行管理，旨在围绕容器格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准 （runtime spec）和 容器镜像标准（image spec）
OCI 是一个开放的治理结构，其明确目的是围绕容器格式和运行时创建开放的行业标准。 它提供了必须由容器运行时引擎实现的规范。两个重要的规格是： runC：种子容器运行时引擎。大多数现代容器运行时环境都使用 runC 并围绕这个种子引擎开发附加功能。 这种低级运行时用于启动容器的各种工具，包括 Docker 本身。 OCI 规范：关于如何运行、构建和分发容器的映像、运行时和分发规范。 虽然 Docker 经常与容器技术同步使用，但社区一直致力于 OCI 的开放行业标准。 Image-Spec image-spec 定义了如何构建和打包容器镜像。 本规范的目标是创建可互操作的工具，用于构建、传输和准备要运行的容器映像。 Runtime-Spec runtime-spec 指定容器的配置、执行环境和生命周期。 这概述了如何运行在磁盘上解压的“文件系统包(filesystem bundle)”。概括地说，OCI 实现会下载一个 OCI 映像，然后将该映像解压缩到一个 OCI 运行时文件系统包中。 Distribution-Spec Distribution-Spec 提供了一个标准，用于一般内容的分发，特别是容器图像的分发。它是 OCI 项目的最新补充。 实现分发规范的容器注册表为容器映像提供可靠、高度可扩展、安全的存储服务。 客户要么使用云提供商实施、供应商实施，要么使用分发的开源实施。
CRI CRI（Container Runtime Interface）：容器运行时接口，提供计算资源。​ ​kubernetes1.</description></item><item><title>kubernetes 部署插件 (Flannel、Web UI、CoreDNS、Ingress Controller)</title><link>https://www.jobcher.com/k8s11/</link><pubDate>Fri, 07 Oct 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s11/</guid><description>k8s 部署插件 Kubernetes 是高度可配置且可扩展的。因此，大多数情况下， 你不需要派生自己的 Kubernetes 副本或者向项目代码提交补丁，本文会介绍几种常用的 k8s 插件，如果大家喜欢的话，希望大家点赞支持。
1. Flannel 网络插件 Flannel是由 go 语言开发，是一种基于 Overlay 网络的跨主机容器网络解决方案，也就是将TCP数据包封装在另一种网络包里面进行路由转发和通信，Flannel 是 CoreOS 开发，专门用于 docker 多主机互联的一个工具，简单来说，它的功能是让集群中的不同节点主机创建的容器都具有全局唯一的虚拟IP地址
主要功能：
为每个 node 分配 subnet，容器将自动从该子网中获取 IP 地址 当有 node 加入到网络中时，为每个 node 增加路由配置 下载并安装 1wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 2kubectl apply -f kube-flannel.yml 如果 yml 中的&amp;quot;Network&amp;quot;: 10.244.0.0/16和kubeadm init xxx --pod-network-cidr不一样，就需要修改成一样的。不然可能会使得Node间Cluster IP不通。
2. Ingress Controller Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。
Ingress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管
下面是一个将所有流量都发送到同一 Service 的简单 Ingress 示例：
Ingress 可为 Service 提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及基于名称的虚拟托管。 Ingress 控制器 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。</description></item><item><title>Cloudflare Zero Trust 内网穿透</title><link>https://www.jobcher.com/cloudflaretrust/</link><pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/cloudflaretrust/</guid><description>Cloudflare Zero Trust 内网穿透 最快的 Zero Trust 应用访问和互联网浏览平台
增加可见性，消除复杂性，降低远程和办公室用户的风险。杜绝数据丢失、恶意软件和网络钓鱼，保护用户、应用程序和设备安全。
使用 Tunnel 隧道来实现内网传统，实现内网访问各类应用
安装部署 https://dash.teams.cloudflare.com/
Docker 部署 在 docker 环境运行 &amp;lt;token&amp;gt; 是你个人令牌
1docker run -d --name cloudflared cloudflare/cloudflared:latest tunnel --no-autoupdate run --token &amp;lt;token&amp;gt; Linux 部署 X86-64 位 1curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-x86_64.rpm &amp;amp;&amp;amp; \ 2sudo yum localinstall -y cloudflared.rpm &amp;amp;&amp;amp; \ 3sudo cloudflared service install &amp;lt;token&amp;gt; X86-32 位 1curl -L --output cloudflared.rpm https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-386.rpm &amp;amp;&amp;amp; 2 3sudo yum localinstall -y cloudflared.rpm &amp;amp;&amp;amp; 4 5sudo cloudflared service install &amp;lt;token&amp;gt; arm64 1curl -L --output cloudflared.</description></item><item><title>苏州旅行</title><link>https://www.jobcher.com/suzhou/</link><pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/suzhou/</guid><description>苏州旅行 新冠肺炎 COVID-19 警告 苏州，古称吴，现简称苏，是中华人民共和国江苏省东南部的一个地级市，位于长江三角洲和太湖平原的中心地带，著名的鱼米之乡、状元之乡、院士之乡、经济重镇、历史文化名城，自古与杭州共享有“上有天堂、下有苏杭”美誉。
苏州景点 day1 金鸡湖 苏州金鸡湖，是国家5A级景区，但却是免费开放的。湖东与湖西高楼林立，展现了苏州现代的一面。夜晚，灯光璀璨，如群星般夺目；霓虹闪烁，如银河般绚烂~ 金鸡湖十景 苏州中心 东方之门 音乐喷泉 金鸡湖大桥 文化艺术中心 月光码头 诚品书店 国金中心 望湖角 李公堤 day2 苏州博物馆 地址：姑苏区东北街204号 交通：乘坐游1、游2、游5、55、178、202、309、313、518、529路等到苏州博物馆 门票：免费(可在官网提前预约) 开放时间：每星期二至星期日- 9:00~17:00（16:00停止入馆） ◆建议用时：2-3小时 拙政园 拙政园和苏州博物馆紧临，两者之间步行不会超过3分钟，而平江路是在拙政园的南门沿着门前的东北街往东走，大约在150米处右转过桥就是了，因此可以把这三处安排在同一天，建议游览顺序是拙政园—苏州博物馆—平江路。 淡季（1、2、3、6、11、12月）：70元 旺季（4、5、7、8、9、10月）：90元 day3 虎丘 地址：姑苏区山塘街虎丘山门内8号 交通：南门入口：146、游1、游2路虎丘首末站；北门入口：32、快线3号虎丘北门站 门票：淡季：60.00元 旺季：80.00元 开放时间： 7:30-17:30/17：00 建议用时：2-3小时 苏州美食 饭店 苏帮菜——浓油赤酱里的姑苏风情 鲃肺汤是取生长于太湖一带的鲃鱼，将其肉与肝加入火腿、香菇、笋片等辅料，在鸡汤中共同熬煮，汤鲜味美，是一道不可多得的汤品。 酱方是采用上乘猪五花为原料，经 24 小时腌制后，加入卤汁炖煮 3 小时而成。肉的色泽鲜亮诱人，入口外皮 Q 弹、肉质紧实。 响油鳝糊是以将新鲜鳝鱼切成段，加酱油等佐料爆炒。因鳝糊上桌时油滋滋作响，而得名“响油鳝糊”。菜色深红，口味鲜甜，油而不腻。 樱桃肉因肉形状及色泽极似樱桃而得名，是将优质的五花肉切成小块，以文火炖煮七八小时而成。肥而不腻，满口精华。 松鼠鳜鱼是将鳜鱼在油锅内炸至金黄，再淋上由番茄酱等熬制的酱汁而成。因炸开的鱼肉形似松鼠而得名，入口酥脆酸甜。 碧螺虾仁是将新鲜虾仁配以碧螺春为佐料烹制而成，色泽清淡雅致，虾肉饱满 Q 弹，鲜甜中夹杂了茶叶的香味。 推荐餐厅： 珍珠饭店：蚌肉金花菜 吴门人家：吴门人家6:30-9:00供应早茶，提供糖粥、豆腐花、苏式面、馄饨等各类苏式点心，价格为20元/人 得月楼：松鼠桂鱼、响油鳝糊、清炒虾仁、油爆虾、蟹粉豆腐、狮子头等 松鹤楼：店内供应的菜品与得月楼也是大同小异 小吃 苏式汤面——老苏州的早餐 推荐餐厅： 同得兴：枫镇大肉面 孙盛兴奥灶面馆: 奥灶鸭和爆鱼的浇头 韦复兴: 阳春面 苏式点心——吴侬软语般的甜糯滋味 推荐餐厅： 随柳居:糖粥、泡泡小馄饨 新梅华·茶点餐厅：糖芋艿 老苏州大客堂·特色小吃：响油鳝糊、生煎、锅贴 生煎——一口爆汁的苏州人气美食 推荐餐厅： 哑巴生煎：泡泡小馄饨、牛肉粉丝汤 大阿二生煎：两面黄、生煎 馄饨——别具风味的平凡美食 推荐餐厅： 绿杨馄饨:鲜肉、三鲜、鸡丝、鸡汁虾肉、荠菜、香菇馄饨 熙盛源:无锡小笼、红汤馄饨、开洋馄饨、蟹粉小笼 烧饼豆浆——寻常美食中的苏州味道 推荐餐厅： 王氏林记烧饼(双塔菜场店)：大饼油条、豆浆 阊门姚记豆浆：24 小时通宵营业，咸豆浆、荷叶包美人 糕团——苏州风俗必备美食 推荐餐厅： 黄天源：定胜糕、猪油糕、薄荷糕 明月楼(糕团店)：桂花糕、炒肉团子 长发西饼：鲜肉月饼 胥城鲜肉月饼：鲜肉月饼</description></item><item><title>懒人烧排骨</title><link>https://www.jobcher.com/paigu/</link><pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/paigu/</guid><description>【主料】 精排骨（500 克） 【辅料】 食用面碱（约 2 克） 柠檬（半个） 生姜（1 小块） 小葱（2 根） 八角（1 颗） 桂皮（1 小块） 香叶（半片） 冰糖（约 50 克） 可乐（1000 克） 【调味料】 食用盐（适量） 料酒（适量） 生抽酱油（20 克）</description></item><item><title>k8s CNI 问题 连接认证失效</title><link>https://www.jobcher.com/k8s-error2/</link><pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s-error2/</guid><description>k8s CNI 问题 连接认证失效 删除 calico 换成 flannel 后，容器没有正常启动
network: error getting ClusterInformation: connection is unauthorized: Unauthorized]
解决问题 删除掉 /etc/cni/net.d/ 目录下的 calico 配置文件即可。
要删除所有节点的配置文件
1sudo rm -rf /etc/cni/net.d/*calico* 不要重复网络插件</description></item><item><title>k8s.gcr.io国内无法连接解决方法</title><link>https://www.jobcher.com/k8s-error3/</link><pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s-error3/</guid><description>k8s.gcr.io 国内无法连接解决方法 Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
这个一看知道什么原因了，应该 GFW！那好吧，只能给 docker 加个代理了。
解决问题 添加 mirror 站点
1registry.cn-hangzhou.aliyuncs.com/google_containers</description></item><item><title>Golang 初识（安装、使用）</title><link>https://www.jobcher.com/golang/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/golang/</guid><description>Golang 初识（安装、使用） Go 导学 go 语言由 google 公司推出。
运行速度快，简单易学 适合区块链开发 拥有丰富指令 可以直接包含 C 语言 语言层面支持并发 Go 方向 网络编程 服务器编程 区块链开发 环境安装 安装环境 安装包下载
https://golang.google.cn/dl/
windows 部署 1wget https://golang.google.cn/dl/go1.19.1.windows-amd64.msi 2# 直接安装 GOPATH 设置 在环境变量 PATH 上直接配置安装地址
编写第一个程序 1package main 2 3import &amp;#34;fmt&amp;#34; 4 5func main() { 6	fmt.Println(&amp;#34;Hello World!&amp;#34;) 7}</description></item><item><title>headscale 部署使用</title><link>https://www.jobcher.com/headscale/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/headscale/</guid><description>Headscale Tailscale 的控制服务器是不开源的，而且对免费用户有诸多限制，这是人家的摇钱树，可以理解。好在目前有一款开源的实现叫 Headscale，这也是唯一的一款，希望能发展壮大。
Headscale 由欧洲航天局的 Juan Font 使用 Go 语言开发，在 BSD 许可下发布，实现了 Tailscale 控制服务器的所有主要功能，可以部署在企业内部，没有任何设备数量的限制，且所有的网络流量都由自己控制。
Headscale 部署 我决定使用docker-compose进行部署
创建存储 1#!/bin/bash 2mkdir -p /opt/headscale 3mkdir -p ./config 4touch ./config/db.sqlite 5curl https://raw.githubusercontent.com/juanfont/headscale/main/config-example.yaml -o ./config/config.yaml 运行 docker-compose 文件 创建 docker-compose.yaml
1version: &amp;#34;3&amp;#34; 2services: 3 headscale: 4 image: headscale/headscale:latest 5 volumes: 6 - ./config:/etc/headscale/ 7 - ./data:/var/lib/headscale 8 ports: 9 - 8080:8080 10 - 9090:9090 11 - 50443:50443 12 command: headscale serve 13 restart: unless-stopped 运行</description></item><item><title>清理Docker容器日志</title><link>https://www.jobcher.com/cleandocker/</link><pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/cleandocker/</guid><description>清理 Docker 容器日志 如果 docker 容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在 Linux 或者 Unix 系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null &amp;gt; *-json.log，当然你也可以通过rm -rf删除后重启 docker。
日志清理脚本 clean_docker_log.sh 1#!/bin/sh 2 3echo &amp;#34;======== start clean docker containers logs ========&amp;#34; 4 5logs=$(find /var/lib/docker/containers/ -name *-json.log) 6 7for log in $logs 8 do 9 echo &amp;#34;clean logs : $log&amp;#34; 10 cat /dev/null &amp;gt; $log 11 done 12 13echo &amp;#34;======== end clean docker containers logs ========&amp;#34; chmod +x clean_docker_log.sh &amp;amp;&amp;amp; ./clean_docker_log.sh
设置 Docker 容器日志大小 设置一个容器服务的日志大小上限</description></item><item><title>羊了个羊小程序 破解通关</title><link>https://www.jobcher.com/ylgy/</link><pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ylgy/</guid><description>注意此教程需要通过电脑端完成
操作步骤 1、微信打开羊了个羊小程序，玩第一关 2、进入当前登录的微信数据文件夹 微信左下角 -&amp;gt; 设置 -&amp;gt; 文件管理 -&amp;gt; 打开文件夹
打开后进入当前登录的微信数据文件夹
3、进入当前登录微信数据文件夹后，依次进入 \Applet\wx141bfb9b73c970a9\usr\gamecaches\resources
注意 wx141bfb9b73c970a9 文件名可能不同，但以 a9 结尾
4、修改游戏配置文件 在此文件夹下，有很多 json 文件，找到默认排序的第三个，大小 2k 的文件
我的电脑是 16632884479734.json 文件，用记事本打开，清空里面内容，将 new.txt 文件中的代码复制进此 json 文件，保存关闭
1[1,0,0,[[&amp;#34;cc.JsonAsset&amp;#34;,[&amp;#34;_name&amp;#34;,&amp;#34;json&amp;#34;],1]],[[0,0,1,3]],[[0,&amp;#34;levelConfigData&amp;#34;,{&amp;#34;dailyLevel&amp;#34;:[[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001],[80001,80001]],&amp;#34;topicLevel&amp;#34;:[[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017],[10017,10017]]}]],0,0,[],[],[]] 之后打开游戏，仅需要完成 4 次第一关九宫格样式即可加入羊群！</description></item><item><title>Featured Post without Image</title><link>https://www.jobcher.com/featured-post-without-image/</link><pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/featured-post-without-image/</guid><description>A sample for showing how carousel handle featured posts that without images.</description></item><item><title>K8S 问题排查：cgroup 内存泄露问题</title><link>https://www.jobcher.com/k8s-error/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s-error/</guid><description>K8S 问题排查：cgroup 内存泄露问题 unable to ensure pod container exists: failed to create container for [kubepods besteffort pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod5f26dae8-0421-4eab-a3f7-aa51c6848e2b: cannot allocate memory 查看 linux 内核 1cat /proc/version 2uname -a 可以发现 linux 版本是 3.0 版本
原因 cgroup 的 kmem account 特性在 Linux 3.x 内核上有内存泄露问题，然后k8s用了这个特性，导致后面创建不出新的pod来了
解决方法 1# 修改/etc/default/grub 为 2GRUB_CMDLINE_LINUX=&amp;#34;crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet cgroup.memory=nokmem&amp;#34; 3#加上了 cgroup.memory=nokmem 4# 生成配置 5/usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg 6 7# 重启机器 8reboot 验证 1cat /sys/fs/cgroup/memory/kubepods/burstable/pod*/*/memory.kmem.slabinfo 输出信息
1cat: /sys/fs/cgroup/memory/kubepods/burstable/pod0fe273ca-42e0-4223-9fe8-16d8dd1774e9/0fdd5d9c16929fd600dbdf313b5c3ebabad912dc0cb076ed6e7799e028b31481/memory.</description></item><item><title>RocketMQ k8s部署 4主4从集群</title><link>https://www.jobcher.com/rocketmq3/</link><pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/rocketmq3/</guid><description>RocketMQ k8s 部署 4 主 4 从集群 使用 NFS 配置 StatefulSet 的动态持久化存储 安装 NFS 服务端 1sudo apt update 2sudo apt install nfs-kernel-server nfs-common 安装 NFS 客户端 所有的节点都得执行
sudo apt install nfs-common -y
创建目录 1mkdir -p /data/storage/k8s/rocketmq 使用 NFS 作为StatefulSet持久化存储的操作记录，分别需要创建nfs-provisioner的rbac、storageclass、nfs-client-provisioner和statefulset的pod
创建 nfs 的 rbac 1--- 2apiVersion: v1 3kind: ServiceAccount 4metadata: 5 name: nfs-provisioner 6 namespace: sanjiang 7--- 8kind: ClusterRole 9apiVersion: rbac.authorization.k8s.io/v1 10metadata: 11 name: nfs-provisioner-runner 12 namespace: sanjiang 13rules: 14 - apiGroups: [&amp;#34;&amp;#34;] 15 resources: [&amp;#34;persistentvolumes&amp;#34;] 16 verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;create&amp;#34;, &amp;#34;delete&amp;#34;] 17 - apiGroups: [&amp;#34;&amp;#34;] 18 resources: [&amp;#34;persistentvolumeclaims&amp;#34;] 19 verbs: [&amp;#34;get&amp;#34;, &amp;#34;list&amp;#34;, &amp;#34;watch&amp;#34;, &amp;#34;update&amp;#34;] 20 - apiGroups: [&amp;#34;storage.</description></item><item><title>contained 安装及使用</title><link>https://www.jobcher.com/contained/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/contained/</guid><description>contained 安装及使用 containerd 是一个行业标准的容器运行时，强调简单性、健壮性和可移植性。它可作为 Linux 和 Windows 的守护进程使用，可以管理其主机系统的完整容器生命周期：图像传输和存储、容器执行和监督、低级存储和网络附件等。
containerd is a member of CNCF with graduated status.
早在 2016 年 3 月，Docker 1.11的Docker Engine里就包含了containerd，而现在则是把containerd从Docker Engine里彻底剥离出来，作为一个独立的开源项目独立发展，目标是提供一个更加开放、稳定的容器运行基础设施。和原先包含在 Docker Engine 里containerd相比，独立的containerd将具有更多的功能，可以涵盖整个容器运行时管理的所有需求。 containerd并不是直接面向最终用户的，而是主要用于集成到更上层的系统里，比如Swarm, Kubernetes, Mesos等容器编排系统。 containerd以Daemon的形式运行在系统上，通过暴露底层的gRPC API，上层系统可以通过这些API管理机器上的容器。 每个containerd只负责一台机器，Pull 镜像，对容器的操作（启动、停止等），网络，存储都是由 containerd 完成。具体运行容器由runC负责，实际上只要是符合OCI规范的容器都可以支持。 对于容器编排服务来说，运行时只需要使用containerd+runC，更加轻量，容易管理。 5.独立之后containerd的特性演进可以和Docker Engine分开，专注容器运行时管理，可以更稳定。 安装 centos
1yum install -y containerd.io ubuntu
1apt install -y containerd.io 设置开机自启
1systemctl enable containerd 2systemctl start containerd 3systemctl status containerd 验证
1ctr version ctr 命令 命令 作用 plugins, plugin 提供有关容器插件的信息 version 打印客户端和服务器版本 containers, c, container 管理容器 content 管理内容 events, event 显示容器事件 images, image, i 管理图像 leases 管理租约 namespaces, namespace, ns 管理租命名空间 pprof 为 containerd 提供 golang pprof 输出 run 运行一个容器 snapshots, snapshot 管理快照 tasks, t, task 管理任务 install 安装一个新包 oci OCI 工具 shim 直接与 shim 交互 help, h 显示命令列表或一个命令的帮助</description></item><item><title>Planet 下载及安装</title><link>https://www.jobcher.com/planet/</link><pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/planet/</guid><description>Planet 下载及安装 官网下载 Planet 是一款用于发布和关注 Web 内容的免费开源软件，它不需要集中式服务器或服务。它使用 IPFS 来实现点对点的内容分发。此外，您可以将您的内容链接到以太坊名称 (.eth)，以便其他人可以通过 Planet 以 .eth 名称关注您。由于 IPFS 和 ENS 都是去中心化的，因此您可以以去中心化的方式构建您的网站或关注其他网站。
如何使用 标准是 EIP-1577，这个 Content Hash 字段可以接受一些可能的值。例如，IPFS——另一种去中心化的内容分发技术。而vitalik.eth 网站已经在 IPFS 上运行。
通过 Planet 关注来自 vitalik.eth 的更新
使用 Planet 创建网站后，右键单击侧栏中的项目，然后选择Copy IPNS，然后您将在粘贴板中看到如下所示的内容：
1k51qzi5uqu5dgv8kzl1anc0m74n6t9ffdjnypdh846ct5wgpljc7rulynxa74a 公开 ENS 然后您可以像这样将该 IPNS 放入您的 ENS ContentHash 中：
确保在该字符串之前添加了 ipns://。
完成！ 然后您的网站将链接到您的 ENS。恭喜！现在你有一个在 ENS + IPFS 上运行的去中心化网站！</description></item><item><title>关系数据库 索引操作</title><link>https://www.jobcher.com/sql-index/</link><pubDate>Tue, 16 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/sql-index/</guid><description>索引 在关系数据库中，如果有上万甚至上亿条记录，在查找记录的时候，想要获得非常快的速度，就需要使用索引。
索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。
students表:
id class_id name gender score 1 1 小明 M 90 2 1 小红 F 95 3 1 小军 M 88 如果要经常根据score列进行查询，就可以对score列创建索引： 1ALTER TABLE students 2ADD INDEX idx_score (score); 使用ADD INDEX idx_score (score)就创建了一个名称为idx_score，使用列score的索引。索引名称是任意的，索引如果有多列，可以在括号里依次写上，例如： 1ALTER TABLE students 2ADD INDEX idx_name_score (name, score); 索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。反过来，如果记录的列存在大量相同的值，例如gender列，大约一半的记录值是M，另一半是F，因此，对该列创建索引就没有意义。
唯一索引 在设计关系数据表的时候，看上去唯一的列，例如身份证号、邮箱地址等，因为他们具有业务含义，因此不宜作为主键。
但是，这些列根据业务要求，又具有唯一性约束：即不能出现两条记录存储了同一个身份证号。这个时候，就可以给该列添加一个唯一索引。例如，我们假设students表的name不能重复：
1ALTER TABLE students 2ADD UNIQUE INDEX uni_name (name); 通过UNIQUE关键字我们就添加了一个唯一索引。
也可以只对某一列添加一个唯一约束而不创建唯一索引：
1ALTER TABLE students 2ADD CONSTRAINT uni_name UNIQUE (name); 这种情况下，name列没有索引，但仍然具有唯一性保证。
无论是否创建索引，对于用户和应用程序来说，使用关系数据库不会有任何区别。这里的意思是说，当我们在数据库中查询时，如果有相应的索引可用，数据库系统就会自动使用索引来提高查询效率，如果没有索引，查询也能正常执行，只是速度会变慢。因此，索引可以在使用数据库的过程中逐步优化
通过对数据库表创建索引，可以提高查询速度。 通过创建唯一索引，可以保证某一列的值具有唯一性。 数据库索引对于用户和应用程序来说都是透明的。</description></item><item><title>skywalking APM 监控</title><link>https://www.jobcher.com/skywalking/</link><pubDate>Wed, 10 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/skywalking/</guid><description>skywalking 基于 OpenTracing 规范，专门为微服务架构以及云原生服务。
APM 监控 一个基于微服务架构的电商系统
APM (Application Performance Management) 即应用性能管理，属于 IT 运维管理（ITOM)范畴.
分为一下三个方面：
Logging
服务在处理某个请求时打印的错误日志，可以将这些日志信息记录到Elasticsearch或是其他存储中。通过 Kibana 或是其他工具来分析这些日志了解服务的行为和状态，大多数情况下。日志记录的数据很分散，并且相互独立。例如错误日志，请求处理过程中关键步骤的日志等等。 Metrics
Metric是可以聚合的，例如为电商系统中每个 HTTP 接口添加一个计数器，计算每个接口的 QPS，可以通过简单的加和计算得到系统的总负载情况。 Tracing
在微服务架构系统中一请求会经过很多服务处理，调用链路会非常长，要确定中间哪个服务出现异常是非常麻烦的事情，通过分布式链路追踪，运维人员就可以构建一个请求的视图。视图上战术了一个请求从进入系统开始到返回响应的整个流程。 系统交互图
系统加载图 &amp;gt; 目前流行的APM监控 Zipkin 对 web.xml 进行修改，代码侵入 twitter 开源 Cat 支持 Java、C/C++、Node.Js、Python、go 代码侵入，埋点 美团开源 Pinpoint 基于字节码注入技术，代码无侵入 韩国公司开发，社区交流滞后 只支持 hbase 颗粒度更细 Skywalking
观测性分析平台 基于字节码注入技术，代码无侵入 服务、服务实例、端点指标分析 服务拓扑图分析 服务、服务实例和端点（Endpont）SLA 分析 支持 es，h2,mysql,TiDb,sharding-sphere skywalking 整体框架 上部分 Agent ：负责从应用中，收集链路信息，发送给 SkyWalking OAP 服务器。目前支持 SkyWalking、Zikpin、Jaeger 等提供的 Tracing 数据信息。而我们目前采用的是，SkyWalking Agent 收集 SkyWalking Tracing 数据，传递给服务器。 下部分 SkyWalking OAP ：负责接收 Agent 发送的 Tracing 数据信息，然后进行分析(Analysis Core) ，存储到外部存储器( Storage )，最终提供查询( Query )功能。 右部分 Storage ：Tracing 数据存储。目前支持 ES、MySQL、Sharding Sphere、TiDB、H2 多种存储器。而我们目前采用的是 ES ，主要考虑是 SkyWalking 开发团队自己的生产环境采用 ES 为主。 左部分 SkyWalking UI ：负责提供控台，查看链路等等。 skywalking 配置 使用 docker-compose 安装 使用 mysql 作为存储</description></item><item><title>systemd 守护命令</title><link>https://www.jobcher.com/systemd/</link><pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/systemd/</guid><description>介绍 systemd 是 linux 中用来启动守护进程，Linux 最早一直采用 init 进程
(systemd 架构图)
systemd 命令 systemd 不是一个具体的命令，而是一组命令，用于系统管理的各个方面
1.systemctl systemctl是 Systemd 的主命令，用于管理系统。
1# 重启系统 2$ sudo systemctl reboot 3 4# 关闭系统，切断电源 5$ sudo systemctl poweroff 6 7# CPU停止工作 8$ sudo systemctl halt 9 10# 暂停系统 11$ sudo systemctl suspend 12 13# 让系统进入冬眠状态 14$ sudo systemctl hibernate 15 16# 让系统进入交互式休眠状态 17$ sudo systemctl hybrid-sleep 18 19# 启动进入救援状态（单用户状态） 20$ sudo systemctl rescue 2.systemd-analyze systemd-analyze命令用于查看启动耗时
1# 查看启动耗时 2systemd-analyze 3 4# 查看每个服务的启动耗时 5$ systemd-analyze blame 6 7# 显示瀑布状的启动过程流 8$ systemd-analyze critical-chain 9 10# 显示指定服务的启动流 11$ systemd-analyze critical-chain atd.</description></item><item><title>docker 问题处理</title><link>https://www.jobcher.com/docker-error/</link><pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-error/</guid><description>docker 无法启动 打开服务器输入docker ps,输出错误
Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
怀疑是不是docker.services 部署没成功，systemctl start docker 启动 docker，结果服务器还是报错
Job for docker.service failed because the control process exited with error code.
See &amp;ldquo;systemctl status docker.service&amp;rdquo; and &amp;ldquo;journalctl -xe&amp;rdquo; for details.
systemctl status docker.service 输出日志：
1● docker.service - Docker Application Container Engine 2 Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) 3 Active: failed (Result: exit-code) since Thu 2022-08-04 11:43:05 CST; 2min 57s ago 4TriggeredBy: ● docker.</description></item><item><title>kubernetes 存储</title><link>https://www.jobcher.com/k8s10/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s10/</guid><description>kubernetes 存储 k8s 支持多种途径的多种类型的存储。例如 iSCSI,SMB,NFS，以及对象存储。都是不同类型的部署在云上或者自建数据中心的外部存储系统。k8s 上的所有存储都被称作卷
CSI 容器存储接口 CSI 是 k8s 存储体系中一部分，是一个开源项目，定义了一套基于标准的接口，从而使容器能够以一种统一的方式被不同的容器编排的工具使用。可以将插件称为provisioner
持久化 持久化卷 （pv） 持久化卷申请 （pvc） 存储类 （sv） PV 代表 k8s 的存储，pvc 代表的是许可证，赋予 pod 访问 pv 的权限。cs 使分配过程是动态的。
使用 iSCSI 操作存储 iscsi 卷能将 iSCSI (基于 IP 的 SCSI) 卷挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，iscsi 卷的内容在删除 Pod 时会被保留，卷只是被卸载。 这意味着 iscsi 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。
iSCSI 的一个特点是它可以同时被多个用户以只读方式挂载。 这意味着你可以用数据集预先填充卷，然后根据需要在尽可能多的 Pod 上使用它。 不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载。不允许同时写入。
创建 iscsi-pv.yaml iscsi-pvc.yaml iscsi-pv.yaml
1apiVersion: v1 2kind: PersistentVolume 3metadata: 4 name: iscsi-pv 5spec: 6 capacity: 7 storage: 500Gi 8 accessModes: 9 - ReadWriteOnce 10 iscsi: 11 targetPortal: 10.</description></item><item><title>linux服务器 删除空间却未释放</title><link>https://www.jobcher.com/linux-disk/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/linux-disk/</guid><description>linux 服务器 删除空间却未释放 在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink)，然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用，这样就会导致我们明明删除了文件，但是磁盘空间却未被释放
获取占用列表状态 1lsof | grep deleted 可以看到哪些文件还被使用，未被释放空间。
释放磁盘空间 一种方法是 kill 掉相应的进程，或者停掉使用这个文件的应用，让 os 自动回收磁盘空间，当 linux 打开一个文件的时候,Linux 内核会为每一个进程在/proc/, /proc/nnnn/fd/目录（nnnn 为 pid）建立一个以其 pid 为名的目录用来保存进程的相关信息，而其子目录 fd 保存的是该进程打开的所有文件的 fd（fd：file descriptor）；
kill进程是通过截断 proc 文件系统中的文件可以强制要求系统回收分配给正在使用的的文件，这是一项高级技术，仅当管理员确定不会对运行中的进程造成影响时使用。 1kill -9 12345 # PID 重启服务 lsof 命令 lsof全名list opened files，也就是列举系统中已经被打开的文件。我们都知道，linux 环境中，任何事物都是文件，设备是文件，目录是文件，甚至sockets也是文件。</description></item><item><title>logstash 多管道部署</title><link>https://www.jobcher.com/logstash/</link><pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/logstash/</guid><description>logstash 多管道部署 找到 logstash 目录位置，一般来说在 /etc/logstash 路径下,修改 logstash.yml
1#增加 日志记录 2path.logs: /var/log/logstash 增加管道 增加 conf.d目录下 test.conf
input { beats { host =&amp;gt; &amp;#34;0.0.0.0&amp;#34; port =&amp;gt; 23000 # 修改端口IP } } filter { mutate{ add_field =&amp;gt; { &amp;#34;cluster&amp;#34; =&amp;gt; &amp;#34;test&amp;#34; # 修改标签 &amp;#34;job&amp;#34; =&amp;gt; &amp;#34;logstash&amp;#34; } } } output { file { path =&amp;gt; &amp;#34;/data/路径名称&amp;#34; # 路径名称 gzip =&amp;gt; false #匹配以空格开头的行 } } 修改 pipelines.yml
1- pipeline.id: 名称 2 path.config: &amp;#34;/etc/logstash/conf.d/配置文件.conf&amp;#34; 3 queue.</description></item><item><title>kubernetes 从1.23.x 升级到 1.24.x</title><link>https://www.jobcher.com/k8s9/</link><pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s9/</guid><description>kubernetes 从1.23.x 升级到 1.24.x k8s 在1.24.x之后的版本放弃了和 docker 的兼容，使用 containerd 作为底层的容器，直接参照官方文档的资料进行更新就会报错。因为你没有安装 containerd，所以要安装 containerd 并配置才能正确的升级 k8s
我用的是CentOS7.9的版本，因此以下操作都是在CentOS下操作。
Master 节点操作 1.升级 kubeadm 1yum install -y kubeadm-1.24.2-0 --disableexcludes=kubernetes 2kubeadm version 3kubeadm upgrade plan 4sudo kubeadm upgrade apply v1.24.2 2.安装 containerd 1yum install containerd.io -y 2containerd config default &amp;gt; /etc/containerd/config.toml 3vim /var/lib/kubelet/kubeadm-flags.env 修改 kubeadm-flags.env 变量：
1KUBELET_KUBEADM_ARGS=&amp;#34;--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock&amp;#34; 3.升级 kubelet 1yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes=kubernetes 2systemctl daemon-reload &amp;amp;&amp;amp; systemctl restart containerd &amp;amp;&amp;amp; systemctl restart kubelet 查看状态：</description></item><item><title>编写 kubernetes 资源描述文件</title><link>https://www.jobcher.com/k8s8/</link><pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s8/</guid><description>编写 kubernetes 资源描述文件 1. 部署一个应用 1apiVersion: apps/v1 #与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本 2kind: Deployment #该配置的类型，我们使用的是 Deployment 3metadata: #译名为元数据，即 Deployment 的一些基本属性和信息 4 name: nginx-deployment #Deployment 的名称 5 labels: #标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解 6 app: nginx #为该Deployment设置key为app，value为nginx的标签 7spec: #这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用 8 replicas: 1 #使用该Deployment创建一个应用程序实例 9 selector: #标签选择器，与上面的标签共同作用，目前不需要理解 10 matchLabels: #选择包含标签app:nginx的资源 11 app: nginx 12 template: #这是选择或创建的Pod的模板 13 metadata: #Pod的元数据 14 labels: #Pod的标签，上面的selector即选择包含标签app:nginx的Pod 15 app: nginx 16 spec: #期望Pod实现的功能（即在pod中部署） 17 containers: #生成container，与docker中的container是同一种 18 - name: nginx #container的名称 19 image: nginx:1.</description></item><item><title>nginx ssh-key connection exception</title><link>https://www.jobcher.com/nginx05/</link><pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx05/</guid><description>nginx ssh-key connection exception Not long ago, I wanted to restart the company&amp;rsquo;s gitlab server.I couldn&amp;rsquo;t coonect to ssh when it restarted.emm……I try copy the ssh rsa.pub,but it didn&amp;rsquo;t work.
error log:
identity_sign: private key ~/.ssh/id_rsa contents do not match public what is happen？
solution reconfigure gitlab ssh key!
create new ssh key 1ssh-keygen -t rsa -C &amp;#39;git@gitlab.com&amp;#39; -f ~/.ssh/gitlab-rsa update config file,enter ~./ssh,open config 1# add host 2Host gitlab.com 3 HostName gitlab.</description></item><item><title>kubernetes manual expansion</title><link>https://www.jobcher.com/k8s7/</link><pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s7/</guid><description>k8s manual expansion We find k8s-master node.Input the Command：
expand 1kubectl scale --replicas=3 deploy my-test-deploy shrink 1kubectl scale --replicas=1 deploy my-test-deploy trouble cleaning get resource list 1kubectl get deployment 2kubectl get pods 3kubectl get nodes 4# exists in the namespace 5kubectl api-resources --namespaced=true 6# not exists in the namespace 7kubectl api-resources --namespaced=false show info 1kubectl describe pod my-test-pod 2kubectl describe deployment my-test-pod exec container 1kubectl exec -ti my-test-pod /bin/bash</description></item><item><title>nginx exporter 安装配置</title><link>https://www.jobcher.com/nginx-exporter/</link><pubDate>Wed, 08 Jun 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx-exporter/</guid><description>nginx exporter 安装配置 二进制安装 1wget https://github.com/nginxinc/nginx-prometheus-exporter/releases/download/v0.10.0/nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz 2tar -zxvf nginx-prometheus-exporter_0.10.0_linux_amd64.tar.gz -C ./nginx-exporter 在 nginx 上配置 1./configure \ 2… \ 3--with-http_stub_status_module 4make 5sudo make install 在 nginx.config 上配置
server { # 新增 location /nginx_status { stub_status on; access_log off; } } 重启 nginx 服务
1nginx -t 2nginx -s reload 启动 nginx exporter 1nginx-prometheus-exporter -nginx.scrape-uri http://&amp;lt;nginx&amp;gt;:8080/nginx_status 配置 prometheus 添加 prometheus.yml 1- job_name: &amp;#34;nginx-exporter&amp;#34; 2 file_sd_configs: 3 - files: 4 - &amp;#34;./file_sd/nginx-exporter.yaml&amp;#34; 在 ./file_sd/新建 nginx-exporter.</description></item><item><title>go Struct 结构体</title><link>https://www.jobcher.com/go3/</link><pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/go3/</guid><description>go Struct 结构体 结构体是将零个或多个任意类型的变量，组合在一起的聚合数据类型，也可以看做是数据的集合。
声明结构体 1//demo_11.go 2package main 3 4import ( 5	&amp;#34;fmt&amp;#34; 6) 7 8type Person struct { 9	Name string 10	Age int 11} 12 13func main() { 14	var p1 Person 15	p1.Name = &amp;#34;Tom&amp;#34; 16	p1.Age = 30 17	fmt.Println(&amp;#34;p1 =&amp;#34;, p1) 18 19	var p2 = Person{Name:&amp;#34;Burke&amp;#34;, Age:31} 20	fmt.Println(&amp;#34;p2 =&amp;#34;, p2) 21 22	p3 := Person{Name:&amp;#34;Aaron&amp;#34;, Age:32} 23	fmt.Println(&amp;#34;p2 =&amp;#34;, p3) 24 25	//匿名结构体 26	p4 := struct { 27	Name string 28	Age int 29	} {Name:&amp;#34;匿名&amp;#34;, Age:33} 30	fmt.</description></item><item><title>go Slice切片语法</title><link>https://www.jobcher.com/go2/</link><pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/go2/</guid><description>go Slice 切片语法 切片是一种动态数组，比数组操作灵活，长度不是固定的，可以进行追加和删除。
len() 和 cap() 返回结果可相同和不同。
声明切片 1//demo_7.go 2package main 3 4import ( 5	&amp;#34;fmt&amp;#34; 6) 7 8func main() { 9	var sli_1 [] int //nil 切片 10	fmt.Printf(&amp;#34;len=%d cap=%d slice=%v\n&amp;#34;,len(sli_1),cap(sli_1),sli_1) 11 12	var sli_2 = [] int {} //空切片 13	fmt.Printf(&amp;#34;len=%d cap=%d slice=%v\n&amp;#34;,len(sli_1),cap(sli_2),sli_2) 14 15	var sli_3 = [] int {1, 2, 3, 4, 5} 16	fmt.Printf(&amp;#34;len=%d cap=%d slice=%v\n&amp;#34;,len(sli_3),cap(sli_3),sli_3) 17 18	sli_4 := [] int {1, 2, 3, 4, 5} 19	fmt.</description></item><item><title>go 基础知识</title><link>https://www.jobcher.com/go1/</link><pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/go1/</guid><description>go 基础知识 目录结构 1├─ code -- 代码根目录 2│ ├─ bin 3│ ├─ pkg 4│ ├─ src 5│ ├── hello 6│ ├── hello.go bin 存放编译后可执行的文件。 pkg 存放编译后的应用包。 src 存放应用源代码。 Hello World 代码
1//在 hello 目录下创建 hello.go 2package main 3 4import ( 5	&amp;#34;fmt&amp;#34; 6) 7 8func main() { 9	fmt.Println(&amp;#34;Hello World!&amp;#34;) 10} 基础命令 1go build hello 2#在src目录或hello目录下执行 go build hello，只在对应当前目录下生成文件。 3go install hello 4#在src目录或hello目录下执行 go install hello，会把编译好的结果移动到 $GOPATH/bin。 5go run hello 6#在src目录或hello目录下执行 go run hello，不生成任何文件只运行程序。 7go fmt hello 8#在src目录或hello目录下执行 go run hello，格式化代码，将代码修改成标准格式。 数据类型 类型 表示 备注 字符串 string 只能用一对双引号（&amp;quot;&amp;quot;）或反引号（``）括起来定义，不能用单引号（&amp;rsquo;&amp;rsquo;）定义！ 布尔 bool 只有 true 和 false，默认为 false。 整型 int8 uint8 int16 uint16 int32 uint32 int64 uint64 int uint 具体长度取决于 CPU 位数。 浮点型 float32 float64 常量声明 常量，在程序编译阶段就确定下来的值，而程序在运行时无法改变该值。</description></item><item><title>VSCode插件推荐=> Code Runner</title><link>https://www.jobcher.com/vscode-runcode/</link><pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/vscode-runcode/</guid><description>VSCode 插件推荐=&amp;gt; Code Runner Run code snippet or code file for multiple languages: C, C++, Java, JavaScript, PHP, Python, Perl, Perl 6, Ruby, Go, Lua, Groovy, PowerShell, BAT/CMD, BASH/SH, F# Script, F# (.NET Core), C# Script, C# (.NET Core), VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml Script, R, AppleScript, Elixir, Visual Basic .NET, Clojure, Haxe, Objective-C, Rust, Racket, Scheme, AutoHotkey, AutoIt, Kotlin, Dart, Free Pascal, Haskell, Nim, D, Lisp, Kit, V, SCSS, Sass, CUDA, Less, Fortran, Ring, and custom command</description></item><item><title>ant build.xml 编写</title><link>https://www.jobcher.com/ant1/</link><pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ant1/</guid><description>ant build.xml 编写 生成 build.xml Eclipse 自动生成 Ant 的Build.xml 配置文件,生成的方法很隐蔽
选择你要生成Build.xml文件的项目,右键. Export-&amp;gt; General -&amp;gt; Ant Buildfiles .
点 Next,选择项目，再点Finish.
编写 build.xml 1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34; standalone=&amp;#34;no&amp;#34;?&amp;gt; 2 3&amp;lt;!-- 每个构建文件对应一个项目。&amp;lt;project&amp;gt;标签时构建文件的根标签。它可以有多个内在属性，就如代码中所示，其各个属性的含义分别如下。 4(1) default表示默认的运行目标，这个属性是必须的。 5(2) basedir表示项目的基准目录。 6(3) name表示项目名。 7(4) description表示项目的描述。 8 --&amp;gt; 9&amp;lt;project default=&amp;#34;build&amp;#34; name=&amp;#34;Sort&amp;#34;&amp;gt; 10	&amp;lt;!-- 设置属性或文件路径，读取属性使用${property}，value路径默认项目根目录 --&amp;gt; 11	&amp;lt;property file=&amp;#34;ant/builds.properties&amp;#34; /&amp;gt; 12 13	&amp;lt;property name=&amp;#34;src.dir&amp;#34; value=&amp;#34;src/statics&amp;#34; /&amp;gt; 14 15	&amp;lt;property name=&amp;#34;classes.dir&amp;#34; value=&amp;#34;ant/classes&amp;#34; /&amp;gt; 16 17	&amp;lt;property name=&amp;#34;lib.dir&amp;#34; value=&amp;#34;lib&amp;#34; /&amp;gt; 18 19	&amp;lt;property name=&amp;#34;dist.</description></item><item><title>kubernetes 调度过程</title><link>https://www.jobcher.com/k8s6/</link><pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s6/</guid><description>k8s 调度过程 执行滚动升级 修改 deployment.yml 文件，追加 rollingUpdate
1# 部署应用 2apiVersion: apps/v1 3kind: Deployment 4metadata: 5 name: jobcher-blog-deployment 6 labels: 7 app: jobcher-blog 8spec: 9 replicas: 3 10 selector: 11 matchLabels: 12 app: jobcher-blog 13 minReadySeconds: 10 #准备10s 14 strategy: 15 type: RollingUpdate 16 rollingUpdate: 17 maxUnavailable: 1 #更新期间不少于3-1 18 maxSurge: 1 #更新期间不超过3+1 19 template: 20 metadata: 21 labels: 22 app: jobcher-blog 23 spec: 24 containers: 25 - name: jobcher-blog-pod 26 image: hub.</description></item><item><title>Golang go build 编译不同版本</title><link>https://www.jobcher.com/go/</link><pubDate>Sun, 17 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/go/</guid><description>Golang go build 编译不同系统下的可执行文件 Mac 系统编译 1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build test.go 2CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go Linux 系统编译 1CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build test.go 2CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build test.go windows 系统编译 1SET CGO_ENABLED=0 SET GOOS=darwin3 SET GOARCH=amd64 go build test.go 2SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build test.go GOOS：目标可执行程序运行操作系统，支持 darwin，freebsd，linux，windows GOARCH：目标可执行程序操作系统构架，包括 386，amd64，arm</description></item><item><title>记录一次上门打散工</title><link>https://www.jobcher.com/20220416/</link><pubDate>Sun, 17 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/20220416/</guid><description>记录一次上门打散工 壬寅年头磨难多
人间规则奈吾何
吟诗为把瘟神送
风起大江扬洪波
疫情减弱，遍邀亲友，无人相约，但闻昔日挚友，感怀往事邀吾往之。欲把殷勤牵挂诉，幸之。遂至友舍，诉之：帮忙装个监控吧～
买物料 和朋友两个人出发，帮朋友邻居家装个监控，他这个监控是要求装在车库里，但是网线要从 4 楼下放下去。所以，我们首先要出门购买一下物料：
带 RJ45 接口监控 足够长的网线 走了 10000 多步人都走傻了～
布线 这个没啥好说的，纯粹体力活，感谢朋友的暴风之锤，提高了工作效率，加快了项目进度 感谢 感谢朋友，给我这次项目实践和锻炼的机会让我认识到了自己的能力的不足～
欢迎关注我的博客www.jobcher.com</description></item><item><title>ansible 命令</title><link>https://www.jobcher.com/ansible1/</link><pubDate>Thu, 14 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ansible1/</guid><description>ansible 命令 Inventory：Ansible 管理的主机信息，包括 IP 地址、SSH 端口、账号、密码等 Modules：任务均有模块完成，也可以自定义模块，例如经常用的脚本。 Plugins：使用插件增加 Ansible 核心功能，自身提供了很多插件，也可以自定义插件。例如 connection 插件，用于连接目标主机。 Playbooks：“剧本”，模块化定义一系列任务，供外部统一调用。Ansible 核心功能。 编辑主机清单 1[webservers] 2192.168.0.20 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 3192.168.0.21 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 4192.168.0.22 ansible_ssh_user=root ansible_ssh_pass=’200271200’ 5 6[dbservers] 710.12.0.100 810.12.0.101 1sed -i &amp;#34;s/#host_key_checking = .*/host_key_checking = False/g&amp;#34; /etc/ansible/ansible.cfg 命令行 1ansible all -m ping 2ansible all -m shell -a &amp;#34;ls /root&amp;#34; -u root -k 常用模块 在目标主机执行 shell 命令。
shell 1- name: 将命令结果输出到指定文件 2 shell: somescript.sh &amp;gt;&amp;gt; somelog.txt 3- name: 切换目录执行命令 4 shell: 5 cmd: ls -l | grep log 6 chdir: somedir/ 7- name: 编写脚本 8 shell: | 9 if [ 0 -eq 0 ]; then 10 echo yes &amp;gt; /tmp/result 11 else 12 echo no &amp;gt; /tmp/result 13 fi 14 args: 15 executable: /bin/bash copy 将文件复制到远程主机。 1- name: 拷贝文件 2 copy: 3 src: /srv/myfiles/foo.</description></item><item><title>Ant中如何添加第三方jar包依赖</title><link>https://www.jobcher.com/ant/</link><pubDate>Thu, 14 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ant/</guid><description>Ant 中如何添加第三方 jar 包依赖 如果使用 ant 进行 java 项目的编译部署，那怎么添加第三方 jar 包的依赖呢？方法如下：
在项目的根目录下创建 lib 目录，并把所有需要的第三方 jar 包放到此目录下。 在 build.xml 中依次添加：path、property，并在 javac 中添加 classpath，添加 unjar。完整配置如下： 1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 2&amp;lt;project name=&amp;#34;MyTool&amp;#34; default=&amp;#34;build&amp;#34; basedir=&amp;#34;.&amp;#34;&amp;gt; 3 &amp;lt;description&amp;gt;The ant project to build MyTool.&amp;lt;/description&amp;gt; 4 &amp;lt;property name=&amp;#34;srcDir&amp;#34; location=&amp;#34;src&amp;#34; description=&amp;#34;源文件的存放目录&amp;#34; /&amp;gt; 5 &amp;lt;property name=&amp;#34;libDir&amp;#34; location=&amp;#34;lib&amp;#34; description=&amp;#34;第三方jar包的存放目录&amp;#34; /&amp;gt; 6 &amp;lt;property name=&amp;#34;antDir&amp;#34; location=&amp;#34;ant&amp;#34; description=&amp;#34;编译后所有文件存放的根目录&amp;#34; /&amp;gt; 7 &amp;lt;property name=&amp;#34;binDir&amp;#34; location=&amp;#34;${antDir}/bin&amp;#34; description=&amp;#34;编译后class文件的存放目录&amp;#34; /&amp;gt; 8 &amp;lt;property name=&amp;#34;jarDir&amp;#34; location=&amp;#34;${antDir}/jar&amp;#34; description=&amp;#34;打包后jar包的存放目录&amp;#34; /&amp;gt; 9 &amp;lt;property name=&amp;#34;jarFile&amp;#34; location=&amp;#34;${jarDir}/MyTool.</description></item><item><title>k8s本地联调神器kt-connect</title><link>https://www.jobcher.com/kt-connect/</link><pubDate>Thu, 14 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/kt-connect/</guid><description>k8s 本地联调神器 kt-connect 转载自 Bboysoul&amp;rsquo;sBlog
k8s 集群内部的服务网络怎么和我们本地网络打通。kt-connect 就是用来解决这个问题的
使用方法 下载安装什么的都很简单，一个二进制而已
1https://github.com/alibaba/kt-connect 如果你安装好了，那么直接使用下面的命令使用就好了
1sudo ktctl connect 当然也可以指定配置文件
1sudo ktctl --kubeconfig ~/.kube/local connect 执行完成之后，这个集群的所有svc都可以直接在本地解析，当然直接 ping pod 的 ip 也是可以的</description></item><item><title>OpenELB：让k8s私有环境对外暴露端口</title><link>https://www.jobcher.com/openelb/</link><pubDate>Wed, 13 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/openelb/</guid><description>OpenELB：云原生负载均衡器插件 OpenELB 是一个开源的云原生负载均衡器实现，可以在基于裸金属服务器、边缘以及虚拟化的 Kubernetes 环境中使用 LoadBalancer 类型的 Service 对外暴露服务。
在 Kubernetes 中安装 OpenELB 1kubectl apply -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml 查看状态 1kubectl get po -n openelb-system 使用 kubectl 删除 OpenELB 1kubectl delete -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml 1kubectl get ns 配置 OpenELB 1kubectl edit configmap kube-proxy -n kube-system 2 3# 修改 网卡 4ipvs: 5 strictARP: true 重启组件 1kubectl rollout restart daemonset kube-proxy -n kube-system 为 master1 节点添加一个 annotation 来指定网卡： 1kubectl annotate nodes master1 layer2.openelb.kubesphere.io/v1alpha1=&amp;#34;192.168.0.2&amp;#34; 创建地址池 layer2-eip.yaml 1apiVersion: network.</description></item><item><title>kubernetes ansible自动化部署</title><link>https://www.jobcher.com/k8s5/</link><pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s5/</guid><description>kubernetes ansible 自动化部署 服务器规划 角色 IP 组件 k8s-master1 10.12.12.15 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-master2 10.12.12.17 kube-apiserver kube-controller-manager kube-scheduler etcd k8s-02 10.12.12.22 kubelet kube-proxy docker etcd k8s-03 10.12.12.21 kubelet kube-proxy docker etcd load Balancer(master) 10.12.12.15 10.12.12.23(VIP) nginx keepalived load Balancer(backup) 10.12.12.17 nginx keepalived 系统初始化 关闭 selinux，firewalld 关闭 swap 时间同步 写 hosts ssh 免密（可选） etcd 集群部署 生成 etcd 证书 部署三个 ETC 集群 查看集群状态 部署 Masterß 生成 apiserver 证书 部署 apiserver、controller-manager 和 scheduler 组件 启动 TLS Bootstrapping 部署 Node 安装 Docker 部署 Kubelet 和 kube-proxy 在 Master 上运行为新 Node 颁发证书 授权 apiserver 访问 kubelet 部署插件（准备好镜像） Flannel Web UI CoreDNS Ingress Controller Master 高可用 增加 Master 节点（与 Master1 一致） 部署 nginx 负载均衡器 Nginx+Keepalived 高可用 修改 Node 连接 VIP</description></item><item><title>Git 规则</title><link>https://www.jobcher.com/git3/</link><pubDate>Thu, 24 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/git3/</guid><description>Git 飞行规则(Flight Rules) 编辑提交(editting commits) 我刚才提交了什么? 我的提交信息(commit message)写错了 我提交(commit)里的用户名和邮箱不对 我想从一个提交(commit)里移除一个文件 我想删除我的的最后一次提交(commit) 删除任意提交(commit) 我尝试推一个修正后的提交(amended commit)到远程，但是报错： 我意外的做了一次硬重置(hard reset)，我想找回我的内容 暂存(Staging) 我需要把暂存的内容添加到上一次的提交(commit) 我想要暂存一个新文件的一部分，而不是这个文件的全部 我想把在一个文件里的变化(changes)加到两个提交(commit)里 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来 未暂存(Unstaged)的内容 我想把未暂存的内容移动到一个新分支 我想把未暂存的内容移动到另一个已存在的分支 我想丢弃本地未提交的变化(uncommitted changes) 我想丢弃某些未暂存的内容 分支(Branches) 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 我需要提交到一个新分支，但错误的提交到了 main 我想保留来自另外一个 ref-ish 的整个文件 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 我想删除上游(upstream)分支被删除了的本地分支 我不小心删除了我的分支 我想删除一个分支 我想从别人正在工作的远程分支签出(checkout)一个分支 Rebasing 和合并(Merging) 我想撤销 rebase/merge 我已经 rebase 过, 但是我不想强推(force push) 我需要组合(combine)几个提交(commit) 安全合并(merging)策略 我需要将一个分支合并成一个提交(commit) 我只想组合(combine)未推的提交(unpushed commit) 检查是否分支上的所有提交(commit)都合并(merge)过了 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现&amp;rsquo;noop&amp;rsquo; 有冲突的情况 Stash 暂存所有改动 暂存指定文件 暂存时记录消息 使用某个指定暂存 暂存时保留未暂存的内容 杂项(Miscellaneous Objects) 克隆所有子模块 删除标签(tag) 恢复已删除标签(tag) 已删除补丁(patch) 跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 我想从 Git 删除一个文件，但保留该文件 配置(Configuration) 我想给一些 Git 命令添加别名(alias) 我想缓存一个仓库(repository)的用户名和密码 我不知道我做错了些什么 其它资源(Other Resources) 书(Books) 教程(Tutorials) 脚本和工具(Scripts and Tools) GUI 客户端(GUI Clients) 编辑提交(editting commits) 我刚才提交了什么?</description></item><item><title>shell 脚本（1）</title><link>https://www.jobcher.com/shell1/</link><pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/shell1/</guid><description>shell 脚本之变量 变量替换 语法 说明 ${变量名#匹配规则} 从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则} 从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则} 从变量尾部进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则} 从变量尾部进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串} 变量内容符合旧字符串则，则第一个旧字符串会被新字符串取代 ${变量名//旧字符串/新字符串} 变量内容符合旧字符串则，则全部的旧字符串会被新字符串取代 字符串处理 计算字符串长度 - 语法 说明 方法一 ${#string} 无 方法二 expr length &amp;ldquo;$string&amp;rdquo; string 有空格，则必须加双引号 获取子串在字符串中的索引位置
语法： expr index $string $substring
计算子串长度
语法： expr match $string substr
抽取子串
${string:position} ：从 string 中的 position 开始 ${string:position:length}：从 position 开始，匹配长度为 length ${string:-position}：从右边开始匹配 ${string:(position)}：从左边开始匹配 expr substr $string $position $length：从 position 开始，匹配长度为 length</description></item><item><title>kubernetes 脚本快速安装</title><link>https://www.jobcher.com/k8s4/</link><pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s4/</guid><description>kubernetes 脚本快速安装 1、三台机器设置自己的 hostname（不能是 localhost） 1# 修改 hostname; k8s-01要变为自己的hostname 2hostnamectl set-hostname k8s-01 3# 设置 hostname 解析 4echo &amp;#34;127.0.0.1 $(hostname)&amp;#34; &amp;gt;&amp;gt; /etc/hosts 2、所有机器批量执行如下脚本
1#先在所有机器执行 vi k8s.sh 2# 进入编辑模式（输入i），把如下脚本复制 3# 所有机器给脚本权限 chmod +x k8s.sh 4#执行脚本 ./k8s.sh 1#/bin/sh 2 3#######################开始设置环境##################################### \n 4 5 6printf &amp;#34;##################正在配置所有基础环境信息################## \n&amp;#34; 7 8 9printf &amp;#34;##################关闭selinux################## \n&amp;#34; 10sed -i &amp;#39;s/enforcing/disabled/&amp;#39; /etc/selinux/config 11setenforce 0 12printf &amp;#34;##################关闭swap################## \n&amp;#34; 13swapoff -a 14sed -ri &amp;#39;s/.*swap.*/#&amp;amp;/&amp;#39; /etc/fstab 15 16printf &amp;#34;##################配置路由转发################## \n&amp;#34; 17cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.</description></item><item><title>Maven 安装编译</title><link>https://www.jobcher.com/maven/</link><pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/maven/</guid><description>Maven 安装编译 Maven 就是专门为 Java 项目打造的管理和构建工具，它的主要功能有：
提供了一套标准化的项目结构； 提供了一套标准化的构建流程（编译，测试，打包，发布……）； 提供了一套依赖管理机制。 默认结构：
1a-maven-project 2├── pom.xml 3├── src 4│ ├── main 5│ │ ├── java 6│ │ └── resources 7│ └── test 8│ ├── java 9│ └── resources 10└── target 项目的根目录a-maven-project是项目名，
它有一个项目描述文件pom.xml，
存放Java源码的目录是src/main/java，
存放资源文件的目录是src/main/resources，
存放测试源码的目录是src/test/java，
存放测试资源的目录是src/test/resources，
最后，所有编译、打包生成的文件都放在target目录里。
这些就是一个 Maven 项目的标准目录结构。
pom.xml 文件:
1&amp;lt;project ...&amp;gt; 2	&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; 3	&amp;lt;groupId&amp;gt;com.itranswarp.learnjava&amp;lt;/groupId&amp;gt; 4	&amp;lt;artifactId&amp;gt;hello&amp;lt;/artifactId&amp;gt; 5	&amp;lt;version&amp;gt;1.0&amp;lt;/version&amp;gt; 6	&amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt; 7	&amp;lt;properties&amp;gt; 8 ... 9	&amp;lt;/properties&amp;gt; 10	&amp;lt;dependencies&amp;gt; 11 &amp;lt;dependency&amp;gt; 12 &amp;lt;groupId&amp;gt;commons-logging&amp;lt;/groupId&amp;gt; 13 &amp;lt;artifactId&amp;gt;commons-logging&amp;lt;/artifactId&amp;gt; 14 &amp;lt;version&amp;gt;1.</description></item><item><title>Nodejs 安装编译</title><link>https://www.jobcher.com/nodejs/</link><pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nodejs/</guid><description>Nodejs 安装编译 Node.js 平台是在后端运行 JavaScript 代码，必须首先在本机安装 Node 环境。
安装 Node.js 安装 npm npm 其实是 Node.js 的包管理工具（package manager）。</description></item><item><title>ruoyi-cloud docker部署</title><link>https://www.jobcher.com/ruoyi/</link><pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ruoyi/</guid><description>基础环境安装 1# docker 脚本安装 2curl -sSL https://get.daocloud.io/docker | sh 3 4#docker compose 脚本安装 5curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` &amp;gt; /usr/local/bin/docker-compose 6 7 8#可执行权限 9sudo chmod +x /usr/local/bin/docker-compose 10#创建软链： 11sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 12#测试是否安装成功 13docker-compose --version 下载安装 1git clone https://gitlab.sanjiang.com/it-group/ruoyi-cloud.git 编译 1cd ruoyi-cloud 2mvn clean install -DskipTests 复制 jar 包 1cd ./docker 2./copy.sh 部署 docker 1./deploy.sh base 2./deploy.sh modules 检查 docker 1docker ps -a | grep ruoyi 2docker logs -f ruoyi-auth 3docker logs -f ruoyi-gateway 4docker logs -f ruoyi-modules-system</description></item><item><title>git版本控制</title><link>https://www.jobcher.com/git2/</link><pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/git2/</guid><description>git 版本控制 版本回退 1.查看 git 提交历史 1#查看git提交历史 2git log 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数
1git log --pretty=oneline 2.回退到上一个版本 Git必须知道当前版本是哪个版本，在 Git 中，用HEAD表示当前版本，也就是最新的提交b534d741..（注意我的提交 ID 和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上 100 个版本写 100 个^比较容易数不过来，所以写成HEAD~100
1git reset --hard HEAD^ 最新的那个版本已经看不到了，可以顺着往上找，找到那个版本的 ID
1git reset --hard c8275ca Git 在内部有个指向当前版本的HEAD指针,当你回退版本的时候，Git 仅仅是把HEAD从指向update
1┌────┐ 2│HEAD│ 3└────┘ 4 │ 5 └──&amp;gt; ○ update 6 │ 7 ○ Create README.md 8 │ 9 ○ init 改为指向 Create README.md：
1┌────┐ 2│HEAD│ 3└────┘ 4 │ 5 │ ○ update 6 │ │ 7 └──&amp;gt; ○ Create README.</description></item><item><title>Linux crontab 命令</title><link>https://www.jobcher.com/crontab/</link><pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/crontab/</guid><description>Linux crontab 命令 Linux crontab是用来定期执行程序的命令。
系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法 1crontab [ -u user ] file 2crontab [ -u user ] { -l | -r | -e } 说明：
crontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。
-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。
参数说明：
-e : 执行文字编辑器来设定时程表，内定的文字编辑器是 VI，如果你想用别的文字编辑器，则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe)
-r : 删除目前的时程表
-l : 列出目前的时程表
时间格式如下：
1f1 f2 f3 f4 f5 program 2* * * * * 3- - - - - 4| | | | | 5| | | | +----- 星期中星期几 (0 - 6) (星期天 为0) 6| | | +---------- 月份 (1 - 12) 7| | +--------------- 一个月中的第几天 (1 - 31) 8| +-------------------- 小时 (0 - 23) 9+------------------------- 分钟 (0 - 59) 其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 * 时表示每分钟都要执行 program，f2 为 * 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次，f2 为 */n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,.</description></item><item><title>linux 网络测速</title><link>https://www.jobcher.com/bench/</link><pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/bench/</guid><description>linux 网络测速 一键测试脚本bench.sh 适用于各种 Linux 发行版的网络（下行）和 IO 测试：
显示当前测试的各种系统信息 取自世界多处的知名数据中心的测试点，下载测试比较全面 支持 IPv6 下载测速 IO 测试三次，并显示平均值 1wget -qO- bench.sh | bash 2#或者下面这命令下载执行 3curl -Lso- bench.sh | bash 欢迎关注我的博客www.jobcher.com</description></item><item><title>docker 命令(2)</title><link>https://www.jobcher.com/docker02/</link><pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker02/</guid><description>docker 命令(2) docker ps 命令 docker ps 能查看所有运行中的容器
docker ps -a 能查看所有的容器
docker rm -f $(docker ps -aq) 强制删除所有容器
docker run和docker create有什么区别 docker create命令能够基于镜像创建容器。
该命令执行的效果类似于docker run -d，即创建一个将在系统后台运行的容器。
但是与docker run -d不同的是，docker create创建的容器并未实际启动，还需要执行docker start命令或docker run命令以启动容器。
事实上，docker create 命令常用于在启动容器之前进行必要的设置。</description></item><item><title>CICD 概念</title><link>https://www.jobcher.com/devops/</link><pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/devops/</guid><description>CICD 概念 DevOps Devlopment 和 Operation 的组合词
规划-》代码-》构建-》测试-》发布-》部署-》运营-》监控-》再次规划
devOps 看作开发（软件工程）、技术运营和质量保障（QA）三者的交集 突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps 希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗。更加高效的协同工作。良好的闭环可以大大增加整体的产出。 CICD 持续集成 持续部署
持续集成
持续集成是指软件个人研发的部分向软件整体部分交付，频繁进行集成以便更快地发现其中的错误。“持续集成”源自于极限编程（XP），是 12 最初的 12 种实践之一 Ci 需要具备这些： 1全面的自动化测试，这是实践持续集成和持续部署的基础，同时，选择合适的自动化测试工具也极其重要； 2灵活的基础设施。容器，虚拟化的存在让开发人员和QA不必再大费周折 3版本控制工具。如git，cvs，svn等 4自动化的构建和软件发布流程工具，如 Jenkins，flow.ci; 5反馈机制，如构建/测试的失败，可以快速地反馈到相关负责人，以尽快解决达到一个更稳定的版本。</description></item><item><title>git使用方法</title><link>https://www.jobcher.com/git/</link><pubDate>Thu, 17 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/git/</guid><description>git 使用方法 一、git 安装配置 Debian/Ubuntu 1 apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \ 2 libz-dev libssl-dev 3 4 apt-get install git 5 6 git --version 7 git version 1.8.1.2 Centos/RedHat 1 yum install curl-devel expat-devel gettext-devel \ 2 openssl-devel zlib-devel 3 4 yum -y install git-core 5 6 git --version 7 git version 1.7.1 二、git 拉取异常如何重新拉取 1.同一文件有修改，产生冲突。 先将本地修改存储起来 使用git stash命令，这样本地的所有修改就都被暂时存储起来 。其中stash@{0}就是刚才保存的标记。后续可以通过此标记访问。 再次拉取代码 1git pull 还原暂存的内容 1git stash pop stash@{0} 解决冲突 在存在冲突的文件中，Updated upstream 和=====之间的内容为拉取下来的代码，=====和stashed changes之间的内容就为本地修改的代码。解决完成之后，就可以正常的提交了。 5.</description></item><item><title>kubernetes面试题汇总</title><link>https://www.jobcher.com/k8s3/</link><pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s3/</guid><description>kubernetes 面试题汇总 1、 k8s 是什么？请说出你的了解？ 答：Kubenetes 是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。
K8S 是 Google 公司推出的，它来源于由 Google 公司内部使用了 15 年的 Borg 系统，集结了 Borg 的精华。
2、 K8s 架构的组成是什么？ 答：和大多数分布式系统一样，K8S 集群至少需要一个主节点（Master）和多个计算节点（Node）。
主节点主要用于暴露 API，调度部署和节点的管理；
计算节点运行一个容器运行环境，一般是 docker 环境（类似 docker 环境的还有 rkt），同时运行一个 K8s 的代理（kubelet）用于和 master 通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是 k8s 集群中真正工作的节点。
1K8S架构细分： 21、Master节点（默认不参加实际工作）： 3 4Kubectl：客户端命令行工具，作为整个K8s集群的操作入口； 5Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件； 6Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等； 7Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上； 8Etcd：担任数据中心的角色，保存了整个群集的状态； 92、Node节点： 10Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）； 11Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务时，Service接收到的请求后就是通过kube-proxy来转发到pod上的）； 12container-runtime：是负责管理运行容器的软件，比如docker 13Pod：是k8s集群里面最小的单位。每个pod里边可以运行一个或多个container（容器），如果一个pod中有两个container，那么container的USR（用户）、MNT（挂载点）、PID（进程号）是相互隔离的，UTS（主机名和域名）、IPC（消息队列）、NET（网络栈）是相互共享的。我比较喜欢把pod来当做豌豆夹，而豌豆就是pod中的container； 3、 容器和主机部署应用的区别是什么？ 答：容器的中心思想就是秒级启动；一次封装、到处运行；这是主机部署应用无法达到的效果，但同时也更应该注重容器的数据持久化问题。 另外，容器部署可以将各个服务进行隔离，互不影响，这也是容器的另一个核心概念。
4、请你说一下 kubenetes 针对 pod 资源对象的健康监测机制？ 答：K8s 中对于pod资源对象的健康状态检测，提供了三类probe（探针）来执行对 pod 的健康监测：
livenessProbe探针
可以根据用户自定义规则来判定 pod 是否健康，如果 livenessProbe 探针探测到容器不健康，则 kubelet 会根据其重启策略来决定是否重启，如果一个容器不包含 livenessProbe 探针，则 kubelet 会认为容器的 livenessProbe 探针的返回值永远成功。 ReadinessProbe探针</description></item><item><title>Kubernetes 安装</title><link>https://www.jobcher.com/k8s2/</link><pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s2/</guid><description>Kubernetes 安装 环境配置 关闭防火墙： 如果是云服务器，需要设置安全组策略放行端口 1systemctl stop firewalld 2systemctl disable firewalld 修改 hostname 1hostnamectl set-hostname k8s-01 2echo &amp;#34;127.0.0.1 $(hostname)&amp;#34; &amp;gt;&amp;gt; /etc/hosts 3reboot 关闭 selinux： 1sed -i &amp;#39;s/enforcing/disabled/&amp;#39; /etc/selinux/config 2setenforce 0 关闭 swap： 1swapoff -a 2sed -ri &amp;#39;s/.*swap.*/#&amp;amp;/&amp;#39; /etc/fstab 修改 /etc/sysctl.conf 1# 如果有配置，则修改 2sed -i &amp;#34;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g&amp;#34; /etc/sysctl.conf 3sed -i &amp;#34;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g&amp;#34; /etc/sysctl.conf 4sed -i &amp;#34;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g&amp;#34; /etc/sysctl.conf 5sed -i &amp;#34;s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g&amp;#34; /etc/sysctl.conf 6sed -i &amp;#34;s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g&amp;#34; /etc/sysctl.conf 7sed -i &amp;#34;s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g&amp;#34; /etc/sysctl.conf 8sed -i &amp;#34;s#^net.ipv6.conf.all.forwarding.*#net.ipv6.conf.all.forwarding=1#g&amp;#34; /etc/sysctl.conf 9# 可能没有，追加 10echo &amp;#34;net.</description></item><item><title>linux常用命令</title><link>https://www.jobcher.com/linux1/</link><pubDate>Sat, 12 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/linux1/</guid><description>linux 常用命令 软件操作命令 1#软件包管理器 2yum 3# 安装软件 4yum install xxxx 5# 卸载软件 6yum remove xxx 7# 搜索软件 8yum search xxx 9# 清理缓存 10yum clean packages 11# 列出已安装 12yum list 13# 软件包信息 14yum info 服务器硬件资源和磁盘操作 1# 内存 2free -h 3# 硬盘 4df -h 5# 负载 6w/top/htop 7# 查看cpu 8cat /proc/cpuinfo 9# 查看磁盘 10fdisk -l 文件和文件夹操作命令 命令 解释 ls 查看目录下的文件 touch 新建文件 mkdir 新建目录 cd 进入目录 rm 删除文件和目录 cp 复制 mv 移动 pwd 显示路径 系统用户操作命令 防火墙相关设置 提权操作 sudo 和文件传输</description></item><item><title>linux基础知识</title><link>https://www.jobcher.com/linux/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/linux/</guid><description>linux 基础知识 1、简述 Linux 权限划分原则。 给文件或目录分配权限时，先考虑所有者和所属组 遵循最小化权限，用啥权限给啥权限 修改目录和子文件归属权限，注意递归 文件权限分配是最常用的安全防护手段 2、当用户 user1，对/testdir 目录有写和执行权限时，该目录下的只读文件 file1 是否可修改和删除？ 对 file1 不能修改也不能删除。（如果对目录有写权限和执行权限，则对 file1 不能修改可以删除）
3、如果一个系统没有任何的备份策略，请写出一个较为全面合理的备份方案！ 增量备份：将相较于前一天增加的内容备份，适合每天改变量较大的数据。
差异备份：将相较于第一天改变的内容备份，适合原始数据量比较大，但是之后改变的比较小，即使中间哪一天的丢了也没事，只要最后一天，和第一天的在就行。
4、网站服务器每天产生的日志数量较大，请问如何备份? 使用 logrotate 滚动日志 split 大文件切分处理 shell 脚本处理日志 5、简述 Raid 0、Raid 1、Raid 5 的特点与原理。 RAID 等级 最少硬盘 最大容错 可用容量 读取性能 写入性能 安全性 目的 应用产业 单一硬盘 (参考) 0 1 1 1 无 JBOD 1 0 n 1 1 无（同 RAID 0） 增加容量 个人（暂时） 存储备份 0 2 0 n n n 一个硬盘异常，全部硬盘都会异常 追求最大容量、速度 视频剪接缓存用途 1 2 n-1 1 n 1 高，一个正常即可 追求最大安全性 个人、企业备份 5 3 1 n-1 n-1 n-1 中下至中 追求最大容量、最小预算 个人、小型企业备份 6 4 2 n-2 n-2 n-2 中至中高,仅安全性较 RAID 5 高 同 RAID 5，但较安全 个人、企业备份 10 4 高 综合 RAID 0/1 优点，理论速度较快 大型数据库、服务器 50 6 高 提升资料安全 60 8 高 提升资料安全 6、简述 Raid6、Raid 10 的特点与原理。 与 RAID 5 相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，任意两块磁盘同时失效时不会影响数据完整性。RAID 6 需要分配给奇偶校验信息更大的磁盘空间和额外的校验计算，相对于 RAID 5 有更大的 IO 操作量和计算量，其“写性能”强烈取决于具体的实现方案，因此RAID 6通常不会通过软件方式来实现，而更可能通过硬件方式实现。</description></item><item><title>网心云挂机教程 | 轻松实现睡后收入~</title><link>https://www.jobcher.com/wxyun/</link><pubDate>Fri, 11 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/wxyun/</guid><description>网心云挂机教程 | 轻松实现睡后收入~ 首先，本文章只是分享，造成一切的后果，博主概不负责！都是成年人了……
我采用 docker 容器魔方来挂载网心云
docker 部署 /mnt/money/wxedge_storage这个路径改为自己的存储路径建议&amp;gt;200G
1docker run \ 2--name=wxedge \ 3--restart=always \ 4--privileged \ 5--net=host \ 6--tmpfs /run \ 7--tmpfs /tmp \ 8-v /mnt/money/wxedge_storage:/storage:rw \ 9-d \ 10registry.cn-hangzhou.aliyuncs.com/onething/wxedge 设备绑定 进入 dockerip 地址 （http://127.0.0.1:18888) 下载 app 扫码绑定 成功 然后坐等第二天收益到账就可以了，记得19:00-23:00是收益高峰期尽量保持在线~</description></item><item><title>清理Docker的container，image与volume</title><link>https://www.jobcher.com/docker-clean/</link><pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-clean/</guid><description>清理 Docker 的 container，image 与 volume Docker 的镜像（image）、容器（container）、数据卷（volume）， 都是由 daemon 托管的。 因此，在需要清理时，也需要使用其自带的手段。
清理技巧 清理所有停止运行的容器：
1docker container prune 2# or 3docker rm $(docker ps -aq) 清理所有悬挂（&amp;lt;none&amp;gt;）镜像：
1docker image prune 2# or 3docker rmi $(docker images -qf &amp;#34;dangling=true&amp;#34;) 清理所有无用数据卷：
1docker volume prune 由于prune操作是批量删除类的危险操作，所以会有一次确认。 如果不想输入y&amp;lt;CR&amp;gt;来确认，可以添加-f操作。慎用！
清理停止的容器 docker rm -lv CONTAINER -l是清理 link，v是清理 volume。 这里的 CONTAINER 是容器的 name 或 ID，可以是一个或多个。
参数列表：
Name shorthand Default Description –force,-f false Force the removal of a running container (uses SIGKILL) –link, -l false Remove the specified link –volumes, -v false Remove the volumes associated with the container 清理所有停止的容器 通过docker ps可以查询当前运行的容器信息。 而通过docker ps -a，可以查询所有的容器信息，包括已停止的。</description></item><item><title>Jenkins 安装与使用</title><link>https://www.jobcher.com/jenkins/</link><pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/jenkins/</guid><description>Jenkins 安装与使用 代码在本地修改&amp;mdash;-》提交到远程 gitlab&amp;mdash;-》触发 jenkins 整个自动化构建流程（打包，测试，发布，部署）
安装 docker 安装 docker
docker 安装 jenkins 1docker run \ 2 -u root \ 3 -d \ 4 -p 8080:8080 \ 5 -p 50000:50000 \ 6 -v jenkins-data:/var/jenkins_home \ 7 -v /etc/localtime:/etc/localtime:ro \ 8 -v /var/run/docker.sock:/var/run/docker.sock \ 9 --restart=always \ 10 jenkinsci/blueocean 访问 http://localhost:8080
显示初始密码
1docker exec -ti &amp;lt;容器名称&amp;gt; sh 2cat /var/jenkins_home/secrets/initialAdminPassword 工作流程 先定义一个流水线项目，指定项目的 git 位置 git 位置自动拉取代码 解析拉取代码里面的 Jenkinsfile 文件 按照 Jenkinsfile 指定的流水线开始加工项目 Jenkinsfile 语法 基础语法,在仓库创建一个 Jenkinsfile 文件</description></item><item><title>Navicat 查看导出连接的密码 | navicat查看密码方案</title><link>https://www.jobcher.com/navicatforgetpassword/</link><pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/navicatforgetpassword/</guid><description>Navicat 查看密码方案 解决问题： 我们经常使用 navicat 连接数据库，有时候时间久了之后，会忘记之前的密码，那么现在我们有办法获得只要正常连接的数据库的密码
步骤： 导出连接 connections.ncx，拿到保存到本地的 connections.ncx 文件中的 Password，粘贴到下面的代码中 登陆https://tool.lu/coderunner/，使用 PHP 在线运行工具，粘贴下面添加密码后的代码
备用工具网址（https://zixuephp.net/tool-runcode.html） 1&amp;lt;?php 2class NavicatPassword 3{ 4 protected $version = 0; 5 protected $aesKey = &amp;#39;libcckeylibcckey&amp;#39;; 6 protected $aesIv = &amp;#39;libcciv libcciv &amp;#39;; 7 protected $blowString = &amp;#39;3DC5CA39&amp;#39;; 8 protected $blowKey = null; 9 protected $blowIv = null; 10 11 public function __construct($version = 12) 12 { 13 $this-&amp;gt;version = $version; 14 $this-&amp;gt;blowKey = sha1(&amp;#39;3DC5CA39&amp;#39;, true); 15 $this-&amp;gt;blowIv = hex2bin(&amp;#39;d9c7c3c8870d64bd&amp;#39;); 16 } 17 18 public function encrypt($string) 19 { 20 $result = FALSE; 21 switch ($this-&amp;gt;version) { 22 case 11: 23 $result = $this-&amp;gt;encryptEleven($string); 24 break; 25 case 12: 26 $result = $this-&amp;gt;encryptTwelve($string); 27 break; 28 default: 29 break; 30 } 31 32 return $result; 33 } 34 35 protected function encryptEleven($string) 36 { 37 $round = intval(floor(strlen($string) / 8)); 38 $leftLength = strlen($string) % 8; 39 $result = &amp;#39;&amp;#39;; 40 $currentVector = $this-&amp;gt;blowIv; 41 42 for ($i = 0; $i &amp;lt; $round; $i++) { 43 $temp = $this-&amp;gt;encryptBlock($this-&amp;gt;xorBytes(substr($string, 8 * $i, 8), $currentVector)); 44 $currentVector = $this-&amp;gt;xorBytes($currentVector, $temp); 45 $result .</description></item><item><title>ProXmoX VE升级 apt-get update 报错</title><link>https://www.jobcher.com/pveupdate/</link><pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/pveupdate/</guid><description>ProXmoX VE 升级 apt-get update 报错 解决方法 1vim /etc/apt/sources.list.d/pve-enterprise.list 2#注释掉 3#deb https://enterprise.proxmox.com/debian/pve stretch pve-enterprise 添加内容 1echo &amp;#34;deb http://download.proxmox.com/debian/pve stretch pve-no-subscription&amp;#34; &amp;gt; /etc/apt/sources.list.d/pve-install-repo.list 2wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg 更新系统 1apt update &amp;amp;&amp;amp; apt dist-upgrade 结尾 升级完成后，可以执行pveversion -v查看下最新的软件版本。然后执行reboot重启物理服务器</description></item><item><title>mysql 笔记（2）</title><link>https://www.jobcher.com/mysql02/</link><pubDate>Fri, 21 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/mysql02/</guid><description>mysql 学习笔记（2） mysql 主从复制 MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。
MySQL 主从复制的主要用途 读写分离 数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换(主从切换) 高可用（HA） 架构扩展 MySQL 主从复制的原理 MySQL 主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:
主节点 log dump 线程
当从节点连接主节点时，主节点会为其创建一个 log dump 线程，用于发送和读取 bin-log 的内容。在读取 bin-log 中的操作时，log dump 线程会对主节点上的 bin-log 加锁，当读取完成，在发送给从节点之前，锁会被释放。主节点会为自己的每一个从节点创建一个log dump 线程。
从节点 I/O 线程
当从节点上执行start slave命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O 线程接收到主节点的 blog dump 进程发来的更新之后，保存在本地relay-log（中继日志）中。
从节点 SQL 线程
SQL 线程负责读取 relay-log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。
对于每一个主从连接，都需要这三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时 I/O 进程可以很快从主节点获取更新，尽管 SQL 进程还没有执行。如果在 SQL 进程执行之前从节点服务停止，至少 I/O 进程已经从主节点拉取到了最新的变更并且保存在本地 relay 日志中，当服务再次起来之后，就可以完成数据的同步。</description></item><item><title>Proxmox VE 在线扩容磁盘分区</title><link>https://www.jobcher.com/pve1/</link><pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/pve1/</guid><description>Proxmox VE 在线扩容磁盘分区 添加磁盘大小 在 VM 上做扩容操作 安装 growpart 1yum install -y epel-release 2yum install -y cloud-utils 查看系统盘 路径 1fdisk -l 2df -h 扩容设备并重启 1growpart /dev/sda 2 #2代表是第二块系统分区，不是sda2,中间有空格 2reboot 重启执行命令 1xfs_growfs /dev/sda2 #(xfs 文件系统) 2resize2fs /dev/sda2 #(ext4 文件系统) 更新完成 1df -h 逻辑卷没有正常扩容的情况 检查当前逻辑卷属于哪个卷组: 1vgdisplay 检查卷组中是有足够的空间可以扩容,还有99g
扩展逻辑卷大小到200G: 1lvextend -L +99G /dev/mapper/ubuntu--vg-ubuntu--lv 调整文件系统大小到逻辑卷大小: 1resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv 4. 检查
1df -h /dev/mapper/ubuntu--vg-ubuntu--lv 成功扩容</description></item><item><title>Gitlab批量导出用户</title><link>https://www.jobcher.com/exportuser/</link><pubDate>Fri, 14 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/exportuser/</guid><description>Gitlab 批量导出用户 登陆 Gitlab 服务器进行数据库登陆、数据查询及信息导出操作。
操作步骤 根据配置文件，定位数据库相关信息 1cat /var/opt/gitlab/gitlab-rails/etc/database.yml 查看 Gitlab 对应的系统用户 1cat /etc/passwd | grep gitlab 切换用户 gitlab-psql 1su - gitlab-psql 登陆数据库（-h 指定 host，-d 指定数据库） 使用第 1 步获取的信息 1psql -h /var/opt/gitlab/postgresql -d gitlabhq_production (1) 查看帮助信息
1gitlabhq_production=# \h (2) 查看数据库
1gitlabhq_production=# \l (3) 查看库中的表（执行命令后，按回车键显示更多表信息）
1gitlabhq_production=# \dt (4) 通过筛查，可在库中找到 users 表，相关用户信息都记录在表中！
1gitlabhq_production=# \d users (5) 查看表信息
1gitlabhq_production=# SELECT * FROM users; (6) 查看 users 表中的 name 字段
1gitlabhq_production=# SELECT name FROM users; (7)登出数据库</description></item><item><title>Harbor 搭建</title><link>https://www.jobcher.com/harbor/</link><pubDate>Fri, 14 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/harbor/</guid><description>Harbor 搭建 Harbor 是一个开源可信的云原生注册表项目，用于存储、签名和扫描内容。用于存储 docker image
要求 Linux 主机 docker 17.06.0-ce 以上 docker-compose 1.18.0 以上 链接跳转：docker 安装
安装 下载程序 在线安装包
1wget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-online-installer-v1.10.10.tgz 离线安装包
1wget https://github.com/goharbor/harbor/releases/download/v1.10.10/harbor-offline-installer-v1.10.10.tgz 安装 1mkdir -p /data 2cd /data 3tar -zxvf harbor-offline-installer-v1.10.10.tgz 4cd /harbor 5./install.sh 接下来只要安静的等待安装就可以了
配置 1# Configuration file of Harbor 2 3# The IP address or hostname to access admin UI and registry service. 4# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.</description></item><item><title>prometheus grafana alertmanager 安装配置</title><link>https://www.jobcher.com/prometheus1/</link><pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/prometheus1/</guid><description>prometheus+grafana+alertmanager 安装配置 服务器监控告警系统搭建，通过 exporter 获取节点信息到 prometheus。prometheus 配置规则，使 garfana 和 alertmanager 能够接受到数据，分别展示数据和发送告警
参数 VM :192.168.99.78
端口 服务 9100 node_exporter 3000 grafana 9090 prometheus 9115 blackbox_exporter 安装 grafa 安装 docker 安装 1docker run -d -p 3000:3000 \ 2--name=grafana \ 3-v grafana-storage:/var/lib/grafana \ 4grafana/grafana:8.3.3 prometheus 安装 下载 1wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz 2tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz 3cd prometheus-2.32.1.linux-amd64 4mkdir -p file_sd 5mkdir -p rules 运行 prometheus 1killall prometheus 2nohup ./prometheus --config.file=prometheus.yml &amp;amp; 3# 查看运行状况 4tail -f nohup.out node_exporter 安装 docker-compose 安装 1version: &amp;#34;3&amp;#34; 2services: 3 node-exporter: 4 image: prom/node-exporter:v1.</description></item><item><title>prometheus 配置</title><link>https://www.jobcher.com/prometheus/</link><pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/prometheus/</guid><description>prometheus 配置 Prometheus 是由 SoundCloud 开源监控告警解决方案
组件 Prometheus Server， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。 client libraries，用于对接 Prometheus Server, 可以查询和上报数据。 push gateway ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。 各种汇报数据的 exporters ，例如汇报机器数据的 node_exporter, 汇报 MongoDB 信息的 MongoDB exporter 等等。 用于告警通知管理的 alertmanager 。 运行逻辑 Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。 Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。 Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。 安装 prometheus 使用预编译的二进制文件安装 1wget https://github.com/prometheus/prometheus/releases/download/v2.32.1/prometheus-2.32.1.linux-amd64.tar.gz 2tar -zxvf prometheus-2.32.1.linux-amd64.tar.gz 3cd prometheus-2.</description></item><item><title>centos7.9 网络配置</title><link>https://www.jobcher.com/linux-network/</link><pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/linux-network/</guid><description>centos7.9 网络配置 解决 centos 新机器网络不通的问题，CentOS7 默认不启动网卡的。CentOS 安装成功后,进行一下 ping 的操作,验证网络是否联通.
1ping 1.1.1.1 2ip addr 3# 查看ip网络名称 启用网卡 进入 /etc/sysconfig/network-scipts 文件夹下，找到 IP 网卡名称 1cd /etc/sysconfig/network-scipts 2vim ifcfg-eth0 启用 ONBOOT 1#vim ifcfg-eth0 2#修改 3ONBOOT=YES 4# esc 并:wq退出保存 重启机器 1shutdown -r now 结尾 centos 用的挺别扭，不考虑性能和性价比，我还是喜欢用 ubuntu……，简单的配置，初学者我建议还是先用 ubuntu，会少踩很多坑。当然了，用 x86 不然初学者用树莓派和 arm 设备，会碰到很多兼容性的问题。</description></item><item><title>安装 docker 出现 ERROR: Unsupported distribution 'ol' 问题</title><link>https://www.jobcher.com/error1/</link><pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/error1/</guid><description>安装 docker 出现 ERROR: Unsupported distribution &amp;lsquo;ol&amp;rsquo; 问题 部署 docker 安装出现 ERROR: Unsupported distribution &amp;lsquo;ol&amp;rsquo;
确认是不是 arm 架构 1uname -r 确认使用的是不是 oracle 服务器系统,如果是请继续操作，安装依赖： 1dnf install -y dnf-utils zip unzip 2dnf config-manager --add-repo=https://download.docker.com/linux/centos/docker-ce.repo 安装 docker 1dnf remove -y runc 2dnf install -y docker-ce --nobest 完成 docker 安装并检查 1systemctl enable docker.service 2systemctl start docker.service 1#检查 2systemctl status docker.service 3docker info 4docker version 结尾 该问题主要是 oracle 没有支持依赖导致的~oracle 还是很不错的~</description></item><item><title>Kubernetes 实验手册（1）</title><link>https://www.jobcher.com/k8s1/</link><pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8s1/</guid><description>Kubernetes 实验手册（1） 通过在 pve 创建 5 台虚拟机：
节点 IP 作用 node0 192.168.99.69 k8s-master01 node1 192.168.99.9 k8s-master02 node2 192.168.99.53 k8s-master03 node3 192.168.99.41 k8s-node01 node4 192.168.99.219 k8s-node02 node5 192.168.99.42 k8s-master-lb 配置信息 备注 系统版本 Ubuntu Docker 20.10.12 pod 网段 172.168.0.0/12 service 网段 10.96.0.0/12 VIP 不要和内网 IP 重复，VIP 需要和主机在同一个局域网内
更新 ansible 连接 1ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.155 2ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.199 3ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.87 4#ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.41 5#ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.99.219 1vim /etc/hosts 2192.</description></item><item><title>RocketMQ 安装和启动</title><link>https://www.jobcher.com/rocketmq/</link><pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/rocketmq/</guid><description>RocketMQ 安装和部署 部署 RocketMQ
单机安装构建 安装 JDK 1.8.0 1yum install java-1.8.0-openjdk* 安装 Maven 1wget http://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz 2tar -zxvf apache-maven-3.8.4-bin.tar.gz 3mv -f apache-maven-3.8.4 /usr/local/ 4vim /etc/profile 5# 末尾添加 6export MAVEN_HOME=/usr/local/apache-maven-3.8.4 7export PATH=${PATH}:${MAVEN_HOME}/bin 8# 保存 9source /etc/profile 10# 查看maven是否正常 11mvn -v 快速部署 1#构建 DLedger 2git clone https://github.com/openmessaging/openmessaging-storage-dledger.git 3cd openmessaging-storage-dledger 4mvn clean install -DskipTests 5# 构建 RocketMQ 6git clone https://github.com/apache/rocketmq.git 7cd rocketmq 8git checkout -b store_with_dledger origin/store_with_dledger 9mvn -Prelease-all -DskipTests clean install -U 10# 部署 11cd rocketmq/distribution/target/apache-rocketmq 12sh bin/dledger/fast-try.</description></item><item><title>安装 minIO Azure S3网关</title><link>https://www.jobcher.com/minio/</link><pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/minio/</guid><description>安装 minIO 通过 docker 安装 1docker run -p 9000:9000 -p 41863:41863 -d --name azure-s3 \ 2 -e &amp;#34;MINIO_ACCESS_KEY=azure存储账户&amp;#34; \ 3 -e &amp;#34;MINIO_SECRET_KEY=azure存储密码&amp;#34; \ 4 minio/minio gateway azure --console-address &amp;#34;:41863&amp;#34; 通过 docker-compose 安装 1version: &amp;#34;3&amp;#34; 2services: 3 minio: 4 image: &amp;#34;minio/minio:RELEASE.2022-01-04T07-41-07Z.fips&amp;#34; 5 container_name: &amp;#34;minio&amp;#34; 6 restart: &amp;#34;always&amp;#34; 7 volumes: 8 - &amp;#34;/etc/localtime:/etc/localtime&amp;#34; 9 ports: 10 - &amp;#34;9000:9000&amp;#34; 11 - &amp;#34;9001:9001&amp;#34; 12 environment: 13 - &amp;#34;MINIO_ROOT_USER=azure存储账户&amp;#34; 14 - &amp;#34;MINIO_ROOT_PASSWORD=azure存储密码&amp;#34; 15 command: 16 - --console-address &amp;#34;:41863&amp;#34;</description></item><item><title>Keepalived高可用</title><link>https://www.jobcher.com/keepalived/</link><pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/keepalived/</guid><description>Keepalived 高可用 配置文件存放位置：/usr/share/doc/keepalived/samples
VVRP 虚拟路由冗余协议
组成 LB 集群：Load Balancing，负载均衡集群，平均分配给多个节点
HA 集群：High Availability，高可用集群，保证服务可用
HPC 集群：High Performance Computing，高性能集群
配置 keepalived+LVS+nginx
各节点时间必须同步：ntp, chrony 关闭防火墙及 SELinux 同步各节点时间 1#安装ntpdate 2apt install ntpdate 3#更改时区 4timedatectl set-timezone &amp;#39;Asia/Shanghai&amp;#39; 5#查看时间 6timedatectl 7datetime 安装 keepalived 1#安装 2apt install keepalived 3#更改模板 4cd /usr/share/doc/keepalived/samples</description></item><item><title>ansible 安装和部署</title><link>https://www.jobcher.com/ansible/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/ansible/</guid><description>ansible 安装和部署 Ansible 默认通过 SSH 协议管理机器.
安装 ansible 下载安装 1# ubuntu 安装 2apt-get install software-properties-common 3apt-add-repository ppa:ansible/ansible 4apt-get update 5apt-get install ansible 6# centos 安装 7yum install ansible 检查文件 1#检查 2ansible --version ansible 配置 添加主机 1vim /etc/ansible/hosts 2#添加你需要添加的被控主机地址和IP 配置 SSH key 授权访问 1# 控制主机生成ssh 密钥对（一路回车） 2ssh-keygen -t rsa 3# 复制公钥IP到被控主机 4ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.2 5ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.3 6ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.0.4 7# ssh-copy-id命令会自动将id_rsa.pub文件的内容追加到远程主机root用户下.ssh/authorized_keys文件中。 更改 ansible 配置 1vim /etc/ansible/ansible.cfg 2 3#禁用每次执行ansbile命令检查ssh key host 4host_key_checking = False 5# 开启日志记录 6log_path = /var/log/ansible.</description></item><item><title>yaml 语法</title><link>https://www.jobcher.com/yaml/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/yaml/</guid><description>yaml 语法 我们使用 YAML 是因为它像 XML 或 JSON 是一种利于人们读写的数据格式. 此外在大多数变成语言中有使用 YAML 的库.YAML 语法的基本概述, 它被用来描述一个 playbooks(我们的配置管理语言).
基本的 YAML 对于 Ansible, 每一个 YAML 文件都是从一个列表开始. 列表中的每一项都是一个键值对, 通常它们被称为一个 “哈希” 或 “字典”. 所以, 我们需要知道如何在 YAML 中编写列表和字典.
YAML 还有一个小的怪癖. 所有的 YAML 文件(无论和 Ansible 有没有关系)开始行都应该是 &amp;mdash;. 这是 YAML 格式的一部分, 表明一个文件的开始.
1--- 2# 一个美味水果的列表 3- Apple 4- Orange 5- Strawberry 6- Mango</description></item><item><title>logrotate 日志滚动的使用</title><link>https://www.jobcher.com/logrotate/</link><pubDate>Wed, 29 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/logrotate/</guid><description>logrotate 日志滚动的使用 logrotate 日志滚动切割工具，是 linux 默认安装的工具，配置文件位置：
1/etc/logrotate.conf 2/etc/logrotate.d/ 参数 以 nginx 配置为例
1/opt/log/nginx/*.log { 2	daily 3	missingok 4	rotate 14 5 errors &amp;#34;nb@nbtyfood.com&amp;#34; 6	compress 7	delaycompress 8	notifempty 9	create 0640 www-data adm 10	sharedscripts 11	prerotate 12	if [ -d /etc/logrotate.d/httpd-prerotate ]; then \ 13	run-parts /etc/logrotate.d/httpd-prerotate; \ 14	fi \ 15	endscript 16	postrotate 17	invoke-rc.d nginx rotate &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 18	endscript 19} 参数 作用 compress 压缩日志文件的所有非当前版本 daily,weekly,monthly 按指定计划轮换日志文件 delaycompress 压缩所有版本，除了当前和下一个最近的 endscript 标记 prerotate 或 postrotate 脚本的结束 errors &amp;ldquo;emailid&amp;rdquo; 给指定邮箱发送错误通知 missingok 如果日志文件丢失，不要显示错误 notifempty 如果日志文件为空，则不轮换日志文件 olddir &amp;ldquo;dir&amp;rdquo; 指定日志文件的旧版本放在 “dir” 中 postrotate 引入一个在日志被轮换后执行的脚本 prerotate 引入一个在日志被轮换前执行的脚本 rotate &amp;rsquo;n' 在轮换方案中包含日志的 n 个版本 sharedscripts 对于整个日志组只运行一次脚本 size=&amp;lsquo;logsize&amp;rsquo; 在日志大小大于 logsize（例如 100K，4M）时轮换</description></item><item><title>docker 和 docker-compose 安装</title><link>https://www.jobcher.com/docker/</link><pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker/</guid><description>安装 docker 通过 docker 脚本安装
1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 1curl -sSL https://get.daocloud.io/docker | sh docker-compose 安装 1#下载安装 2sudo curl -L &amp;#34;https://github.jobcher.com/gh/https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose 3#可执行权限 4sudo chmod +x /usr/local/bin/docker-compose 5#创建软链： 6sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 7#测试是否安装成功 8docker-compose --version docker 命令 常用 docker 命令
1 #查看容器 2 docker ps 3 #查看镜像 4 docker images 5 #停止当前所有容器 6 docker stop $(docker ps -aq) 7 #删除当前停止的所有容器 8 docker rm $(docker ps -aq) 9 #删除镜像 10 docker rmi nginx</description></item><item><title>gitlab与github同步项目</title><link>https://www.jobcher.com/gitrsync/</link><pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/gitrsync/</guid><description>gitlab 与 github 同步项目 本地同步项目 1git clone 创建一个同名的项目,命令行终端中添加 remote 地址 1git remote add githubOrigin git@github.com:sjtfreaks/blog.git 项目同步到 Github 上 1git push -u githubOrigin main 分别同步 github 与 gitlab 即可 1git push -u githubOrigin main 2git push -u origin main</description></item><item><title>iptables 基础知识</title><link>https://www.jobcher.com/iptable/</link><pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/iptable/</guid><description>iptables 基础知识 内核包过滤与 NAT 管理工具.是 linux 系统中在用户空间中运行的运来配置内核防火墙的工具。它可以设置，维护和检查 linux 内核中的 ipv4 包过滤规则和管理网络地址转换（NAT）。
ipatbles 命令仅支持 ipv4，如果使用的 IP 协议是 ipv6 则需要使用专门的管理工具 ip6tables。
常用参数 参数 作用 -t&amp;lt;表&amp;gt; 指定要操纵的表 -A 向规则链中追加条目 -D 从规则链中删除条目 -I 向规则链中插入条目 -R 替换规则链中的相应条目 -L 显示规则链中的已有条目 -F 清除规则链中的现有条目。不改变规则链的默认目标策略 -Z 清空规则链中的数据包计数器和字节计数器 -N 创建新的用户自定义规则链 -P 定义规则链中的默认目标（策略） -h 显示帮助信息 -p&amp;lt;协议&amp;gt; 指定要匹配的数据包的协议类型 -s&amp;lt;源地址&amp;gt; 指定要匹配的数据包的源 IP 地址 -j&amp;lt;目标&amp;gt; 指定要跳转的目标 -i&amp;lt;网络接口&amp;gt; 指定数据包进入本机的网络接口 -o&amp;lt;网络接口&amp;gt; 指定数据包离开本机做使用的网络接口 -c&amp;lt;包计数&amp;gt; 在执行插入、追加和替换操作时初始化包计数器和字节计数器 参考实例 显示内核当前的 filter 表：
1iptables -L 显示内核当前的 nat 表：
1iptables -L -t nat 禁止本机对 192.</description></item><item><title>k3s 升级版本</title><link>https://www.jobcher.com/k3supgrade/</link><pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k3supgrade/</guid><description>k3s 升级版本 停止所有的 K3s 容器（慎用） 从 server 节点运行 killall 脚本
1/usr/local/bin/k3s-killall.sh 开始升级 使用安装脚本升级 K3s 1curl -sfL https://get.k3s.io | sh - 2#国内可用 3curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 重启 k3s 1sudo systemctl restart k3s</description></item><item><title>安装配置 Terraform</title><link>https://www.jobcher.com/terraform/</link><pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/terraform/</guid><description>安装配置 Terraform 安装 macOS 苹果系统安装 1#安装 2brew tap hashicorp/tap 3brew install hashicorp/tap/terraform 4# 更新 5brew update 6brew upgrade hashicorp/tap/terraform 7#验证安装 8terraform -help windows 系统安装 1#安装 2choco install terraform 3#直接到这个url里下载64位系统 4https://www.terraform.io/downloads 5#验证安装 6terraform -help Linux 安装 1curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - 2sudo apt-add-repository &amp;#34;deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main&amp;#34; 3sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install terraform 4#验证安装 5terraform -help 1wget -O- https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo | sudo tee /etc/yum.repos.d/hashicorp.repo 2sudo yum install terraform -y terrafrom 控制 proxmox 虚拟机 来源：https://github.</description></item><item><title>孜然杏鲍菇-素食</title><link>https://www.jobcher.com/eryngii/</link><pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/eryngii/</guid><description>孜然杏鲍菇-素食 准备食材 杏鲍菇 蒜 糖 白芝麻 孜然粉 老抽 生抽 蚝油 步骤 杏鲍菇切片 蒜切成末 热油下蒜爆香 杏鲍菇下锅把水分炒干 加一勺生抽、半勺老抽，半勺蚝油，一勺孜然粉，一勺白芝麻，半勺糖炒匀</description></item><item><title>mysql数据库备份迁移</title><link>https://www.jobcher.com/mysqldump/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/mysqldump/</guid><description>mysql 数据库备份迁移 使用 mydumper 做数据备份迁移
备份数据库 安装 1# 安装 centos 2yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el7.x86_64.rpm 3yum install https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper-0.11.5-1.el8.x86_64.rpm 1# 安装 ubuntu 2apt-get install libatomic1 3wget https://github.com/mydumper/mydumper/releases/download/v0.11.5/mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb 4dpkg -i mydumper_0.11.5-1.$(lsb_release -cs)_amd64.deb 备份 1nohup mydumper -h &amp;#39;备份数据库&amp;#39; \ 2-u &amp;#39;用户名&amp;#39; \ 3-p &amp;#39;密码&amp;#39; \ 4--threads=16 \ 5-B 备份数据库 \ 6-v 3 \ 7--outputdir=./backup --rows=100000 \ 8-L mydumper-logs.log &amp;amp; 迁移数据库 还原数据 1nohup myloader -h &amp;#39;迁移数据库&amp;#39; \ 2-u &amp;#39;用户名&amp;#39; \ 3-p &amp;#39;密码&amp;#39; \ 4--directory=./backup \ 5-s 来源数据库 \ 6-B 还原数据库 \ 7-t 16 \ 8-v 3 \ 9-e 2&amp;gt;myloader-logs.</description></item><item><title>nginx 编译参数详解</title><link>https://www.jobcher.com/nginx02/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx02/</guid><description>nginx 编译参数详解 nginx 编译参数 作用 –prefix= 指向安装目录 –sbin-path 指向（执行）程序文件（nginx） –conf-path= 指向配置文件（nginx.conf） –error-log-path= 指向错误日志目录 –pid-path= 指向 pid 文件（nginx.pid） –lock-path= 指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作。） –user= 指定程序运行时的非特权用户 –group= 指定程序运行时的非特权用户组 –builddir= 指向编译目录 –with-rtsig_module 启用 rtsig 模块支持（实时信号） –with-select_module 启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：–withoutselect_module –with-poll_module 启用 poll 模块支持（功能与 select 相同，与 select 特性相同，为一种轮询模式,不推荐在高载环境下使用） –with-file-aio 启用 file aio 支持（一种 APL 文件传输格式） –with-ipv6 启用 ipv6 支持 –with-http_ssl_module 启用 ngx_http_ssl_module 支持（使支持 https 请求，需已安装 openssl） –with-http_realip_module 启用 ngx_http_realip_module 支持（这个模块允许从请求标头更改客户端的 IP 地址值，默认为关） –with-http_addition_module 启用 ngx_http_addition_module 支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求） –with-http_xslt_module 启用 ngx_http_xslt_module 支持（过滤转换 XML 请求 –with-http_image_filter_module 启用 ngx_http_image_filter_module 支持（传输 JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd 库要用到） –with-http_geoip_module 启用 ngx_http_geoip_module 支持（该模块创建基于与 MaxMind GeoIP 二进制文件相配的客户端 IP 地址的 ngx_http_geoip_module 变量） –with-http_sub_module 启用 ngx_http_sub_module 支持（允许用一些其他文本替换 nginx 响应中的一些文本） –with-http_dav_module 启用 ngx_http_dav_module 支持（增加 PUT,DELETE,MKCOL：创建集合,COPY 和 MOVE 方法）默认情况下为关闭，需编译开启 –with-http_flv_module 启用 ngx_http_flv_module 支持（提供寻求内存使用基于时间的偏移量文件） –with-http_gzip_static_module 启用 ngx_http_gzip_static_module 支持（在线实时压缩输出数据流） –with-http_random_index_module 启用 ngx_http_random_index_module 支持（从目录中随机挑选一个目录索引） –with-http_secure_link_module 启用 ngx_http_secure_link_module 支持（计算和检查要求所需的安全链接网址） –with-http_degradation_module 启用 ngx_http_degradation_module 支持（允许在内存不足的情况下返回 204 或 444 码） –with-http_stub_status_module 启用 ngx_http_stub_status_module 支持（获取 nginx 自上次启动以来的工作状态） –without-http_charset_module 禁用 ngx_http_charset_module 支持（重新编码 web 页面，但只能是一个方向–服务器端到客户端，并且只有一个字节的编码可以被重新编码） –without-http_gzip_module 禁用 ngx_http_gzip_module 支持（该模块同-with-http_gzip_static_module 功能一样） –without-http_ssi_module 禁用 ngx_http_ssi_module 支持（该模块提供了一个在输入端处理处理服务器包含文件（SSI）的过滤器，目前支持 SSI 命令的列表是不完整的） –without-http_userid_module 禁用 ngx_http_userid_module 支持（该模块用来处理用来确定客户端后续请求的 cookies） –without-http_access_module 禁用 ngx_http_access_module 支持（该模块提供了一个简单的基于主机的访问控制。允许/拒绝基于 ip 地址） –without-http_auth_basic_module 禁用 ngx_http_auth_basic_module（该模块是可以使用用户名和密码基于 http 基本认证方法来保护你的站点或其部分内容） –without-http_autoindex_module 禁用 disable ngx_http_autoindex_module 支持（该模块用于自动生成目录列表，只在 ngx_http_index_module 模块未找到索引文件时发出请求。） –without-http_geo_module 禁用 ngx_http_geo_module 支持（创建一些变量，其值依赖于客户端的 IP 地址） –without-http_map_module 禁用 ngx_http_map_module 支持（使用任意的键/值对设置配置变量） –without-http_split_clients_module 禁用 ngx_http_split_clients_module 支持（该模块用来基于某些条件划分用户。条件如：ip 地址、报头、cookies 等等） –without-http_referer_module 禁用 disable ngx_http_referer_module 支持（该模块用来过滤请求，拒绝报 头中 Referer 值不正确的请求） –without-http_rewrite_module 禁用 ngx_http_rewrite_module 支持（该模块允许使用正则表达式改变 URI，并且根据变量来转向以及选择配置。如果在 server 级别设置该选项，那么他们将在 location 之前生效。如果在 location 还有更进一步的重写规则，location 部分的规则依然会被执行。如果这个 URI 重写是因为 location 部分的规则造成的，那么 location 部分会再次被执行作为新的 URI。 这个循环会执行 10 次，然后 Nginx 会返回一个 500 错误。） –without-http_proxy_module 禁用 ngx_http_proxy_module 支持（有关代理服务器） –without-http_fastcgi_module 禁用 ngx_http_fastcgi_module 支持（该模块允许 Nginx 与 FastCGI 进程交互，并通过传递参数来控制 FastCGI 进程工作。 ）FastCGI 一个常驻型的公共网关接口。 –without-http_uwsgi_module 禁用 ngx_http_uwsgi_module 支持（该模块用来医用 uwsgi 协议，uWSGI 服务器相关） –without-http_scgi_module 禁用 ngx_http_scgi_module 支持（该模块用来启用 SCGI 协议支持，SCGI 协议是 CGI 协议的替代。它是一种应用程序与 HTTP 服务接口标准。它有些像 FastCGI 但他的设计 更容易实现。） –without-http_memcached_module 禁用 ngx_http_memcached_module 支持（该模块用来提供简单的缓存，以提高系统效率） -without-http_limit_zone_module 禁用 ngx_http_limit_zone_module 支持（该模块可以针对条件，进行会话的并发连接数控制） –without-http_limit_req_module 禁用 ngx_http_limit_req_module 支持（该模块允许你对于一个地址进行请求数量的限制用一个给定的 session 或一个特定的事件） –without-http_empty_gif_module 禁用 ngx_http_empty_gif_module 支持（该模块在内存中常驻了一个 1*1 的透明 GIF 图像，可以被非常快速的调用） –without-http_browser_module 禁用 ngx_http_browser_module 支持（该模块用来创建依赖于请求报头的值。如果浏览器为 modern ，则$modern_browser 等于 modern_browser_value 指令分配的值；如 果浏览器为 old，则$ancient_browser 等于 ancient_browser_value 指令分配的值；如果浏览器为 MSIE 中的任意版本，则 $msie 等于 1） –without-http_upstream_ip_hash_module 禁用 ngx_http_upstream_ip_hash_module 支持（该模块用于简单的负载均衡） –with-http_perl_module 启用 ngx_http_perl_module 支持（该模块使 nginx 可以直接使用 perl 或通过 ssi 调用 perl） –with-perl_modules_path= 设定 perl 模块路径 –with-perl= 设定 perl 库文件路径 –http-log-path= 设定 access log 路径 –http-client-body-temp-path= 设定 http 客户端请求临时文件路径 –http-proxy-temp-path= 设定 http 代理临时文件路径 –http-fastcgi-temp-path= 设定 http fastcgi 临时文件路径 –http-uwsgi-temp-path= 设定 http uwsgi 临时文件路径 –http-scgi-temp-path= 设定 http scgi 临时文件路径 -without-http 禁用 http server 功能 –without-http-cache 禁用 http cache 功能 –with-mail 启用 POP3/IMAP4/SMTP 代理模块支持 –with-mail_ssl_module 启用 ngx_mail_ssl_module 支持 –without-mail_pop3_module 禁用 pop3 协议（POP3 即邮局协议的第 3 个版本,它是规定个人计算机如何连接到互联网上的邮件服务器进行收发邮件的协议。是因特网电子邮件的第一个离线协议标 准,POP3 协议允许用户从服务器上把邮件存储到本地主机上,同时根据客户端的操作删除或保存在邮件服务器上的邮件。POP3 协议是 TCP/IP 协议族中的一员，主要用于 支持使用客户端远程管理在服务器上的电子邮件） –without-mail_imap_module 禁用 imap 协议（一种邮件获取协议。它的主要作用是邮件客户端可以通过这种协议从邮件服务器上获取邮件的信息，下载邮件等。IMAP 协议运行在 TCP/IP 协议之上， 使用的端口是 143。它与 POP3 协议的主要区别是用户可以不用把所有的邮件全部下载，可以通过客户端直接对服务器上的邮件进行操作。） –without-mail_smtp_module 禁用 smtp 协议（SMTP 即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。SMTP 协议属于 TCP/IP 协议族，它帮助每台计算机在发送或中转信件时找到下一个目的地。） –with-google_perftools_module 启用 ngx_google_perftools_module 支持（调试用，剖析程序性能瓶颈） –with-cpp_test_module 启用 ngx_cpp_test_module 支持 –add-module= 启用外部模块支持 –with-cc= 指向 C 编译器路径 –with-cpp= 指向 C 预处理路径 –with-cc-opt= 设置 C 编译器参数（PCRE 库，需要指定–with-cc-opt=”-I /usr/local/include”，如果使用 select()函数则需要同时增加文件描述符数量，可以通过–with-cc- opt=”-D FD_SETSIZE=2048”指定。） –with-ld-opt= 设置连接文件参数。（PCRE 库，需要指定–with-ld-opt=”-L /usr/local/lib”。） –with-cpu-opt= 指定编译的 CPU，可用的值为: pentium, pentiumpro, pentium3, pentium4, athlon,opteron, amd64, sparc32, sparc64, ppc64 –without-pcre 禁用 pcre 库 –with-pcre 启用 pcre 库 –with-pcre= 指向 pcre 库文件目录 –with-pcre-opt= 在编译时为 pcre 库设置附加参数 –with-md5= 指向 md5 库文件目录（消息摘要算法第五版，用以提供消息的完整性保护） –with-md5-opt= 在编译时为 md5 库设置附加参数 –with-md5-asm 使用 md5 汇编源 –with-sha1= 指向 sha1 库目录（数字签名算法，主要用于数字签名） –with-sha1-opt= 在编译时为 sha1 库设置附加参数 –with-sha1-asm 使用 sha1 汇编源 –with-zlib= 指向 zlib 库目录 –with-zlib-opt= 在编译时为 zlib 设置附加参数 –with-zlib-asm= 为指定的 CPU 使用 zlib 汇编源进行优化，CPU 类型为 pentium, pentiumpro –with-libatomic 为原子内存的更新操作的实现提供一个架构 –with-libatomic= 指向 libatomic_ops 安装目录 –with-openssl= 指向 openssl 安装目录 –with-openssl-opt 在编译时为 openssl 设置附加参数 –with-debug 启用 debug 日志</description></item><item><title>nginx 重写规则 rewrite模块</title><link>https://www.jobcher.com/nginx04/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx04/</guid><description>nginx 重写规则 rewrite 模块 语法 语法 默认值 使用字段 作用 break none server, location, if 完成当前设置的重写规则，停止执行其他的重写规则。 set variable value none server, location, if 为给定的变量设置一个特定值。 return code none server, location, if 停止处理并为客户端返回状态码。非标准的 444 状态码将关闭连接，不发送任何响应头。可以使用的状态码有：204，400，402-406，408，410, 411, 413, 416 与 500-504。如果状态码附带文字段落，该文本将被放置在响应主体。相反，如果状态码后面是一个 URL，该 URL 将成为 location 头补值。没有状态码的 URL 将被视为一个 302 状态码。 rewrite_log on rewrite_log off server, location, if 启用时将在 error log 中记录 notice 级别的重写日志。 rewrite regex replacement flag none server, location, if 按照相关的正则表达式与字符串修改 URI，指令按照在配置文件中出现的顺序执行。可以在重写指令后面添加标记。注意：如果替换的字符串以 http://开头，请求将被重定向，并且不再执行多余的 rewrite 指令。尾部的标记(flag)可以是以下的值：last – 停止处理重写模块指令，之后搜索 location 与更改后的 URI 匹配.</description></item><item><title>nginx.conf 配置文件详解</title><link>https://www.jobcher.com/nginx03/</link><pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx03/</guid><description>nginx.conf 配置文件详解 1# vim nginx.conf 2user nobody nobody; # 运行 nginx 的所属组和所有者 3worker_processes 2; # 开启两个 nginx 工作进程,一般几个 CPU 核心就写几 4error_log logs/error.log notice; # 错误日志路径 5pid logs/nginx.pid; # pid 路径 6 7events 8{ 9 worker_connections 1024; # 一个进程能同时处理 1024 个请求 10} 11 12http 13{ 14 include mime.types; 15 default_type application/octet-stream; 16 17 log_format main ‘$remote_addr – $remote_user [$time_local] “$request” ‘ 18 ‘$status $body_bytes_sent “$http_referer” ‘ 19 ‘”$http_user_agent” “$http_x_forwarded_for”‘; 20 access_log logs/access.</description></item><item><title>网络基础知识</title><link>https://www.jobcher.com/network/</link><pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/network/</guid><description>网络基础知识 1、简述 ISO/OSI 七层模型的分层与作用 分层 作用 应用层 应用系统，提供用户服务 例如：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 表示层 把数据转换为能与接收者的系统格式兼容并适合传输的格式，数据表示，加密，压缩 会话层 负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。确定数据是否需要进行网络传递 分流网络传递还是本地保存 传输层 对数据分组，对报文进行分组(发送时)、组装(接收时)提供传输协议的选择：TCP (传输控制协议) :可靠的，面向连接的传输协议 (可靠，准确) (慢)UDP (用户数据报协议) :不可靠的，面向无连接的传输协议 (快) (不可靠)。端口封装，差错校验，滑动窗口，留空 网络层 网络层（Network Layer）决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络资料。例如:互联网协议（IP）等。1.IP 地址编址 2.路由选择 3.静态路由 4.动态路由 数据链路层 数据链路层（Data Link Layer）负责网络寻址、错误侦测和改错。1.MAC 地址编址 2.MAC 地址寻址 3.差错校验 物理层 物理层（Physical Layer）在局域网上发送数据帧（Data Frame）1.数据实际传输 2.电气特性定义 2、TCP/IP 四层模型与作用？ 分层 协议 应用层 HTTP、HTTPS、FTP、Telnet、SSH、SMTP、DNS 传输层 TCP、UDP 网络层 ICMP、IGMP、IP、ARP、RARP 数据链路层、物理层 PPP、PPPOE 3、TCP 协议与 UDP 协议工作在哪一层，作用是什么？ 传输层，对报文进行分组(发送时)、组装(接收时)提供
当进程需要传输可靠的数据时应使用 TCP，当进程需要高效传输数据，可以忽略可靠性时应使用 UDP 协议。
4、简述 TCP 三次握手的过程。 第一次握手：Client 将标志位 SYN 置为 1，随机产生一个值 seq=J，并将该数据包发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认。 第二次握手：Server 收到数据包后由标志位 SYN=1 知道 Client 请求建立连接，Server 将标志位 SYN 和 ACK 都置为 1，ack=J+1，随机产生一个值 seq=K，并将该数据包发送给 Client 以确认连接请求，Server 进入 SYN_RCVD 状态。 第三次握手：Client 收到确认后，检查 ack 是否为 J+1，ACK 是否为 1，如果正确则将标志位 ACK 置为 1，ack=K+1，并将该数据包发送给 Server，Server 检查 ack 是否为 K+1，ACK 是否为 1，如果正确则连接建立成功，Client 和 Server 进入 ESTABLISHED 状态，完成三次握手，随后 Client 与 Server 之间可以开始传输数据了。 5、简述 TCP 包头的内容。 源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址</description></item><item><title>docker 安装kong 网关</title><link>https://www.jobcher.com/docker-kong/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-kong/</guid><description>docker 安装 kong 网关 建立数据库 创建网络 1docker network create kong-net 建立数据库 1docker run -d --name kong-database \ 2 --network=kong-net \ 3 -p 5432:5432 \ 4 -e &amp;#34;POSTGRES_USER=kong&amp;#34; \ 5 -e &amp;#34;POSTGRES_DB=kong&amp;#34; \ 6 -e &amp;#34;POSTGRES_PASSWORD=kong123&amp;#34; \ 7 postgres:9.6 创建 kong 数据 1docker run --rm --network=kong-net \ 2 -e &amp;#34;KONG_DATABASE=postgres&amp;#34; \ 3 -e &amp;#34;KONG_PG_HOST=kong-database&amp;#34; \ 4 -e &amp;#34;KONG_PG_PASSWORD=kong123&amp;#34; \ 5 -e &amp;#34;KONG_PASSWORD=kong123&amp;#34; \ 6 kong:latest kong migrations bootstrap 创建 kong 创建 kong gateway 1 docker run -d --name kong \ 2 --network=kong-net \ 3 -e &amp;#34;KONG_DATABASE=postgres&amp;#34; \ 4 -e &amp;#34;KONG_PG_HOST=kong-database&amp;#34; \ 5 -e &amp;#34;KONG_PG_USER=kong&amp;#34; \ 6 -e &amp;#34;KONG_PG_PASSWORD=kong123&amp;#34; \ 7 -e &amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database&amp;#34; \ 8 -e &amp;#34;KONG_PROXY_ACCESS_LOG=/dev/stdout&amp;#34; \ 9 -e &amp;#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout&amp;#34; \ 10 -e &amp;#34;KONG_PROXY_ERROR_LOG=/dev/stderr&amp;#34; \ 11 -e &amp;#34;KONG_ADMIN_ERROR_LOG=/dev/stderr&amp;#34; \ 12 -e &amp;#34;KONG_ADMIN_LISTEN=0.</description></item><item><title>搭建docker registry 镜像仓库</title><link>https://www.jobcher.com/docker-registry/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker-registry/</guid><description>搭建 docker registry 镜像仓库 获取镜像 1docker pull registry:2.7.1 1docker pull hyper/docker-registry-web 容器运行 1mkdir -p /opt/data/registry 2docker run -d -p 5000:5000 -v /opt/data/registry:/var/lib/registry --name registry registry:2.7.1 1docker run -d -p 8080:8080 --name registry-web --link registry \ 2 -e REGISTRY_URL=http://192.168.99.146:5000/v2 \ 3 -e REGISTRY_TRUST_ANY_SSL=true \ 4 -e REGISTRY_BASIC_AUTH=&amp;#34;GjhYGDGi2HhkJB&amp;#34; \ 5 -e REGISTRY_NAME=192.168.99.146:5000 \ 6 hyper/docker-registry-web 上传容器 1vim /etc/docker/daemon.json 2{ 3 &amp;#34;insecure-registries&amp;#34;: [&amp;#34;192.168.99.146:5000&amp;#34;] 4} 5 6docker tag sjtfreaks/hogo-nginx:v1.1 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1 7docker push 192.168.99.146:5000/sjtfreaks/hogo-nginx:v1.1</description></item><item><title>rsync 文件同步</title><link>https://www.jobcher.com/rsync/</link><pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/rsync/</guid><description>rsync 文件同步 rsync 是一个常用的 Linux 应用程序，用于文件同步
安装 1# Debian or Ubuntu 2$ sudo apt-get install rsync 3 4# Red Hat 5$ sudo yum install rsync 6 7# Arch Linux 8$ sudo pacman -S rsync 基本用法 使用 rsync 命令时，可以作为 cp 和 mv 命令的替代方法，将源目录同步到目标目录。
-r 表示递归，即包含子目录。注意，-r 是必须的，否则 rsync 运行不会成功。source 目录表示源目录，destination 表示目标目录。
-a 参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新
1rsync -r source destination 远程同步
1rsync -av &amp;lt;源地址&amp;gt;/ &amp;lt;用户名&amp;gt;@&amp;lt;ip地址&amp;gt;:/&amp;lt;目标地址&amp;gt; 友情地址：mysql 迁移</description></item><item><title>helm 安装</title><link>https://www.jobcher.com/helm/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/helm/</guid><description>helm 安装 脚本安装 1curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 2chmod 700 get_helm.sh 3./get_helm.sh 4 5#或者可以使用这个命令 6curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash 7 8helm help 二进制安装 1wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz 2tar -zxvf helm-v3.7.2-linux-amd64.tar.gz 3cd helm-v3.7.2-linux-amd64 4mv linux-amd64/helm /usr/local/bin/helm 5helm help</description></item><item><title>k8s 部署loki日志</title><link>https://www.jobcher.com/k8sloki/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8sloki/</guid><description>k8s 部署 loki 日志 helm 拉取 loki 1#加源 2helm repo add grafana https://grafana.github.io/helm-charts 3helm repo update 4#拉取 5helm fetch grafana/loki-stack --untar --untardir . 6cd loki-stack 7# 生成 k8s 配置 8helm template loki . &amp;gt; loki.yaml 9# 部署（如果要修改默认配置必须要修改一下yaml） 10k3s kubectl apply -f loki.yaml</description></item><item><title>获取用户浏览器默认语言设置，自动判断跳转不同网站</title><link>https://www.jobcher.com/auto/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/auto/</guid><description>自动判断跳转不同网站 根据用户目前的浏览器配置语言进行显示 供语言切换按钮，用户自定义选择不同的语言显示 根据识别用户的浏览器语言，自动判断并跳转到相应的语言网页，让你的网站更加灵动。
以下需要将代码放在 HTML 的内即可，然后自行制作多语言页面。
代码如下：
1&amp;lt;script type=&amp;#34;text/javascript&amp;#34;&amp;gt; 2 //获取用户语言的顺序是 3 //1.获取本地缓存里的内容 4 //2.用户浏览器的语言设置 5 //如果上面2个都没有获取到，就直接使用&amp;#39;en&amp;#39;作为用户选择的语言 6 var language = 7 localStorage.getItem(&amp;#34;locale&amp;#34;) || 8 window.navigator.language.toLowerCase() || 9 &amp;#34;en&amp;#34;; 10 //把用户的语言写入缓存，供下次获取使用 11 localStorage.setItem(&amp;#34;locale&amp;#34;, language); 12 //判断用户的语言，跳转到不同的地方 13 if (language.indexOf(&amp;#34;zh-&amp;#34;) !== -1) { 14 window.location = &amp;#34;/zh-cn/index.html&amp;#34;; 15 } else if (language.indexOf(&amp;#34;en&amp;#34;) !== -1) { 16 window.location = &amp;#34;/en/index.html&amp;#34;; 17 } else { 18 //其它的都使用英文 19 window.location = &amp;#34;/en/index.html&amp;#34;; 20 } 21&amp;lt;/script&amp;gt; 核心代码</description></item><item><title>linux服务基础知识</title><link>https://www.jobcher.com/service/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/service/</guid><description>linux 服务基础知识 1、哪些设置能够提升 SSH 远程管理的安全等级 2、ssh 连接时认证时间过长如何解决？ 3、scp 和 rsync 进行远程文件复制有什么区别？ 4、请描述通过 DHCP 服务器获取 IP 地址的过程。 5、简单描述 FTP 的主动模式和被动模式的区别？ 6、集群环境中，如何保证所有服务器之间的时间误差较小。 7、请描述用户访问网站时 DNS 的解析过程。 8、解释权威 DNS 和递归 DNS 的含义，并描述智能 DNS 的实现原理。 9、公司里有一台服务器，需要在上面跑两个网站，并且其中一个网站需要更换新域名，请问如何处理？ 网站1：www.a.com 网站2：www.b.com（旧） www.d.com（新） 10、简述 Apache 的三种工作模式？ 11、请写出工作中常见的 Apache 优化策略。 12、有哪些技术可以提高网站的安全和效率？ 13、Apache 和 Nginx 各有什么优缺点，应该如何选择？ 14、为什么 Nginx 的并发能力强，资源消耗低？ 15、写出几个 Nginx 的常用模块，并描述其功能。 16、请解释 Nginx 是如何连接 PHP 进行页面解析的？ 17、请描述 Nginx 和 Tomcat 之间的数据传输过程？ 18、请写出几个常见的 HTTP 状态码，并解释出现原因。</description></item><item><title>mysql基础知识</title><link>https://www.jobcher.com/mysql/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/mysql/</guid><description>mysql 基础知识 1、库表 student.report,有 3 个字段，姓名、学科、成绩，记录如下，根据要求完成 SQL 语句： Name Subject Result 李白 Math 95 张三 English 83 王五 Math 79 李六 Math 85 张二 English 74 查询姓李的同学的个数。 查询表中数学成绩大于 80 的前 2 名同学的名字，并按分数从大到小的顺序排列。 2、MYSQL 集群一主多从，主库宕机，如何合理切换到从库，其它从库如何处理？ 3、单台 MySQL 达到性能瓶颈时，如何击碎性能瓶颈？ 4、MySQL 什么时候创建索引？ 5、误操作 drop 语句导致数据库数据破坏，请给出恢复的实际大体步骤。 6、如何保证 Redis 能永久保存数据？ 7、如何利用 Redis 对 MySQL 进行性能优化？</description></item><item><title>shell基础知识</title><link>https://www.jobcher.com/shell/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/shell/</guid><description>shell 基础知识 1、有一个 b.txt 文本(内容如下)，要求将所有域名截取出来，并统计重复域名出现的次数： http://www.baidu.com/index.html
https://www.atguigu.com/index.html
http://www.sina.com.cn/1024.html
https://www.atguigu.com/2048.html
http://www.sina.com.cn/4096.html
https://www.atguigu.com/8192.html
2、统计当前服务器正在连接的 IP 地址，并按连接次数排序 3、使用循环在/atguigu 目录下创建 10 个 txt 文件，要求文件名称由 6 位随机小写字母加固定字符串（_gg）组成，例如：pzjebg_gg.txt。 4、生成随机数字。 5、批量检查多个网站是否可以正常访问，要求使用 shell 数组实现，检测策略尽量模拟用户真实访问模式。 http://www.atguigu.com
http://www.gulixueyuan.com
http://www.baidu.com</description></item><item><title>Kubernetes 创建nfs存储类</title><link>https://www.jobcher.com/k8snfs/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/k8snfs/</guid><description>Kubernetes 创建 nfs 存储类 首先你需要在别的终端上创建 nfs 服务并能提供 nfs 访问
Kubernetes 不包含内部 NFS 驱动。你需要使用外部驱动为 NFS 创建 StorageClass。
https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner
安装 nfs 驱动
安装 nfs 驱动 1#安装nfs客户端 2apt-get install nfs-common 3git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git 4cd nfs-subdir-external-provisioner/deploy 5k3s kubectl create -f rbac.yaml 6vim deployment.yaml 编辑 deployment.yaml 1apiVersion: apps/v1 2kind: Deployment 3metadata: 4 name: nfs-client-provisioner 5 labels: 6 app: nfs-client-provisioner 7 # replace with namespace where provisioner is deployed 8 namespace: default 9spec: 10 replicas: 1 11 strategy: 12 type: Recreate 13 selector: 14 matchLabels: 15 app: nfs-client-provisioner 16 template: 17 metadata: 18 labels: 19 app: nfs-client-provisioner 20 spec: 21 serviceAccountName: nfs-client-provisioner 22 containers: 23 - name: nfs-client-provisioner 24 image: k8s.</description></item><item><title>nginx 日志格式整理</title><link>https://www.jobcher.com/nginx01/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx01/</guid><description>nginx 日志配置 语法 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 设置访问日志 access_log off; # 关闭访问日志 例子：
access_log /var/logs/nginx-access.log access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m 使用 log_format 自定义日志格式 Nginx 预定义了名为 combined 日志格式，如果没有明确指定日志格式默认使用该格式：
log_format combined &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#39; &amp;#39;&amp;#34;$request&amp;#34; $status $body_bytes_sent &amp;#39; &amp;#39;&amp;#34;$http_referer&amp;#34; &amp;#34;$http_user_agent&amp;#34;&amp;#39;; 如果不想使用 Nginx 预定义的格式，可以通过 log_format 指令来自定义。
语法 log_format name [escape=default|json] string ...; 变量 含义 $bytes_sent 发送给客户端的总字节数 $body_bytes_sent 发送给客户端的字节数，不包括响应头的大小 $connection 连接序列号 $connection_requests 当前通过连接发出的请求数量 $msec 日志写入时间，单位为秒，精度是毫秒 $pipe 如果请求是通过 http 流水线发送，则其值为&amp;quot;p&amp;quot;，否则为“.</description></item><item><title>linux系统开启root权限</title><link>https://www.jobcher.com/resetsystem/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/resetsystem/</guid><description>linux 系统开启 root 权限 修改 ssh 服务配置文件 1sudo su - 2sudo vim /etc/ssh/sshd_config 增加权限
在# Authentication: 下输入 1PermitRootLogin yes 更改 root 密码，重启服务 1sudo passwd root 2service sshd restart</description></item><item><title>mysql 笔记（1）</title><link>https://www.jobcher.com/mysql01/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/mysql01/</guid><description>mysql 学习笔记（1） 本文章不涉及到关于 mysql 开放上的问题，主要记录关于 mysql 出现的问题，以及如何去维护 mysql 数据的日常。
mysql 各类信息的收集 收集变量信息 1show global variables; 收集进程信息 1show PROCESSLIST; 收集错误日志 1show global variables like &amp;#39;log_error&amp;#39;; 收集慢日志信息 1show global variables like &amp;#39;slow_querry_log_file&amp;#39;; 收集锁信息，高峰时期运行三次，每次间隔 10s 1SELECT locked_table, 2 locked_index, 3 locked_type, 4 blocking_pid, 5 T2.USER blocking_user, 6 T2.HOST blocking_host, 7 blocking_lock_mode, 8 blocking_trx_rows_modified, 9 waiting_pid, 10 T3.USER waiting_user, 11 T3.HOST waiting_host, 12 waiting_lock_mode, 13 waiting_trx_row_modified, 14 wait_age_secs, 15 waiting_query 16FROM sys.x$innodb_lock_waits T1 17LEFT JOIN INFROMATION_SCHEMA.</description></item><item><title>163企业邮箱设置教程</title><link>https://www.jobcher.com/qyyemail163/</link><pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/qyyemail163/</guid><description>163 企业邮箱设置教程 请进入这个网站 https://qiye.163.com/help/l-11.html</description></item><item><title>git技巧</title><link>https://www.jobcher.com/gitlab/</link><pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/gitlab/</guid><description>git 技巧 Git 是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。
下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 &amp;ldquo;页面内查找&amp;rdquo; 的方式进行快速查询：Ctrl/Command+f。
开卷必读 如果之前未使用过 Git，可以学习 Git 小白教程入门
一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 如果喜欢这个项目，欢迎 Star、提交 Pr、反馈问题😊 目录 脑图 展示帮助信息 回到远程仓库的状态 重设第一个 commit 查看冲突文件列表 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 查看远程分支和本地分支的对应关系 远程删除了分支本地也想删除 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit 修改上一个 commit 的描述 查看 commit 历史 显示本地更新过 HEAD 的 git 命令记录 修改作者名 修改远程仓库的 url 增加远程仓库 列出所有远程仓库 查看两个星期内的改动 把 A 分支的某一个 commit，放到 B 分支上 给 git 命令起别名 存储当前的修改，但不用提交 commit 保存当前状态，包括 untracked 的文件 展示所有 stashes 回到某个 stash 的状态 回到最后一个 stash 的状态，并删除这个 stash 删除所有的 stash 从 stash 中拿出某个文件的修改 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 强制删除 untracked 的目录 展示简化的 commit 历史 查看某段代码是谁写的 把某一个分支导出成一个文件 从包中导入分支 执行 rebase 之前自动 stash 从远程仓库根据 ID，拉下某一状态，到本地分支 详细展示一行中的修改 清除 .</description></item><item><title>docker image镜像上传</title><link>https://www.jobcher.com/dockerimage/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/dockerimage/</guid><description>docker image 镜像上传 登入 docker hub，在https://hub.docker.com上注册你的账号。
1docker login 2username：#输入你的用户名 3password：#输入你的密码 上传镜像 1docker tag nginx:hugo sjtfreaks/hogo-nginx:v1 2docker push sjtfreaks/hogo-nginx:v1</description></item><item><title>docker进阶使用</title><link>https://www.jobcher.com/docker01/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/docker01/</guid><description>docker 进阶使用 dockerfile 和 docker compose 的配置
Dockerfile 使用 Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。
例子：
1 FROM nginx 2 RUN echo &amp;#39;这是一个本地构建的nginx镜像&amp;#39; &amp;gt; /usr/share/nginx/html/index.html 保存 Dockerfile 文件并在本地路径执行
1 docker build -t nginx:v1-test . 2 docker run -name docker run --name nginx-test -d -p 8080:80 nginx:v1-test 浏览 nginx 页面确认更新内容
curl 127.0.0.1:8080 输出： 这是一个本地构建的nginx镜像 Docker 命令详解 COPY 复制指令，从上下文目录中复制文件或者目录到容器里指定路径。
1 COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] &amp;lt;源路径1&amp;gt;... &amp;lt;目标路径&amp;gt; 2 COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [&amp;#34;&amp;lt;源路径1&amp;gt;&amp;#34;,... &amp;#34;&amp;lt;目标路径&amp;gt;&amp;#34;] &amp;lt;源路径&amp;gt;：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如：
1 COPY hom* /mydir/ 2 COPY hom?</description></item><item><title>Kubernetes k8s 组件</title><link>https://www.jobcher.com/kubernetes/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/kubernetes/</guid><description>Kubernetes k8s 组件 控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。
kube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。
etcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。
kube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。
kube-controller-manager 运行控制器进程的控制平面组件。
cloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。
Node 组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。
kubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。
kube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。
容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。
Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。</description></item><item><title>2021年第50周记</title><link>https://www.jobcher.com/20211210/</link><pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/20211210/</guid><description>2021 年第 50 周周记 这周完成了以下任务
搭建 hugo 博客 使用 docker 封装了 blog 搭建 k3s 环境 计划：
学习 k8s 总结：没啥好总结，刚开始写周记，就随便写一点吧
欢迎关注我的博客www.jobcher.com</description></item><item><title>nginx 汇总</title><link>https://www.jobcher.com/nginx/</link><pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nginx/</guid><description>nginx 汇总 各类 nginx 问题汇总
安装 nginx 1 #centos 2 yum install nginx 3 #ubuntu 4 apt install nginx http 代理 正向代理 1 server { 2 listen 80; 3 server_name www.nbtyfood.com; 4 5 location / { 6 proxy_pass http://127.0.0.1:8080; 7 } 8 } 反向代理 负载均衡 1 upstream mysvr { 2 server 192.168.10.121:3333; 3 server 192.168.10.122:3333; 4 } 5 server { 6 .... 7 location ~*^.+$ { 8 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 9 } 10 } 热备</description></item><item><title>TCP/IP详解</title><link>https://www.jobcher.com/tcpip/</link><pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/tcpip/</guid><description>TCP/IP 协议 什么是 TCP/IP 协议 OSI 七层架构 TCP/IP 四层模型 协议 应用层 HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS 表示层 应用层 XDR、ASN.1、NCP、TLS、ASCII 会话层 sockets、SOCKS、PAP 传输层 传输层 TCP、UDP、RTP、SCTP 网络层 网络互连层 IP、ICMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP 数据链路层 网络访问（链接）层 以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11 物理层 调制解调器、无线电、光纤 报文结构 TCP 报文段首部格式
源端口和目的端口：各占 2 个字节，分别写入源端口和目的端口。IP 地址 + 端口号就可以确定一个进程地址
序号/序列号（Sequense Number，SN）：在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。该字段表示本报文段所发送的数据的第一个字节的序号。初始序号称为 Init Sequense Number, ISN（序号/序列号这个字段很重要，大家留个印象，下文会详细讲解） 例如，一报文段的序号是 101，共有 100 字节的数据。这就表明：本报文段的数据的第一个字节的序号是 101，最后一个字节的序号是 200。显然，下一个报文段的数据序号应当从 201 开始，即下一个报文段的序号字段值应为 201。
确认号 ack：期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。
数据偏移（首部长度）：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 TCP 报文段的首部长度。
保留：占 6 位，应置为 0，保留为今后使用。</description></item><item><title>自建服务器内网穿透</title><link>https://www.jobcher.com/nps/</link><pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/nps/</guid><description>内网穿透 文章中使用的内网穿透前提是必须具有公网 IP 的云服务器，不符合条件的同学可以跳过了。
nps 内网穿透 nps 是一款轻量级、高性能、功能强大的内网穿透代理服务器。
在公网服务器上安装 nps sever 端 1 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_server.tar.gz 2 tar -zxvf linux_amd64_server.tar.gz 3 sudo ./nps install 4 sudo nps start 在控制端安装 npc client 端 1 wget https://github.com/ehang-io/nps/releases/download/v0.26.10/linux_amd64_client.tar.gz 2 tar -zxvf linux_amd64_client.tar.gz 3 sudo ./npc -server=ip:port -vkey=web界面中显示的密钥 4 sudo npc start npc 安装完成可以进入 web 页面穿透端口和域名
http://localhost:8080
frps 内网穿透 frps 相对于 nps 的劣势是有断流的风险
frps 相对于 nps 的优势是对于高流量的媒体服务能够提供更可靠的支持
安装 frps 1 wget https://code.aliyun.com/MvsCode/frps-onekey/raw/master/install-frps.sh -O ./install-frps.sh 2 chmod 700 .</description></item><item><title>树莓派搭建k3s</title><link>https://www.jobcher.com/rasberry/</link><pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/rasberry/</guid><description>树莓派安装 k3s 1.安装 k3s 控制节点 1 curl -sfL https://get.k3s.io | sh - 2 cat /var/lib/rancher/k3s/server/node-token 工作节点 1 curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 K3S_TOKEN=mynodetoken sh - 树莓派特别要注意一个坑，就是关于内存的问题这个之后再讲
1 k3s kubectl get nodes 2 #显示正确的节点表示完成 卸载 k3s 1 #server 节点 2 /usr/local/bin/k3s-uninstall.sh 3 #agent 节点 4 /usr/local/bin/k3s-agent-uninstall.sh 2.安装 dashboard k3s 面板 部署 Kubernetes 仪表盘 1 GITHUB_URL=https://github.com/kubernetes/dashboard/releases 2 VERSION_KUBE_DASHBOARD=$(curl -w &amp;#39;%{url_effective}&amp;#39; -I -L -s -S ${GITHUB_URL}/latest -o /dev/null | sed -e &amp;#39;s|.*/||&amp;#39;) 3 sudo k3s kubectl create -f https://raw.</description></item><item><title>brew 安装配置</title><link>https://www.jobcher.com/brew/</link><pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/brew/</guid><description>brew 安装配置 一.安装 1.在 ubuntu 上安装 brew 1 /bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&amp;#34; 2.在 centos 上安装 brew 1 /bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&amp;#34; 3.在 MacOS 上安装 brew 1 /bin/bash -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&amp;#34; 二、使用 1.安装 wget 1 brew install wget Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local
1 $ cd /usr/local 2 $ find Cellar 3 Cellar/wget/1.16.1 4 Cellar/wget/1.16.1/bin/wget 5 Cellar/wget/1.16.1/share/man/man1/wget.1 6 7 $ ls -l bin 8 bin/wget -&amp;gt; ../Cellar/wget/1.16.1/bin/wget 2.创建你自己的 Homebrew 包 1 $ brew create https://foo.</description></item><item><title>gitlab CI/CD 的使用</title><link>https://www.jobcher.com/gitlab-cicd/</link><pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/gitlab-cicd/</guid><description>gitlab CI/CD 的使用 我将使用 gitlab 的流水线自动实现 hugo blog 文章的自动发布。
一、基础知识 二、安装过程 1.安装 gitlab runner 首先需要安装 gitlab runner 进入服务器 A
安装方法：
容器部署
手动二进制文件部署
通过 rpm/deb 包部署
docker 方式安装
安装文档：https://docs.gitlab.com/runne&amp;hellip;
1 docker run -dit \ 2 --name gitlab-runner \ 3 --restart always \ 4 -v /srv/gitlab-runner/config:/etc/gitlab-runner \ 5 -v /var/run/docker.sock:/var/run/docker.sock \ 6 gitlab/gitlab-runner 1.1 设置信息
docker exec -it gitlab-runner gitlab-runner register 非 docker 方式安装 2.1 安装 GitLab Runner
安装环境：Linux
其他环境参考：https://docs.gitlab.com/runne&amp;hellip;
下载
1 curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.</description></item><item><title>Markdown教程</title><link>https://www.jobcher.com/markdown/</link><pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/markdown/</guid><description>Markdown 教程 参考：https://www.runoob.com/markdown</description></item><item><title>感谢打赏</title><link>https://www.jobcher.com/donation/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/donation/</guid><description>如果你觉得这个项目对你有帮助，并且情况允许的话，可以给我一点点支持，支持我维护下去</description></item><item><title>运维知识图谱</title><link>https://www.jobcher.com/yunwei/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/yunwei/</guid><description>运维图谱 云原生平台基础 Docker、Docker Compose：容器化技术 Kubernetes：大规模容器编排 Helm：云原生应用商店 Rancher： 易用的容器管理平台 KubeSphere：一站式容器云平台 OpenTracing：云原生链路追踪标准 Jaeger：云原生链路追踪实现产品 Istio：ServiceMesh下的服务流量治理 Jenkins、JenkinsX、Jenkins-BlueOcean：老牌的CI/CD平台 Gtilab/hub-CICD：Gitlab/hub自带的CICD Argo：kubernetes声明式持续集成 Nexus：Maven私库 Harbor：Docker私库 Prometheus+Granfana：监控与可视化平台 ElasticSearch+Fluentd+Kibana：日志与可视化方案 Serverless：无服务器上云方案（不用去管服务器，不是不需要服务器） SpringCloud Kubernetes：微服务上云方案 熟练掌握docker和k8s技术 devops掌握jenkins和gitlab
应用12要素 在现代，软件通常作为服务交付：称为Web 应用程序或软件即服务。十二因素应用程序是一种构建软件即服务应用程序的方法，它：
使用声明格式进行设置自动化，以最大限度地减少新开发人员加入项目的时间和成本； 与底层操作系统有一个干净的合同，在执行环境之间提供最大的可移植性； 适合部署在现代云平台上，无需服务器和系统管理； 最大限度地减少开发和生产之间的差异，实现持续部署以获得最大的敏捷性； 并且可以在不对工具、架构或开发实践进行重大更改的情况下进行扩展。 名称 英文 描述 基准代码 codebase 一份基准代码，多份部署 依赖 Dependencies 显示声明依赖关系 配置 config 在环境中存储配置 后端服务 backing services 把后端服务当做附加资源 构建，发布，运行 build，release，run 严格分离构建和运行 进程 Processes 以一个或多个无状态进程运行应用 端口绑定 port binding 通过端口绑定来提供服务 并发 concurrency 通过进程模型进行扩展 易处理 disposability 快速启动和优雅终止可最大化健壮性 开发环境和线上环境等价 Dev/prod parity 尽可能保持开发、预发布、线上环境 日志 log 把日志当做事件流 管理进程 admin processes 后台管理任务当做一次性进程处理</description></item><item><title>关于我</title><link>https://www.jobcher.com/about/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://www.jobcher.com/about/</guid><description>感谢您对我们博客文章的关注和支持。您的支持是我们前进的动力，让我们能够不断地创作有价值、有趣的内容。在这篇文章中，我们想要向您表达我们的感激之情，并与您分享一些即将到来的精彩计划。
我们一直致力于为您带来最有价值的内容。不论是技术探讨、创意灵感、生活经验分享，还是深度思考的文章，我们都希望能够触及到您的内心，为您带来启发和帮助。同时，我们也非常欢迎您的反馈和建议，帮助我们不断提升，为您奉上更加精彩的阅读体验。
在线博客 👋 https://www.jobcher.com
https://jobcher.github.io
书签导航 https://nav.jobcher.com/
访问次数</description></item></channel></rss>
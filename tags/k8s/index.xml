<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>k8s - 标签 - 打工人日志 - jobcher</title>
        <link>http://www.jobcher.com/tags/k8s/</link>
        <description>k8s - 标签 - 打工人日志 - jobcher</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>nb@nbtyfood.com (jobcher)</managingEditor>
            <webMaster>nb@nbtyfood.com (jobcher)</webMaster><lastBuildDate>Mon, 01 Aug 2022 00:00:00 &#43;0000</lastBuildDate><atom:link href="http://www.jobcher.com/tags/k8s/" rel="self" type="application/rss+xml" /><item>
    <title>kubernetes 存储</title>
    <link>http://www.jobcher.com/k8s10/</link>
    <pubDate>Mon, 01 Aug 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s10/</guid>
    <description><![CDATA[<h1 id="kubernetes-存储">kubernetes 存储</h1>
<p>k8s支持多种途径的多种类型的存储。例如iSCSI,SMB,NFS，以及对象存储。都是不同类型的部署在云上或者自建数据中心的外部存储系统。k8s上的所有存储都被称作<code>卷</code></p>
<h2 id="csi-容器存储接口">CSI 容器存储接口</h2>
<p>CSI是k8s存储体系中一部分，是一个开源项目，定义了一套基于标准的接口，从而使容器能够以一种统一的方式被不同的容器编排的工具使用。可以将插件称为<code>provisioner</code></p>
<h2 id="持久化">持久化</h2>
<ul>
<li>持久化卷 （pv）</li>
<li>持久化卷申请 （pvc）</li>
<li>存储类 （sv）</li>
</ul>
<p>PV 代表k8s的存储，pvc代表的是许可证，赋予pod访问pv的权限。cs使分配过程是动态的。</p>
<h2 id="使用iscsi操作存储">使用iSCSI操作存储</h2>
<p><code>iscsi</code> 卷能将 iSCSI (基于 IP 的 SCSI) 卷挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，iscsi 卷的内容在删除 Pod 时会被保留，卷只是被卸载。 这意味着 iscsi 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。<br>
<code>iSCSI</code> 的一个特点是它可以同时被多个用户以只读方式挂载。 这意味着你可以用数据集预先填充卷，然后根据需要在尽可能多的 Pod 上使用它。 不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载。不允许同时写入。</p>
<h3 id="创建-iscsi-pvyaml-iscsi-pvcyaml">创建 iscsi-pv.yaml iscsi-pvc.yaml</h3>
<p>iscsi-pv.yaml</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PersistentVolume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iscsi-pv</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">capacity</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l">500Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">accessModes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">ReadWriteOnce</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">iscsi</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPortal</span><span class="p">:</span><span class="w"> </span><span class="m">10.12.12</span><span class="l">.xxx:3260</span><span class="w"> </span><span class="c"># 修改</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">iqn</span><span class="p">:</span><span class="w"> </span><span class="l">iqn.2000-01.com.synology:xxx.Target-1.21xxxxx344</span><span class="w"> </span><span class="c"># 修改</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">lun</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>iscsi-pvc.yaml</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PersistentVolume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">iscsi-pv</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">capacity</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l">500Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">accessModes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">ReadWriteOnce</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">iscsi</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPortal</span><span class="p">:</span><span class="w"> </span><span class="m">10.12.12</span><span class="l">.xxx:3260</span><span class="w"> </span><span class="c"># 修改</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">iqn</span><span class="p">:</span><span class="w"> </span><span class="l">iqn.2000-01.com.synology:xxx.Target-1.21xxxxx344</span><span class="w"> </span><span class="c"># 修改</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">lun</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item><item>
    <title>kubernetes 从1.23.x 升级到 1.24.x</title>
    <link>http://www.jobcher.com/k8s9/</link>
    <pubDate>Wed, 29 Jun 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s9/</guid>
    <description><![CDATA[<h1 id="kubernetes-从123x-升级到-124x">kubernetes 从<code>1.23.x</code> 升级到 <code>1.24.x</code></h1>
<p>k8s 在<code>1.24.x</code>之后的版本放弃了和docker的兼容，使用containerd 作为底层的容器，直接参照官方文档的资料进行更新就会报错。因为你没有安装containerd，所以要安装containerd并配置才能正确的升级k8s<br>
我用的是<code>CentOS7.9</code>的版本，因此以下操作都是在<code>CentOS</code>下操作。</p>
<h2 id="master-节点操作">Master 节点操作</h2>
<h3 id="1升级kubeadm">1.升级kubeadm</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install -y kubeadm-1.24.2-0 --disableexcludes<span class="o">=</span>kubernetes
</span></span><span class="line"><span class="cl">kubeadm version
</span></span><span class="line"><span class="cl">kubeadm upgrade plan
</span></span><span class="line"><span class="cl">sudo kubeadm upgrade apply v1.24.2
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2安装containerd">2.安装containerd</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install containerd.io -y
</span></span><span class="line"><span class="cl">containerd config default &gt; /etc/containerd/config.toml
</span></span><span class="line"><span class="cl">vim /var/lib/kubelet/kubeadm-flags.env
</span></span></code></pre></td></tr></table>
</div>
</div><p>修改kubeadm-flags.env 变量：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nv">KUBELET_KUBEADM_ARGS</span><span class="o">=</span><span class="s2">&#34;--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="3升级kubelet">3.升级kubelet</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes<span class="o">=</span>kubernetes
</span></span><span class="line"><span class="cl">systemctl daemon-reload <span class="o">&amp;&amp;</span> systemctl restart containerd  <span class="o">&amp;&amp;</span> systemctl restart kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><p>查看状态：</p>
<blockquote>
<p>kubectl get nodes<br>
systemctl status kubelet</p>
</blockquote>
<h2 id="worker-节点操作">Worker 节点操作</h2>
<h3 id="1升级kubeadm-1">1.升级kubeadm</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install -y kubeadm-1.24.2-0 --disableexcludes<span class="o">=</span>kubernetes
</span></span><span class="line"><span class="cl">kubeadm version
</span></span><span class="line"><span class="cl">kubeadm upgrade plan
</span></span><span class="line"><span class="cl">sudo kubeadm upgrade node
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2安装containerd-1">2.安装containerd</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install containerd.io -y
</span></span><span class="line"><span class="cl">containerd config default &gt; /etc/containerd/config.toml
</span></span><span class="line"><span class="cl">vim /var/lib/kubelet/kubeadm-flags.env
</span></span></code></pre></td></tr></table>
</div>
</div><p>修改kubeadm-flags.env 变量：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nv">KUBELET_KUBEADM_ARGS</span><span class="o">=</span><span class="s2">&#34;--pod-infra-container-image=k8s.gcr.io/pause:3.6 --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="3升级kubelet-1">3.升级kubelet</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 --disableexcludes<span class="o">=</span>kubernetes
</span></span><span class="line"><span class="cl">systemctl daemon-reload <span class="o">&amp;&amp;</span> systemctl restart containerd  <span class="o">&amp;&amp;</span> systemctl restart kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><p>查看状态：</p>
<blockquote>
<p>systemctl status kubelet</p>
</blockquote>
<h3 id="4优化的维护节点">4.优化的维护节点</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># 设置为不可调度</span>
</span></span><span class="line"><span class="cl">kubectl cordon &lt;nodename&gt;
</span></span><span class="line"><span class="cl"><span class="c1"># 优雅排出容器</span>
</span></span><span class="line"><span class="cl">kubectl drain &lt;nodename&gt; --ignore-daemonsets --delete-emptydir-data
</span></span><span class="line"><span class="cl"><span class="c1"># 确认维护完成之后，恢复正常</span>
</span></span><span class="line"><span class="cl">kubectl uncordon &lt;nodename&gt;
</span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item><item>
    <title>编写 kubernetes 资源描述文件</title>
    <link>http://www.jobcher.com/k8s8/</link>
    <pubDate>Mon, 27 Jun 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s8/</guid>
    <description><![CDATA[<h1 id="编写-kubernetes-资源描述文件">编写 kubernetes 资源描述文件</h1>
<h3 id="1-部署一个应用">1. 部署一个应用</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1	#与k8s集群版本有关，使用 kubectl api-versions 即可查看当前集群支持的版本</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment	#该配置的类型，我们使用的是 Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="l">metadata:	       </span><span class="w"> </span><span class="c">#译名为元数据，即 Deployment 的一些基本属性和信息</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-deployment	#Deployment 的名称</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="l">labels:	   </span><span class="w"> </span><span class="c">#标签，可以灵活定位一个或多个资源，其中key和value均可自定义，可以定义多组，目前不需要理解</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx	#为该Deployment设置key为app，value为nginx的标签</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="l">spec:	       </span><span class="w"> </span><span class="c">#这是关于该Deployment的描述，可以理解为你期待该Deployment在k8s中如何使用</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">	</span><span class="c">#使用该Deployment创建一个应用程序实例</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="l">selector:	   </span><span class="w"> </span><span class="c">#标签选择器，与上面的标签共同作用，目前不需要理解</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w"> </span><span class="c">#选择包含标签app:nginx的资源</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="l">template:	   </span><span class="w"> </span><span class="c">#这是选择或创建的Pod的模板</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="l">metadata:	#Pod的元数据</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">labels:	#Pod的标签，上面的selector即选择包含标签app:nginx的Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="l">spec:	   </span><span class="w"> </span><span class="c">#期望Pod实现的功能（即在pod中部署）</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="l">containers:	#生成container，与docker中的container是同一种</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx	#container的名称</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx:1.7.9	#使用镜像nginx:1.7.9创建container，该container默认80端口可访问</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>kubectl apply -f xxx.yaml</p>
</blockquote>
<h3 id="2暴露应用">2、暴露应用</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-service	#Service 的名称</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">     	</span><span class="c">#Service 自己的标签</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx	#为该 Service 设置 key 为 app，value 为 nginx 的标签</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="l">spec:	   </span><span class="w"> </span><span class="c">#这是关于该 Service 的定义，描述了 Service 如何选择 Pod，如何被访问</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="l">selector:	   </span><span class="w"> </span><span class="c">#标签选择器</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx	#选择包含标签 app:nginx 的 Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-port	#端口的名字</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">TCP	   </span><span class="w"> </span><span class="c">#协议类型 TCP/UDP</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">	        </span><span class="c">#集群内的其他容器组可通过 80 端口访问 Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">nodePort</span><span class="p">:</span><span class="w"> </span><span class="m">32600</span><span class="w">   </span><span class="c">#通过任意节点的 32600 端口访问 Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">	</span><span class="c">#将请求转发到匹配 Pod 的 80 端口</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">NodePort	#Serive的类型，ClusterIP/NodePort/LoaderBalancer</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="3扩缩容">3、扩缩容</h3>
<p>修改deployment.yaml 中的 replicas 属性即可</p>
<p>完成后运行  <code>kubectl apply -f xxx.yaml</code></p>
<h3 id="4滚动升级">4、滚动升级</h3>
<p>修改deployment.yaml 中的 imageName 属性等</p>
<p>完成后运行  <code>kubectl apply -f xxx.yaml</code></p>
]]></description>
</item><item>
    <title>kubernetes manual expansion</title>
    <link>http://www.jobcher.com/k8s7/</link>
    <pubDate>Mon, 13 Jun 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s7/</guid>
    <description><![CDATA[<h1 id="k8s-manual-expansion">k8s manual expansion</h1>
<p>We find k8s-master node.Input the Command：</p>
<ol>
<li>expand</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl scale --replicas<span class="o">=</span><span class="m">3</span> deploy my-test-deploy
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>shrink</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl scale --replicas<span class="o">=</span><span class="m">1</span> deploy my-test-deploy
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="trouble-cleaning">trouble cleaning</h2>
<ol>
<li>get resource list</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get deployment
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl"><span class="c1"># exists in the namespace</span>
</span></span><span class="line"><span class="cl">kubectl api-resources --namespaced<span class="o">=</span><span class="nb">true</span>
</span></span><span class="line"><span class="cl"><span class="c1"># not exists in the namespace</span>
</span></span><span class="line"><span class="cl">kubectl api-resources --namespaced<span class="o">=</span><span class="nb">false</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>show info</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl describe pod my-test-pod
</span></span><span class="line"><span class="cl">kubectl describe deployment my-test-pod
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>exec container</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl <span class="nb">exec</span> -ti my-test-pod /bin/bash
</span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item><item>
    <title>kubernetes 调度过程</title>
    <link>http://www.jobcher.com/k8s6/</link>
    <pubDate>Thu, 21 Apr 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s6/</guid>
    <description><![CDATA[<h1 id="k8s-调度过程">k8s 调度过程</h1>
<p></p>
<h2 id="执行滚动升级">执行滚动升级</h2>
<p>修改deployment.yml文件，追加rollingUpdate</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># 部署应用</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog-deployment</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog	</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="l">spec:	        </span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">minReadySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="c">#准备10s</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RollingUpdate</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="c">#更新期间不少于3-1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">maxSurge</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="c">#更新期间不超过3+1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog-pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">hub.docker.com/blog/hugo:latest</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>执行命令</p>
<blockquote>
<p>kubectl rollout restart deployment jobcher-blog-deployment</p>
</blockquote>
]]></description>
</item><item>
    <title>k8s本地联调神器kt-connect</title>
    <link>http://www.jobcher.com/kt-connect/</link>
    <pubDate>Thu, 14 Apr 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/kt-connect/</guid>
    <description><![CDATA[<h1 id="k8s本地联调神器kt-connect">k8s本地联调神器kt-connect</h1>
<p><a href="https://www.bboy.app/2022/04/11/k8s%E6%9C%AC%E5%9C%B0%E8%81%94%E8%B0%83%E7%A5%9E%E5%99%A8kt-connect/" target="_blank" rel="noopener noreffer">转载自Bboysoul&rsquo;sBlog</a><br>
k8s集群内部的服务网络怎么和我们本地网络打通。kt-connect就是用来解决这个问题的</p>
<h2 id="使用方法">使用方法</h2>
<p>下载安装什么的都很简单，一个二进制而已</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">https://github.com/alibaba/kt-connect
</span></span></code></pre></td></tr></table>
</div>
</div><p>如果你安装好了，那么直接使用下面的命令使用就好了</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo ktctl connect
</span></span></code></pre></td></tr></table>
</div>
</div><p>当然也可以指定配置文件</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo ktctl --kubeconfig ~/.kube/local connect
</span></span></code></pre></td></tr></table>
</div>
</div><p>执行完成之后，这个集群的所有<code>svc</code>都可以直接在本地解析，当然直接ping pod的ip也是可以的</p>
]]></description>
</item><item>
    <title>OpenELB：让k8s私有环境对外暴露端口</title>
    <link>http://www.jobcher.com/openelb/</link>
    <pubDate>Wed, 13 Apr 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/openelb/</guid>
    <description><![CDATA[<h1 id="openelb云原生负载均衡器插件">OpenELB：云原生负载均衡器插件</h1>
<p>OpenELB 是一个开源的云原生负载均衡器实现，可以在基于裸金属服务器、边缘以及虚拟化的 Kubernetes 环境中使用 LoadBalancer 类型的 Service 对外暴露服务。</p>
<h2 id="在-kubernetes-中安装-openelb">在 Kubernetes 中安装 OpenELB</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl apply -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>查看状态</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get po -n openelb-system
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="使用-kubectl-删除-openelb">使用 kubectl 删除 OpenELB</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl delete -f https://raw.githubusercontent.com/openelb/openelb/master/deploy/openelb.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get ns
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="配置-openelb">配置 OpenELB</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl edit configmap kube-proxy -n kube-system
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 修改 网卡</span>
</span></span><span class="line"><span class="cl">ipvs:
</span></span><span class="line"><span class="cl">  strictARP: <span class="nb">true</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="重启组件">重启组件</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl rollout restart daemonset kube-proxy -n kube-system
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="为-master1-节点添加一个-annotation-来指定网卡">为 master1 节点添加一个 annotation 来指定网卡：</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl annotate nodes master1 layer2.openelb.kubesphere.io/v1alpha1<span class="o">=</span><span class="s2">&#34;192.168.0.2&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="创建地址池-layer2-eipyaml">创建地址池 <code>layer2-eip.yaml</code></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">network.kubesphere.io/v1alpha2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Eip</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">layer2-eip</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">address</span><span class="p">:</span><span class="w"> </span><span class="m">192.168.0.91-192.168.0.100</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">interface</span><span class="p">:</span><span class="w"> </span><span class="l">eth0</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">layer2</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="创建部署-jobcher-serviceyaml">创建部署 <code>jobcher-service.yaml</code></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c">#暴露端口</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-service</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">lb.kubesphere.io/v1alpha1</span><span class="p">:</span><span class="w"> </span><span class="l">openelb</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">protocol.openelb.kubesphere.io/v1alpha1</span><span class="p">:</span><span class="w"> </span><span class="l">layer2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">eip.openelb.kubesphere.io/v1alpha2</span><span class="p">:</span><span class="w"> </span><span class="l">layer2-eip</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-blog</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">jobcher-port</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">TCP</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">targetPort</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">LoadBalancer</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item><item>
    <title>kubernetes ansible自动化部署</title>
    <link>http://www.jobcher.com/k8s5/</link>
    <pubDate>Fri, 08 Apr 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s5/</guid>
    <description><![CDATA[<h1 id="kubernetes-ansible-自动化部署">kubernetes ansible 自动化部署</h1>
<h2 id="服务器规划">服务器规划</h2>
<table>
<thead>
<tr>
<th style="text-align:left">角色</th>
<th style="text-align:left">IP</th>
<th style="text-align:left">组件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">k8s-master1</td>
<td style="text-align:left">10.12.12.15</td>
<td style="text-align:left">kube-apiserver kube-controller-manager kube-scheduler etcd</td>
</tr>
<tr>
<td style="text-align:left">k8s-master2</td>
<td style="text-align:left">10.12.12.17</td>
<td style="text-align:left">kube-apiserver kube-controller-manager kube-scheduler etcd</td>
</tr>
<tr>
<td style="text-align:left">k8s-02</td>
<td style="text-align:left">10.12.12.22</td>
<td style="text-align:left">kubelet kube-proxy docker etcd</td>
</tr>
<tr>
<td style="text-align:left">k8s-03</td>
<td style="text-align:left">10.12.12.21</td>
<td style="text-align:left">kubelet kube-proxy docker etcd</td>
</tr>
<tr>
<td style="text-align:left">load Balancer(master)</td>
<td style="text-align:left">10.12.12.15 10.12.12.23(VIP)</td>
<td style="text-align:left">nginx keepalived</td>
</tr>
<tr>
<td style="text-align:left">load Balancer(backup)</td>
<td style="text-align:left">10.12.12.17</td>
<td style="text-align:left">nginx keepalived</td>
</tr>
</tbody>
</table>
<h2 id="系统初始化">系统初始化</h2>
<ol>
<li>关闭selinux，firewalld</li>
<li>关闭swap</li>
<li>时间同步</li>
<li>写hosts</li>
<li>ssh免密（可选）</li>
</ol>
<h2 id="etcd集群部署">etcd集群部署</h2>
<ol>
<li>生成etcd证书</li>
<li>部署三个ETC集群</li>
<li>查看集群状态</li>
</ol>
<h2 id="部署masterß">部署Masterß</h2>
<ol>
<li>生成apiserver证书</li>
<li>部署apiserver、controller-manager和scheduler组件</li>
<li>启动TLS Bootstrapping</li>
</ol>
<h2 id="部署node">部署Node</h2>
<ol>
<li>安装Docker</li>
<li>部署Kubelet和kube-proxy</li>
<li>在Master上运行为新Node颁发证书</li>
<li>授权apiserver访问kubelet</li>
</ol>
<h2 id="部署插件准备好镜像">部署插件（准备好镜像）</h2>
<ol>
<li>Flannel</li>
<li>Web UI</li>
<li>CoreDNS</li>
<li>Ingress Controller</li>
</ol>
<h2 id="master高可用">Master高可用</h2>
<ol>
<li>增加Master节点（与Master1一致）</li>
<li>部署nginx负载均衡器</li>
<li>Nginx+Keepalived 高可用</li>
<li>修改Node连接VIP</li>
</ol>
]]></description>
</item><item>
    <title>kubernetes 脚本快速安装</title>
    <link>http://www.jobcher.com/k8s4/</link>
    <pubDate>Thu, 10 Mar 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s4/</guid>
    <description><![CDATA[<h1 id="kubernetes-脚本快速安装">kubernetes 脚本快速安装</h1>
<ul>
<li>1、三台机器设置自己的hostname（不能是localhost）</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># 修改 hostname;  k8s-01要变为自己的hostname</span>
</span></span><span class="line"><span class="cl">hostnamectl set-hostname k8s-01
</span></span><span class="line"><span class="cl"><span class="c1"># 设置 hostname 解析</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;127.0.0.1   </span><span class="k">$(</span>hostname<span class="k">)</span><span class="s2">&#34;</span> &gt;&gt; /etc/hosts
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>2、所有机器批量执行如下脚本</p>
</li>
<li>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#先在所有机器执行 vi k8s.sh</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 进入编辑模式（输入i），把如下脚本复制</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 所有机器给脚本权限  chmod +x k8s.sh</span>
</span></span><span class="line"><span class="cl"><span class="c1">#执行脚本 ./k8s.sh</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span><span class="lnt">96
</span><span class="lnt">97
</span><span class="lnt">98
</span><span class="lnt">99
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#/bin/sh</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#######################开始设置环境##################################### \n</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################正在配置所有基础环境信息################## \n&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################关闭selinux################## \n&#34;</span>
</span></span><span class="line"><span class="cl">sed -i <span class="s1">&#39;s/enforcing/disabled/&#39;</span> /etc/selinux/config
</span></span><span class="line"><span class="cl">setenforce <span class="m">0</span>
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################关闭swap################## \n&#34;</span>
</span></span><span class="line"><span class="cl">swapoff -a  
</span></span><span class="line"><span class="cl">sed -ri <span class="s1">&#39;s/.*swap.*/#&amp;/&#39;</span> /etc/fstab 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################配置路由转发################## \n&#34;</span>
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span></span></span><span class="line"><span class="cl"><span class="s">br_netfilter
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;net.ipv4.ip_forward = 1&#39;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## 必须 ipv6流量桥接</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;net.bridge.bridge-nf-call-ip6tables = 1&#39;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl"><span class="c1">## 必须 ipv4流量桥接</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;net.bridge.bridge-nf-call-iptables = 1&#39;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;net.ipv6.conf.all.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;net.ipv6.conf.default.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;net.ipv6.conf.lo.disable_ipv6 = 1&#34;</span> &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;net.ipv6.conf.all.forwarding = 1&#34;</span>  &gt;&gt; /etc/sysctl.d/k8s.conf
</span></span><span class="line"><span class="cl">modprobe br_netfilter
</span></span><span class="line"><span class="cl">sudo sysctl --system
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################配置ipvs################## \n&#34;</span>
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF | sudo tee /etc/sysconfig/modules/ipvs.modules
</span></span></span><span class="line"><span class="cl"><span class="s">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="s">modprobe -- ip_vs
</span></span></span><span class="line"><span class="cl"><span class="s">modprobe -- ip_vs_rr
</span></span></span><span class="line"><span class="cl"><span class="s">modprobe -- ip_vs_wrr
</span></span></span><span class="line"><span class="cl"><span class="s">modprobe -- ip_vs_sh
</span></span></span><span class="line"><span class="cl"><span class="s">modprobe -- nf_conntrack_ipv4
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">chmod <span class="m">755</span> /etc/sysconfig/modules/ipvs.modules 
</span></span><span class="line"><span class="cl">sh /etc/sysconfig/modules/ipvs.modules
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################安装ipvsadm相关软件################## \n&#34;</span>
</span></span><span class="line"><span class="cl">yum install -y ipset ipvsadm
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################安装docker容器环境################## \n&#34;</span>
</span></span><span class="line"><span class="cl">sudo yum remove docker*
</span></span><span class="line"><span class="cl">sudo yum install -y yum-utils
</span></span><span class="line"><span class="cl">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</span></span><span class="line"><span class="cl">yum install -y docker-ce-19.03.9  docker-ce-cli-19.03.9 containerd.io
</span></span><span class="line"><span class="cl">systemctl <span class="nb">enable</span> docker
</span></span><span class="line"><span class="cl">systemctl start docker
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span><span class="line"><span class="cl">sudo systemctl restart docker
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################安装k8s核心包 kubeadm kubelet kubectl################## \n&#34;</span>
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span class="line"><span class="cl"><span class="s">[kubernetes]
</span></span></span><span class="line"><span class="cl"><span class="s">name=Kubernetes
</span></span></span><span class="line"><span class="cl"><span class="s">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
</span></span></span><span class="line"><span class="cl"><span class="s">enabled=1
</span></span></span><span class="line"><span class="cl"><span class="s">gpgcheck=0
</span></span></span><span class="line"><span class="cl"><span class="s">repo_gpgcheck=0
</span></span></span><span class="line"><span class="cl"><span class="s">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
</span></span></span><span class="line"><span class="cl"><span class="s">   http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">###指定k8s安装版本</span>
</span></span><span class="line"><span class="cl">yum install -y kubelet-1.21.0 kubeadm-1.21.0 kubectl-1.21.0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">###要把kubelet立即启动。</span>
</span></span><span class="line"><span class="cl">systemctl <span class="nb">enable</span> kubelet
</span></span><span class="line"><span class="cl">systemctl start kubelet
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">printf</span> <span class="s2">&#34;##################下载api-server等核心镜像################## \n&#34;</span>
</span></span><span class="line"><span class="cl">sudo tee ./images.sh <span class="s">&lt;&lt;-&#39;EOF&#39;
</span></span></span><span class="line"><span class="cl"><span class="s">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/kube-apiserver:v1.21.9
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/kube-controller-manager:v1.21.9
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/kube-scheduler:v1.21.9
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/kube-proxy:v1.21.9
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/pause:3.4.1
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/etcd:3.4.13-0
</span></span></span><span class="line"><span class="cl"><span class="s">docker pull k8s.gcr.io/coredns/coredns:v1.8.0
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">chmod +x ./images.sh <span class="o">&amp;&amp;</span> ./images.sh
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl"><span class="c1">### k8s的所有基本环境全部完成</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>3、使用kubeadm引导集群（参照初始化master继续做）</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#### --apiserver-advertise-address 的地址一定写成自己master机器的ip地址</span>
</span></span><span class="line"><span class="cl"><span class="c1">#### 虚拟机或者其他云厂商给你的机器ip  10.96  192.168</span>
</span></span><span class="line"><span class="cl"><span class="c1">#### 以下的只在master节点执行</span>
</span></span><span class="line"><span class="cl">kubeadm init <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--apiserver-advertise-address<span class="o">=</span>10.12.12.24 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--kubernetes-version v1.21.0 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--service-cidr<span class="o">=</span>10.96.0.0/16 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--pod-network-cidr<span class="o">=</span>10.124.0.0/16
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>4、master结束以后，按照控制台引导继续往下</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">## 第一步</span>
</span></span><span class="line"><span class="cl">mkdir -p <span class="nv">$HOME</span>/.kube
</span></span><span class="line"><span class="cl">sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="cl">sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##第二步</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">KUBECONFIG</span><span class="o">=</span>/etc/kubernetes/admin.conf
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##第三步 部署网络插件</span>
</span></span><span class="line"><span class="cl">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##第四步，用控制台打印的kubeadm join 去其他node节点执行</span>
</span></span><span class="line"><span class="cl">kubeadm join 10.170.11.8:6443 --token cnb7x2.lzgz7mfzcjutn0nk <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	--discovery-token-ca-cert-hash sha256:00c9e977ee52632098aadb515c90076603daee94a167728110ef8086d0d5b37d
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="初始化worker节点worker执行">初始化worker节点（worker执行）</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">##过期怎么办</span>
</span></span><span class="line"><span class="cl">kubeadm token create --print-join-command
</span></span><span class="line"><span class="cl">kubeadm join --token y1eyw5.ylg568kvohfdsfco --discovery-token-ca-cert-hash sha256: 6c35e4f73f72afd89bf1c8c303ee55677d2cdb1342d67bb23c852aba2efc7c73
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>5、验证集群</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#等一会，在master节点执行</span>
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>6、设置kube-proxy的ipvs模式</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">##修改kube-proxy默认的配置</span>
</span></span><span class="line"><span class="cl">kubectl edit cm kube-proxy -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1">## 修改mode: &#34;ipvs&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">##改完以后重启kube-proxy</span>
</span></span><span class="line"><span class="cl"><span class="c1">### 查到所有的kube-proxy</span>
</span></span><span class="line"><span class="cl">kubectl get pod -n kube-system <span class="p">|</span>grep kube-proxy
</span></span><span class="line"><span class="cl"><span class="c1">### 删除之前的即可</span>
</span></span><span class="line"><span class="cl">kubectl delete pod 【用自己查出来的kube-proxy-dw5sf kube-proxy-hsrwp kube-proxy-vqv7n】  -n kube-system
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">###</span>
</span></span></code></pre></td></tr></table>
</div>
</div>]]></description>
</item><item>
    <title>kubernetes面试题汇总</title>
    <link>http://www.jobcher.com/k8s3/</link>
    <pubDate>Wed, 16 Feb 2022 00:00:00 &#43;0000</pubDate>
    <author>作者</author>
    <guid>http://www.jobcher.com/k8s3/</guid>
    <description><![CDATA[<h1 id="kubernetes面试题汇总">kubernetes面试题汇总</h1>
<h2 id="1-k8s是什么请说出你的了解">1、 k8s是什么？请说出你的了解？</h2>
<p>答：Kubenetes是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。<br>
K8S是Google公司推出的，它来源于由Google公司内部使用了15年的Borg系统，集结了Borg的精华。</p>
<h2 id="2-k8s架构的组成是什么">2、 K8s架构的组成是什么？</h2>
<p>答：和大多数分布式系统一样，K8S集群至少需要一个主节点（Master）和多个计算节点（Node）。</p>
<p>主节点主要用于暴露API，调度部署和节点的管理；<br>
计算节点运行一个容器运行环境，一般是docker环境（类似docker环境的还有rkt），同时运行一个K8s的代理（kubelet）用于和master通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是k8s集群中真正工作的节点。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">K8S架构细分：
</span></span><span class="line"><span class="cl">1、Master节点（默认不参加实际工作）：
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Kubectl：客户端命令行工具，作为整个K8s集群的操作入口；
</span></span><span class="line"><span class="cl">Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件；
</span></span><span class="line"><span class="cl">Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等；
</span></span><span class="line"><span class="cl">Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上；
</span></span><span class="line"><span class="cl">Etcd：担任数据中心的角色，保存了整个群集的状态；
</span></span><span class="line"><span class="cl">2、Node节点：
</span></span><span class="line"><span class="cl">Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）；
</span></span><span class="line"><span class="cl">Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务时，Service接收到的请求后就是通过kube-proxy来转发到pod上的）；
</span></span><span class="line"><span class="cl">container-runtime：是负责管理运行容器的软件，比如docker
</span></span><span class="line"><span class="cl">Pod：是k8s集群里面最小的单位。每个pod里边可以运行一个或多个container（容器），如果一个pod中有两个container，那么container的USR（用户）、MNT（挂载点）、PID（进程号）是相互隔离的，UTS（主机名和域名）、IPC（消息队列）、NET（网络栈）是相互共享的。我比较喜欢把pod来当做豌豆夹，而豌豆就是pod中的container；
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="3-容器和主机部署应用的区别是什么">3、 容器和主机部署应用的区别是什么？</h2>
<p>答：容器的中心思想就是秒级启动；一次封装、到处运行；这是主机部署应用无法达到的效果，但同时也更应该注重容器的数据持久化问题。
另外，容器部署可以将各个服务进行隔离，互不影响，这也是容器的另一个核心概念。</p>
<h2 id="4请你说一下kubenetes针对pod资源对象的健康监测机制">4、请你说一下kubenetes针对pod资源对象的健康监测机制？</h2>
<p>答：K8s中对于<code>pod</code>资源对象的健康状态检测，提供了三类<code>probe（探针）</code>来执行对pod的健康监测：</p>
<ol>
<li><code>livenessProbe</code>探针<br>
可以根据用户自定义规则来判定pod是否健康，如果livenessProbe探针探测到容器不健康，则kubelet会根据其重启策略来决定是否重启，如果一个容器不包含livenessProbe探针，则kubelet会认为容器的livenessProbe探针的返回值永远成功。</li>
<li><code>ReadinessProbe</code>探针<br>
同样是可以根据用户自定义规则来判断pod是否健康，如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功。</li>
<li><code>startupProbe</code>探针<br>
启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间：
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">initialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败  
</span></span><span class="line"><span class="cl">periodSeconds：检查间隔，多久执行probe检查，默认为10s；  
</span></span><span class="line"><span class="cl">timeoutSeconds：检查超时时长，探测应用timeout后为失败；  
</span></span><span class="line"><span class="cl">successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="上面两种探针都支持以下三种探测方法">上面两种探针都支持以下三种探测方法：</h2>
<ol>
<li>Exec：通过执行命令的方式来检查服务是否正常，比如使用cat命令查看pod中的某个重要配置文件是否存在，若存在，则表示pod健康。反之异常。<br>
Exec探测方式的yaml文件语法如下：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">liveness</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/busybox</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">args</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">/bin/sh</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- -<span class="l">c</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">         </span><span class="c">#选择livenessProbe的探测机制</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">exec</span><span class="p">:</span><span class="w">                      </span><span class="c">#执行以下命令</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="l">cat</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="l">/tmp/healthy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">          </span><span class="c">#在容器运行五秒后开始探测</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">               </span><span class="c">#每次探测的时间间隔为5秒</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在上面的配置文件中，探测机制为在容器运行5秒后，每隔五秒探测一次，如果cat命令返回的值为“0”，则表示健康，如果为非0，则表示异常。</p>
<ol start="2">
<li>Httpget：通过发送http/htps请求检查服务是否正常，返回的状态码为200-399则表示容器健康（注http get类似于命令curl -I）。<br>
Httpget探测方式的yaml文件语法如下：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">liveness</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/liveness</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">              </span><span class="c">#采用livenessProbe机制探测</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">                  </span><span class="c">#采用httpget的方式</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="l">scheme:HTTP        </span><span class="w"> </span><span class="c">#指定协议，也支持https</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/healthz         </span><span class="w"> </span><span class="c">#检测是否可以访问到网页根目录下的healthz网页文件</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">              </span><span class="c">#监听端口是8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">     </span><span class="c">#容器运行3秒后开始探测</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">                </span><span class="c">#探测频率为3秒</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>上述配置文件中，探测方式为项容器发送HTTP GET请求，请求的是8080端口下的healthz文件，返回任何大于或等于200且小于400的状态码表示成功。任何其他代码表示异常。</p>
<ol start="3">
<li>tcpSocket：通过容器的IP和Port执行TCP检查，如果能够建立TCP连接，则表明容器健康，这种方式与HTTPget的探测机制有些类似，tcpsocket健康检查适用于TCP业务。<br>
tcpSocket探测方式的yaml文件语法如下：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">goproxy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/goproxy:0.1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c">#这里两种探测机制都用上了，都是为了和容器的8080端口建立TCP连接</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">tcpSocket</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">tcpSocket</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">15</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">20</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在上述的yaml配置文件中，两类探针都使用了，在容器启动5秒后，kubelet将发送第一个readinessProbe探针，这将连接容器的8080端口，如果探测成功，则该pod为健康，十秒后，kubelet将进行第二次连接。</p>
<p>除了readinessProbe探针外，在容器启动15秒后，kubelet将发送第一个livenessProbe探针，仍然尝试连接容器的8080端口，如果连接失败，则重启容器。</p>
<p>探针探测的结果无外乎以下三者之一：</p>
<p>Success：Container通过了检查；
Failure：Container没有通过检查；
Unknown：没有执行检查，因此不采取任何措施（通常是我们没有定义探针检测，默认为成功）。
若觉得上面还不够透彻，可以移步其官网文档：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/" target="_blank" rel="noopener noreffer">https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/</a></p>
<h2 id="5-如何控制滚动更新过程">5、 如何控制滚动更新过程？</h2>
<p>答：
可以通过下面的命令查看到更新时可以控制的参数：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">[</span>root@master yaml<span class="o">]</span><span class="c1"># kubectl explain deploy.spec.strategy.rollingUpdate</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>maxSurge ：此参数控制滚动更新过程，副本总数超过预期pod数量的上限。可以是百分比，也可以是具体的值。默认为1。<br>
（上述参数的作用就是在更新过程中，值若为3，那么不管三七二一，先运行三个pod，用于替换旧的pod，以此类推）<br>
maxUnavailable：此参数控制滚动更新过程中，不可用的Pod的数量。 （这个值和上面的值没有任何关系，举个例子：我有十个pod，但是在更新的过程中，我允许这十个pod中最多有三个不可用，那么就将这个参数的值设置为3，在更新的过程中，只要不可用的pod数量小于或等于3，那么更新过程就不会停止）。</p>
<h2 id="6k8s中镜像的下载策略是什么">6、K8s中镜像的下载策略是什么？</h2>
<p>答：可通过命令“kubectl explain pod.spec.containers”来查看imagePullPolicy这行的解释。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">K8s的镜像下载策略有三种：Always、Never、IFNotPresent；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Always：镜像标签为latest时，总是从指定的仓库中获取镜像；
</span></span><span class="line"><span class="cl">Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；
</span></span><span class="line"><span class="cl">IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。
</span></span><span class="line"><span class="cl">默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="7-image的状态有哪些">7、 image的状态有哪些？</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">Running：Pod所需的容器已经被成功调度到某个节点，且已经成功运行，
</span></span><span class="line"><span class="cl">Pending：APIserver创建了pod资源对象，并且已经存入etcd中，但它尚未被调度完成或者仍然处于仓库中下载镜像的过程
</span></span><span class="line"><span class="cl">Unknown：APIserver无法正常获取到pod对象的状态，通常是其无法与所在工作节点的kubelet通信所致。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="8-pod的重启策略是什么">8、 pod的重启策略是什么？</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">答：可以通过命令“kubectl explain pod.spec”查看pod的重启策略。（restartPolicy字段）
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Always：但凡pod对象终止就重启，此为默认策略。
</span></span><span class="line"><span class="cl">OnFailure：仅在pod对象出现错误时才重启
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="9-service这种资源对象的作用是什么">9、 Service这种资源对象的作用是什么？</h2>
<p>答：用来给相同的多个pod对象提供一个固定的统一访问接口，常用于服务发现和服务访问。</p>
<h2 id="10版本回滚相关的命令">10、版本回滚相关的命令？</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">[</span>root@master httpd-web<span class="o">]</span><span class="c1"># kubectl apply -f httpd2-deploy1.yaml  --record  </span>
</span></span><span class="line"><span class="cl"><span class="c1">#运行yaml文件，并记录版本信息；</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master httpd-web<span class="o">]</span><span class="c1"># kubectl rollout history deployment httpd-devploy1  </span>
</span></span><span class="line"><span class="cl"><span class="c1">#查看该deployment的历史版本</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master httpd-web<span class="o">]</span><span class="c1"># kubectl rollout undo deployment httpd-devploy1 --to-revision=1    </span>
</span></span><span class="line"><span class="cl"><span class="c1">#执行回滚操作，指定回滚到版本1</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="c1">#在yaml文件的spec字段中，可以写以下选项（用于限制最多记录多少个历史版本）：</span>
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  revisionHistoryLimit: <span class="m">5</span>            
</span></span><span class="line"><span class="cl"><span class="c1">#这个字段通过 kubectl explain deploy.spec  命令找到revisionHistoryLimit   &lt;integer&gt;行获得</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="11-标签与标签选择器的作用是什么">11、 标签与标签选择器的作用是什么？</h2>
<p><code>标签</code>：是当相同类型的资源对象越来越多的时候，为了更好的管理，可以按照标签将其分为一个组，为的是提升资源对象的管理效率。<br>
<code>标签选择器</code>：就是标签的查询过滤条件。目前API支持两种标签选择器：</p>
<ol>
<li>基于等值关系的，如：“=”、“”“==”、“！=”（注：“==”也是等于的意思，yaml文件中的matchLabels字段）；</li>
<li>基于集合的，如：in、notin、exists（yaml文件中的matchExpressions字段）；</li>
<li>注：in:在这个集合中；notin：不在这个集合中；exists：要么全在（exists）这个集合中，要么都不在（notexists）；
使用标签选择器的操作逻辑：</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">在使用基于集合的标签选择器同时指定多个选择器之间的逻辑关系为“与”操作（比如：- <span class="o">{</span>key: name,operator: In,values: <span class="o">[</span>zhangsan,lisi<span class="o">]}</span> ，那么只要拥有这两个值的资源，都会被选中）；
</span></span><span class="line"><span class="cl">使用空值的标签选择器，意味着每个资源对象都被选中（如：标签选择器的键是“A”，两个资源对象同时拥有A这个键，但是值不一样，这种情况下，如果使用空值的标签选择器，那么将同时选中这两个资源对象）
</span></span><span class="line"><span class="cl">空的标签选择器（注意不是上面说的空值，而是空的，都没有定义键的名称），将无法选择出任何资源；
</span></span><span class="line"><span class="cl">在基于集合的选择器中，使用“In”或者“Notin”操作时，其values可以为空，但是如果为空，这个标签选择器，就没有任何意义了。
</span></span></code></pre></td></tr></table>
</div>
</div><p>两种标签选择器类型（基于等值、基于集合的书写方法）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">           </span><span class="c">#基于等值</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">         </span><span class="c">#基于集合</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- {<span class="nt">key: name,operator: In,values</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="l">zhangsan,lisi]}    </span><span class="w"> </span><span class="c">#key、operator、values这三个字段是固定的</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- {<span class="nt">key: age,operator</span><span class="p">:</span><span class="w"> </span><span class="l">Exists,values:}  </span><span class="w"> </span><span class="c">#如果指定为exists，那么values的值一定要为空</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="12-常用的标签分类有哪些">12、 常用的标签分类有哪些？</h2>
<p>标签分类是可以自定义的，但是为了能使他人可以达到一目了然的效果，一般会使用以下一些分类：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">版本类标签（release）：stable（稳定版）、canary（金丝雀版本，可以将其称之为测试版中的测试版）、beta（测试版）；
</span></span><span class="line"><span class="cl">环境类标签（environment）：dev（开发）、qa（测试）、production（生产）、op（运维）；
</span></span><span class="line"><span class="cl">应用类（app）：ui、as、pc、sc；
</span></span><span class="line"><span class="cl">架构类（tier）：frontend（前端）、backend（后端）、cache（缓存）；
</span></span><span class="line"><span class="cl">分区标签（partition）：customerA（客户A）、customerB（客户B）；
</span></span><span class="line"><span class="cl">品控级别（Track）：daily（每天）、weekly（每周）。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="13-有几种查看标签的方式">13、 有几种查看标签的方式？</h2>
<p>答：常用的有以下三种查看方式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl get pod --show-labels    #查看pod，并且显示标签内容</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl get pod -L env,tier      #显示资源对象标签的值</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl get pod -l env,tier      #只显示符合键值资源对象的pod，而“-L”是显示所有的pod</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="14-添加修改删除标签的命令">14、 添加、修改、删除标签的命令？</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#对pod标签的操作</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label pod label-pod abc=123     #给名为label-pod的pod添加标签</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label pod label-pod abc=456 --overwrite       #修改名为label-pod的标签</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label pod label-pod abc-             #删除名为label-pod的标签</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl get pod --show-labels</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="c1">#对node节点的标签操作   </span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label nodes node01 disk=ssd      #给节点node01添加disk标签</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label nodes node01 disk=sss –overwrite    #修改节点node01的标签</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>root@master ~<span class="o">]</span><span class="c1"># kubectl label nodes node01 disk-         #删除节点node01的disk标签</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="15-daemonset资源对象的特性">15、 DaemonSet资源对象的特性？</h2>
<p><code>DaemonSet</code>这种资源对象会在每个k8s集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。所以，在其yaml文件中，不支持定义replicas，除此之外，与Deployment、RS等资源对象的写法相同。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">它的一般使用场景如下：
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">在去做每个节点的日志收集工作；
</span></span><span class="line"><span class="cl">监控每个节点的的运行状态；
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="16-说说你对job这种资源对象的了解">16、 说说你对Job这种资源对象的了解？</h2>
<p>答：Job与其他服务类容器不同，Job是一种工作类容器（一般用于做一次性任务）。使用常见不多，可以忽略这个问题。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#提高Job执行效率的方法：</span>
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  parallelism: <span class="m">2</span>           <span class="c1">#一次运行2个</span>
</span></span><span class="line"><span class="cl">  completions: <span class="m">8</span>           <span class="c1">#最多运行8个</span>
</span></span><span class="line"><span class="cl">  template:
</span></span><span class="line"><span class="cl">metadata:
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="17描述一下pod的生命周期有哪些状态">17、描述一下pod的生命周期有哪些状态？</h2>
<p>Pending：表示pod已经被同意创建，正在等待kube-scheduler选择合适的节点创建，一般是在准备镜像；
Running：表示pod中所有的容器已经被创建，并且至少有一个容器正在运行或者是正在启动或者是正在重启；
Succeeded：表示所有容器已经成功终止，并且不会再启动；
Failed：表示pod中所有容器都是非0（不正常）状态退出；
Unknown：表示无法读取Pod状态，通常是kube-controller-manager无法与Pod通信。</p>
<h2 id="18-创建一个pod的流程是什么">18、 创建一个pod的流程是什么？</h2>
<p>答：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">1） 客户端提交Pod的配置信息（可以是yaml文件定义好的信息）到kube-apiserver；
</span></span><span class="line"><span class="cl">2） Apiserver收到指令后，通知给controller-manager创建一个资源对象；
</span></span><span class="line"><span class="cl">3） Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中；
</span></span><span class="line"><span class="cl">4） Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。
</span></span><span class="line"><span class="cl">5） Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="19-删除一个pod会发生什么事情">19、 删除一个Pod会发生什么事情？</h2>
<p>答：Kube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作；</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">关闭流程如下：
</span></span><span class="line"><span class="cl">1、 pod从service的endpoint列表中被移除；
</span></span><span class="line"><span class="cl">2、 如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程；
</span></span><span class="line"><span class="cl">3、 进程被发送TERM信号（kill -14）
</span></span><span class="line"><span class="cl">4、 当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）。
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="20-k8s的service是什么">20、 K8s的Service是什么？</h2>
<p>答：Pod每次重启或者重新部署，其IP地址都会产生变化，这使得pod间通信和pod与外部通信变得困难，这时候，就需要Service为pod提供一个固定的入口。</p>
<p>Service的Endpoint列表通常绑定了一组相同配置的pod，通过负载均衡的方式把外界请求分配到多个pod上</p>
<h2 id="21-k8s是怎么进行服务注册的">21、 k8s是怎么进行服务注册的？</h2>
<p>答：Pod启动后会加载当前环境所有Service信息，以便不同Pod根据Service名进行通信。</p>
<h2 id="22-k8s集群外流量怎么访问pod">22、 k8s集群外流量怎么访问Pod？</h2>
<p>答：可以通过Service的NodePort方式访问，会在所有节点监听同一个端口，比如：30000，访问节点的流量会被重定向到对应的Service上面。</p>
<h2 id="23-k8s数据持久化的方式有哪些">23、 k8s数据持久化的方式有哪些？</h2>
<p>答：1）EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">主要使用场景：
</span></span><span class="line"><span class="cl">1） 只需要临时将数据保存在磁盘上，比如在合并/排序算法中；
</span></span><span class="line"><span class="cl">2） 作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由同一个webserver容器对外提供这些页面。
</span></span><span class="line"><span class="cl">emptyDir的特性：
</span></span><span class="line"><span class="cl">同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。如果仅仅是容器被销毁，pod还在，则不会影响volume中的数据。
</span></span><span class="line"><span class="cl">总结来说：emptyDir的数据持久化的生命周期和使用的pod一致。一般是作为临时存储使用。
</span></span></code></pre></td></tr></table>
</div>
</div><p>2）Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式。
这种数据持久化方式，运用场景不多，因为它增加了pod与节点之间的耦合。
一般对于k8s集群本身的数据持久化和docker本身的数据持久化会使用这种方式，可以自行参考apiService的yaml文件，位于：/etc/kubernetes/main…目录下。</p>
<p>3）PersistentVolume（简称PV）：
基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">在一个PV的yaml文件中，可以对其配置PV的大小，
</span></span><span class="line"><span class="cl">指定PV的访问模式：
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">ReadWriteOnce：只能以读写的方式挂载到单个节点；
</span></span><span class="line"><span class="cl">ReadOnlyMany：能以只读的方式挂载到多个节点；
</span></span><span class="line"><span class="cl">ReadWriteMany：能以读写的方式挂载到多个节点。，
</span></span><span class="line"><span class="cl">以及指定pv的回收策略：
</span></span><span class="line"><span class="cl">recycle：清除PV的数据，然后自动回收；
</span></span><span class="line"><span class="cl">Retain：需要手动回收；
</span></span><span class="line"><span class="cl">delete：删除云存储资源，云存储专用；
</span></span><span class="line"><span class="cl"><span class="c1">#PS：这里的回收策略指的是在PV被删除后，在这个PV下所存储的源文件是否删除）。</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>若需使用PV，那么还有一个重要的概念：PVC，PVC是向PV申请应用所需的容量大小，K8s集群中可能会有多个PV，PVC和PV若要关联，其定义的访问模式必须一致。定义的storageClassName也必须一致，若群集中存在相同的（名字、访问模式都一致）两个PV，那么PVC会选择向它所需容量接近的PV去申请，或者随机申请。</p>
]]></description>
</item></channel>
</rss>
